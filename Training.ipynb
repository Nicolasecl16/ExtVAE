{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import Prob_models as PM\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import tensorboard\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "tfpl = tfp.layers\n",
    "tfd = tfp.distributions\n",
    "import random\n",
    "from netCDF4 import Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 100\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training radius model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radius dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165.50166\n",
      "16.883898\n"
     ]
    }
   ],
   "source": [
    "A = 2*tfd.Uniform().sample(1000)\n",
    "X = tfd.InverseGamma(concentration =1.5, scale = 0.6 ).sample(1000)\n",
    "R1 = A*X\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "train_dataset = R1[:250]\n",
    "train_dataset = tf.reshape(train_dataset,[250,1])\n",
    "eval_dataset = R1[250:]\n",
    "eval_dataset=tf.reshape(eval_dataset,[750,1])\n",
    "print(np.max(R1))\n",
    "print(np.max(R1[:250]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Danube river network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18244, 31)\n"
     ]
    }
   ],
   "source": [
    "ncfile = Dataset('/home/nlafon/These/4Dvarnetstochastic/Danube_river_network/Dataset_danube.nc',\"r\")\n",
    "L=[]\n",
    "for i in range(31):\n",
    "    L.append(ncfile['S'+str(i+1)][:].reshape(18244,1))\n",
    "        \n",
    "dataset = np.concatenate((L[0],L[1],L[2],L[3],L[4],L[5],L[6],L[7],L[8],L[9],L[10],L[11],L[12],L[13],L[14],L[15],L[16],L[17],L[18],L[19],L[20],L[21],L[22],L[23],L[24],L[25],L[26],L[27],L[28],L[29],L[30]),axis=1)\n",
    "print(dataset.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We focus on two groups of stations R4 and R2 (see $Asadi\\ et\\ al.\\ (2015). $)  \n",
    "R2 comprises five stations in the Inn basin that are fed by precipitation in high-altitude alpine regions.  \n",
    "R4 contains five stations with sources north of the Danube.  \n",
    "Stations of R4 : 23; 24; 25; 26; 27.   \n",
    "Stations of R2 : 13; 28; 29; 30; 31."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(730, 1)\n",
      "856.9\n",
      "1899.0\n"
     ]
    }
   ],
   "source": [
    "R4 = dataset[:,22:27]\n",
    "axis = 1\n",
    "R4_rad = np.sum(R4,axis)\n",
    "R4_rad = R4_rad.reshape((18244,1))\n",
    "R4_S = np.divide(R4,R4_rad)\n",
    "train_dataset = R4_rad[::25,:]\n",
    "eval_dataset  = R4_rad\n",
    "print(train_dataset.shape)\n",
    "print(np.max(train_dataset))\n",
    "print(np.max(R4_rad))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import VAE model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing standard VAE model : vae = PM.Std_VAE()  \n",
    "Importing Extreme value VAE model assuming known shape parameter: vae = PM.Ext_VAE()  \n",
    "Importing Extreme value VAE model, shape parameter is learned : vae = PM.U_Ext_VAE()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'prior_c:0' shape=(1,) dtype=float32, numpy=array([4.8579035], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "#vae = PM.Std_VAE()\n",
    "#vae = PM.Ext_VAE()\n",
    "vae  = PM.U_Ext_VAE()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = '/home/nlafon/These/Extreme_VAE/tmp/Danube/radius/Ext_VAE/Gamma_output_prior_unknown3/checkpoint'\n",
    "metric ='val_loss'\n",
    "model_checkpoint_callback = tfk.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor=metric,\n",
    "    mode='min',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pre-training of the encoder if needed in case of instability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "23/23 [==============================] - 1s 5ms/step - loss: 586.1639\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 567.6381\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 543.5135\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 510.9303\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 4ms/step - loss: nan \n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 4ms/step - loss: nan\n",
      "<tf.Variable 'prior_c:0' shape=(1,) dtype=float32, numpy=array([nan], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "# U_Ext_VAE\n",
    "enc = vae.encoder\n",
    "enc.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-5),\n",
    "            loss=negative_log_likelihood)\n",
    "\n",
    "enc.fit(x=train_dataset,\n",
    "\ty=train_dataset, \n",
    "        #validation_data=(eval_dataset,eval_dataset), \n",
    "        batch_size=32,\n",
    "        epochs=10)\n",
    "print(enc.prior.concentration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_log_likelihood = lambda x, rv_x: -rv_x.log_prob(x)\n",
    "\n",
    "vae.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-3),\n",
    "            loss=negative_log_likelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fit the VAE, saving the best model wrt to val loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "23/23 [==============================] - 6s 214ms/step - loss: 7.5493 - val_loss: 7.1321\n",
      "Epoch 2/1000\n",
      "23/23 [==============================] - 3s 136ms/step - loss: 6.5737 - val_loss: 6.4667\n",
      "Epoch 3/1000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: 6.1812 - val_loss: 6.7813\n",
      "Epoch 4/1000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: 6.2231 - val_loss: 6.2562\n",
      "Epoch 5/1000\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 6.2738 - val_loss: 6.5242\n",
      "Epoch 6/1000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: 6.2533 - val_loss: 6.4655\n",
      "Epoch 7/1000\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 6.2852 - val_loss: 6.4543\n",
      "Epoch 8/1000\n",
      "23/23 [==============================] - 3s 121ms/step - loss: 6.2199 - val_loss: 6.1478\n",
      "Epoch 9/1000\n",
      "23/23 [==============================] - 3s 141ms/step - loss: 6.0658 - val_loss: 6.2226\n",
      "Epoch 10/1000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: 6.0393 - val_loss: 6.1186\n",
      "Epoch 11/1000\n",
      "23/23 [==============================] - 6s 290ms/step - loss: 6.0870 - val_loss: 6.1152\n",
      "Epoch 12/1000\n",
      "23/23 [==============================] - 4s 172ms/step - loss: 6.1294 - val_loss: 6.2394\n",
      "Epoch 13/1000\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 6.8971 - val_loss: 6.5712\n",
      "Epoch 14/1000\n",
      "23/23 [==============================] - 3s 152ms/step - loss: 6.2574 - val_loss: 6.1805\n",
      "Epoch 15/1000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: 6.0481 - val_loss: 6.1350\n",
      "Epoch 16/1000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: 6.0549 - val_loss: 6.4483\n",
      "Epoch 17/1000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: 10.3315 - val_loss: 7.9851\n",
      "Epoch 18/1000\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 7.2304 - val_loss: 6.8701\n",
      "Epoch 19/1000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: 6.5723 - val_loss: 6.7293\n",
      "Epoch 20/1000\n",
      "23/23 [==============================] - 5s 240ms/step - loss: 6.3757 - val_loss: 6.5210\n",
      "Epoch 21/1000\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 6.2248 - val_loss: 6.2469\n",
      "Epoch 22/1000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: 7.7140 - val_loss: 7.5615\n",
      "Epoch 23/1000\n",
      "23/23 [==============================] - 3s 149ms/step - loss: 8.2290 - val_loss: 9.1623\n",
      "Epoch 24/1000\n",
      "23/23 [==============================] - 3s 139ms/step - loss: 7.5469 - val_loss: 6.7501\n",
      "Epoch 25/1000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: 6.7021 - val_loss: 6.6492\n",
      "Epoch 26/1000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: 6.4297 - val_loss: 6.4271\n",
      "Epoch 27/1000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: 6.3645 - val_loss: 6.3166\n",
      "Epoch 28/1000\n",
      "23/23 [==============================] - 5s 206ms/step - loss: 6.2176 - val_loss: 6.2650\n",
      "Epoch 29/1000\n",
      "23/23 [==============================] - 7s 323ms/step - loss: 6.1946 - val_loss: 6.2325\n",
      "Epoch 30/1000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: 6.2008 - val_loss: 6.3250\n",
      "Epoch 31/1000\n",
      "23/23 [==============================] - 4s 167ms/step - loss: 6.1647 - val_loss: 6.2227\n",
      "Epoch 32/1000\n",
      "23/23 [==============================] - 5s 206ms/step - loss: 6.3248 - val_loss: 6.5922\n",
      "Epoch 33/1000\n",
      "23/23 [==============================] - 4s 179ms/step - loss: 6.2049 - val_loss: 6.2218\n",
      "Epoch 34/1000\n",
      "23/23 [==============================] - 3s 131ms/step - loss: 6.1445 - val_loss: 6.2109\n",
      "Epoch 35/1000\n",
      "23/23 [==============================] - 7s 314ms/step - loss: 6.1361 - val_loss: 6.2095\n",
      "Epoch 36/1000\n",
      "23/23 [==============================] - 7s 321ms/step - loss: 6.1371 - val_loss: 6.2452\n",
      "Epoch 37/1000\n",
      "23/23 [==============================] - 5s 227ms/step - loss: 6.1364 - val_loss: 6.3387\n",
      "Epoch 38/1000\n",
      "23/23 [==============================] - 3s 157ms/step - loss: 6.1417 - val_loss: 6.2128\n",
      "Epoch 39/1000\n",
      "23/23 [==============================] - 5s 232ms/step - loss: 6.1138 - val_loss: 6.4249\n",
      "Epoch 40/1000\n",
      "23/23 [==============================] - 7s 322ms/step - loss: 6.1729 - val_loss: 6.2091\n",
      "Epoch 41/1000\n",
      "23/23 [==============================] - 7s 325ms/step - loss: 6.1805 - val_loss: 6.2511\n",
      "Epoch 42/1000\n",
      "23/23 [==============================] - 7s 303ms/step - loss: 6.1331 - val_loss: 6.1922\n",
      "Epoch 43/1000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: 6.1374 - val_loss: 6.3019\n",
      "Epoch 44/1000\n",
      "23/23 [==============================] - 7s 339ms/step - loss: 8.1841 - val_loss: 7.5576\n",
      "Epoch 45/1000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: 7.2256 - val_loss: 6.6125\n",
      "Epoch 46/1000\n",
      "23/23 [==============================] - 5s 241ms/step - loss: 6.3997 - val_loss: 6.6285\n",
      "Epoch 47/1000\n",
      "23/23 [==============================] - 3s 114ms/step - loss: 6.2686 - val_loss: 6.2429\n",
      "Epoch 48/1000\n",
      "23/23 [==============================] - 3s 133ms/step - loss: 6.1532 - val_loss: 6.2100\n",
      "Epoch 49/1000\n",
      "23/23 [==============================] - 8s 350ms/step - loss: 6.1638 - val_loss: 6.2275\n",
      "Epoch 50/1000\n",
      "23/23 [==============================] - 7s 335ms/step - loss: 6.1991 - val_loss: 6.2143\n",
      "Epoch 51/1000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: 6.1187 - val_loss: 6.2747\n",
      "Epoch 52/1000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: 6.1083 - val_loss: 6.2851\n",
      "Epoch 53/1000\n",
      "23/23 [==============================] - 4s 167ms/step - loss: 6.1152 - val_loss: 6.1962\n",
      "Epoch 54/1000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: 6.0969 - val_loss: 6.1974\n",
      "Epoch 55/1000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: 6.3567 - val_loss: 8.3569\n",
      "Epoch 56/1000\n",
      "23/23 [==============================] - 5s 247ms/step - loss: 7.1494 - val_loss: 7.0106\n",
      "Epoch 57/1000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: 8.4665 - val_loss: 7.8767\n",
      "Epoch 58/1000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: 7.1231 - val_loss: 6.5178\n",
      "Epoch 59/1000\n",
      "23/23 [==============================] - 4s 172ms/step - loss: 6.3912 - val_loss: 6.4211\n",
      "Epoch 60/1000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: 6.2515 - val_loss: 6.3317\n",
      "Epoch 61/1000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: 6.1756 - val_loss: 6.3253\n",
      "Epoch 62/1000\n",
      "23/23 [==============================] - 4s 158ms/step - loss: 6.1509 - val_loss: 6.2169\n",
      "Epoch 63/1000\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 6.1419"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_checkpoint_callback\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m       \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/keras/engine/training.py:1606\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[1;32m   1593\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m   1594\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1604\u001b[0m         steps_per_execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution,\n\u001b[1;32m   1605\u001b[0m     )\n\u001b[0;32m-> 1606\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1608\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1609\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1611\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1615\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1617\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1618\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1619\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1620\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1621\u001b[0m }\n\u001b[1;32m   1622\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/keras/engine/training.py:1947\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1943\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1944\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1945\u001b[0m ):\n\u001b[1;32m   1946\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 1947\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1949\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vae.fit(train_dataset,train_dataset, \n",
    "        validation_data=(eval_dataset,eval_dataset), \n",
    "        batch_size=32,\n",
    "        epochs=5000, \n",
    "        callbacks = [model_checkpoint_callback]\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'prior_c:0' shape=(1,) dtype=float32, numpy=array([4.4771185], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "enc = vae.encoder\n",
    "print(enc.prior.concentration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training radius-conditioned angular model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Angle dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Synthetic dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let **X** the multivariate random vector we want to sample from. **X** =R **$\\Theta$**  \n",
    "The norm is set to the 1D samples of previous section. \n",
    "We sample on the multivariate sphere according to a Dirichlet distribution. \n",
    "For every radius r,  **$\\Theta$** | r is Dirichlet with K=5, $\\alpha_1(R))=\\alpha_2(R) = 3\\left(2 -min(1, \\frac{1}{2R})\\right)$, $ \\alpha_3=\\alpha_4 = \\alpha_5=3\\left(1 + min(1, \\frac{1}{2||R||})\\right)$.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 5)\n",
      "(250, 1)\n"
     ]
    }
   ],
   "source": [
    "def alphas_function(x):\n",
    "    res = tf.convert_to_tensor([6. -3*tf.minimum(1.,0.5/x), 6. -3*tf.minimum(1.,0.5/x) , 3.+ 3*tf.minimum(1,0.5/x), 3.+ 3*tf.minimum(1,0.5/x), 3.+ 3*tf.minimum(1,0.5/x)])\n",
    "    return(tf.transpose(res))\n",
    "\n",
    "\n",
    "alphas          = alphas_function(train_dataset[:,0])\n",
    "angle_train_dep = tfd.Dirichlet(alphas).sample()\n",
    "print(angle_train_dep.shape)\n",
    "print(train_dataset.shape)\n",
    "alphas_eval     = alphas_function(eval_dataset[:,0])\n",
    "angle_eval_dep = tfd.Dirichlet(alphas_eval).sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Danube dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(730, 5)\n",
      "(730, 1)\n",
      "(18244, 5)\n"
     ]
    }
   ],
   "source": [
    "angle_train_dep = R4_S[::25,:]\n",
    "print(angle_train_dep.shape)\n",
    "print(train_dataset.shape)\n",
    "angle_eval_dep  = R4_S\n",
    "print(angle_eval_dep.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = '/home/nlafon/These/Extreme_VAE/tmp/Danube/angle/normal_output2/checkpoint'\n",
    "metric ='val_loss'\n",
    "model_checkpoint_callback = tfk.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor=metric,\n",
    "    mode='min',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-11 11:08:52.370692: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-11 11:08:52.373747: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fbdf45ad490>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae = PM.Sphere_VAE()\n",
    "#If training from previously learned model :\n",
    "#vae.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-5),\n",
    "            loss=negative_log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n",
      "23/23 [==============================] - 4s 114ms/step - loss: -7.8900 - val_loss: -7.7346\n",
      "Epoch 2/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -7.9944 - val_loss: -7.6563\n",
      "Epoch 3/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -7.9769 - val_loss: -7.6996\n",
      "Epoch 4/5000\n",
      "23/23 [==============================] - 2s 78ms/step - loss: -7.9934 - val_loss: -7.6917\n",
      "Epoch 5/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -7.9413 - val_loss: -7.7356\n",
      "Epoch 6/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -7.8925 - val_loss: -7.7178\n",
      "Epoch 7/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -7.8636 - val_loss: -7.7445\n",
      "Epoch 8/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -7.9511 - val_loss: -7.7303\n",
      "Epoch 9/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -7.9822 - val_loss: -7.7134\n",
      "Epoch 10/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -7.9197 - val_loss: -7.7324\n",
      "Epoch 11/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -7.8986 - val_loss: -7.6831\n",
      "Epoch 12/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -7.8913 - val_loss: -7.7227\n",
      "Epoch 13/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -7.8441 - val_loss: -7.6416\n",
      "Epoch 14/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -7.8865 - val_loss: -7.7384\n",
      "Epoch 15/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -7.8370 - val_loss: -7.7395\n",
      "Epoch 16/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -7.9208 - val_loss: -7.7310\n",
      "Epoch 17/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -7.9519 - val_loss: -7.7441\n",
      "Epoch 18/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -7.8867 - val_loss: -7.7366\n",
      "Epoch 19/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -7.8515 - val_loss: -7.7615\n",
      "Epoch 20/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -7.8647 - val_loss: -7.7362\n",
      "Epoch 21/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -7.8405 - val_loss: -7.7296\n",
      "Epoch 22/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -7.9638 - val_loss: -7.7642\n",
      "Epoch 23/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -7.9028 - val_loss: -7.7472\n",
      "Epoch 24/5000\n",
      "23/23 [==============================] - 2s 80ms/step - loss: -7.9783 - val_loss: -7.7161\n",
      "Epoch 25/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -7.9888 - val_loss: -7.7581\n",
      "Epoch 26/5000\n",
      "23/23 [==============================] - 4s 166ms/step - loss: -7.9477 - val_loss: -7.7552\n",
      "Epoch 27/5000\n",
      "23/23 [==============================] - 4s 182ms/step - loss: -7.9411 - val_loss: -7.7532\n",
      "Epoch 28/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -7.8608 - val_loss: -7.7262\n",
      "Epoch 29/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -7.8800 - val_loss: -7.7595\n",
      "Epoch 30/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -7.9327 - val_loss: -7.7146\n",
      "Epoch 31/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -7.9681 - val_loss: -7.7481\n",
      "Epoch 32/5000\n",
      "23/23 [==============================] - 3s 131ms/step - loss: -7.8746 - val_loss: -7.7543\n",
      "Epoch 33/5000\n",
      "23/23 [==============================] - 5s 247ms/step - loss: -7.9926 - val_loss: -7.7621\n",
      "Epoch 34/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -7.9088 - val_loss: -7.7691\n",
      "Epoch 35/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -7.9502 - val_loss: -7.7558\n",
      "Epoch 36/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -7.9708 - val_loss: -7.7682\n",
      "Epoch 37/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -7.9524 - val_loss: -7.7611\n",
      "Epoch 38/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -7.9737 - val_loss: -7.7696\n",
      "Epoch 39/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -7.9277 - val_loss: -7.7696\n",
      "Epoch 40/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -7.9385 - val_loss: -7.7640\n",
      "Epoch 41/5000\n",
      "23/23 [==============================] - 3s 139ms/step - loss: -8.0028 - val_loss: -7.7882\n",
      "Epoch 42/5000\n",
      "23/23 [==============================] - 5s 209ms/step - loss: -7.9444 - val_loss: -7.7778\n",
      "Epoch 43/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -7.9800 - val_loss: -7.7415\n",
      "Epoch 44/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -7.9468 - val_loss: -7.7708\n",
      "Epoch 45/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -7.9617 - val_loss: -7.7651\n",
      "Epoch 46/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -7.8621 - val_loss: -7.7770\n",
      "Epoch 47/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -7.9968 - val_loss: -7.7935\n",
      "Epoch 48/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -7.9168 - val_loss: -7.6725\n",
      "Epoch 49/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -7.9915 - val_loss: -7.7730\n",
      "Epoch 50/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.0241 - val_loss: -7.7998\n",
      "Epoch 51/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -7.9706 - val_loss: -7.7842\n",
      "Epoch 52/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -7.9433 - val_loss: -7.7926\n",
      "Epoch 53/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -7.9720 - val_loss: -7.7822\n",
      "Epoch 54/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -7.9722 - val_loss: -7.7323\n",
      "Epoch 55/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -7.9941 - val_loss: -7.7962\n",
      "Epoch 56/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -7.9449 - val_loss: -7.7955\n",
      "Epoch 57/5000\n",
      "23/23 [==============================] - 2s 80ms/step - loss: -8.0083 - val_loss: -7.7762\n",
      "Epoch 58/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -7.9080 - val_loss: -7.7961\n",
      "Epoch 59/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -7.9927 - val_loss: -7.7323\n",
      "Epoch 60/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -7.9799 - val_loss: -7.7823\n",
      "Epoch 61/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -7.9752 - val_loss: -7.8138\n",
      "Epoch 62/5000\n",
      "23/23 [==============================] - 6s 266ms/step - loss: -7.8473 - val_loss: -7.8207\n",
      "Epoch 63/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.0478 - val_loss: -7.8174\n",
      "Epoch 64/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -7.9833 - val_loss: -7.8143\n",
      "Epoch 65/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.0353 - val_loss: -7.8173\n",
      "Epoch 66/5000\n",
      "23/23 [==============================] - 3s 136ms/step - loss: -8.0224 - val_loss: -7.7758\n",
      "Epoch 67/5000\n",
      "23/23 [==============================] - 6s 261ms/step - loss: -8.0417 - val_loss: -7.7513\n",
      "Epoch 68/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -7.9090 - val_loss: -7.7910\n",
      "Epoch 69/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -7.9414 - val_loss: -7.8357\n",
      "Epoch 70/5000\n",
      "23/23 [==============================] - 2s 78ms/step - loss: -7.9734 - val_loss: -7.7820\n",
      "Epoch 71/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -7.9613 - val_loss: -7.7996\n",
      "Epoch 72/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -8.0547 - val_loss: -7.8309\n",
      "Epoch 73/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -8.0269 - val_loss: -7.7874\n",
      "Epoch 74/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -8.0508 - val_loss: -7.8160\n",
      "Epoch 75/5000\n",
      "23/23 [==============================] - 6s 263ms/step - loss: -7.9854 - val_loss: -7.8346\n",
      "Epoch 76/5000\n",
      "23/23 [==============================] - 6s 261ms/step - loss: -8.0113 - val_loss: -7.8033\n",
      "Epoch 77/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.0260 - val_loss: -7.8174\n",
      "Epoch 78/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -8.0183 - val_loss: -7.8393\n",
      "Epoch 79/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -7.9720 - val_loss: -7.8356\n",
      "Epoch 80/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -8.0157 - val_loss: -7.8377\n",
      "Epoch 81/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -8.0291 - val_loss: -7.8469\n",
      "Epoch 82/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -7.9800 - val_loss: -7.8660\n",
      "Epoch 83/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.0163 - val_loss: -7.8324\n",
      "Epoch 84/5000\n",
      "23/23 [==============================] - 2s 81ms/step - loss: -8.0057 - val_loss: -7.7801\n",
      "Epoch 85/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -8.0311 - val_loss: -7.8398\n",
      "Epoch 86/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.0229 - val_loss: -7.8424\n",
      "Epoch 87/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -7.9855 - val_loss: -7.8496\n",
      "Epoch 88/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -8.0327 - val_loss: -7.8180\n",
      "Epoch 89/5000\n",
      "23/23 [==============================] - 2s 80ms/step - loss: -8.0501 - val_loss: -7.8332\n",
      "Epoch 90/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -8.0441 - val_loss: -7.8589\n",
      "Epoch 91/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.0838 - val_loss: -7.8651\n",
      "Epoch 92/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -8.0914 - val_loss: -7.8439\n",
      "Epoch 93/5000\n",
      "23/23 [==============================] - 5s 219ms/step - loss: -8.0156 - val_loss: -7.8364\n",
      "Epoch 94/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -8.0017 - val_loss: -7.8292\n",
      "Epoch 95/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -8.0367 - val_loss: -7.8362\n",
      "Epoch 96/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -8.0097 - val_loss: -7.8664\n",
      "Epoch 97/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.0019 - val_loss: -7.8447\n",
      "Epoch 98/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -7.9919 - val_loss: -7.8477\n",
      "Epoch 99/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -8.0030 - val_loss: -7.8713\n",
      "Epoch 100/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.0379 - val_loss: -7.8363\n",
      "Epoch 101/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -7.9996 - val_loss: -7.8545\n",
      "Epoch 102/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -8.0668 - val_loss: -7.8509\n",
      "Epoch 103/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -7.8893 - val_loss: -7.8486\n",
      "Epoch 104/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.1147 - val_loss: -7.8852\n",
      "Epoch 105/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.1092 - val_loss: -7.8732\n",
      "Epoch 106/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -8.0333 - val_loss: -7.8539\n",
      "Epoch 107/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -8.0549 - val_loss: -7.7733\n",
      "Epoch 108/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.0500 - val_loss: -7.8873\n",
      "Epoch 109/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -8.0245 - val_loss: -7.8741\n",
      "Epoch 110/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -8.0240 - val_loss: -7.8652\n",
      "Epoch 111/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -8.0051 - val_loss: -7.8271\n",
      "Epoch 112/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.1474 - val_loss: -7.8874\n",
      "Epoch 113/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -8.1039 - val_loss: -7.8776\n",
      "Epoch 114/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -7.9936 - val_loss: -7.8995\n",
      "Epoch 115/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.1347 - val_loss: -7.8744\n",
      "Epoch 116/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -8.0943 - val_loss: -7.8660\n",
      "Epoch 117/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.0271 - val_loss: -7.8990\n",
      "Epoch 118/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -7.9585 - val_loss: -7.8869\n",
      "Epoch 119/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -8.1331 - val_loss: -7.9028\n",
      "Epoch 120/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -8.0639 - val_loss: -7.8605\n",
      "Epoch 121/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -8.1066 - val_loss: -7.8751\n",
      "Epoch 122/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.0707 - val_loss: -7.8737\n",
      "Epoch 123/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.1080 - val_loss: -7.8562\n",
      "Epoch 124/5000\n",
      "23/23 [==============================] - 2s 112ms/step - loss: -8.0597 - val_loss: -7.8939\n",
      "Epoch 125/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -8.0310 - val_loss: -7.8904\n",
      "Epoch 126/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -7.9914 - val_loss: -7.8445\n",
      "Epoch 127/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -8.0836 - val_loss: -7.9162\n",
      "Epoch 128/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.1108 - val_loss: -7.9082\n",
      "Epoch 129/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -8.0603 - val_loss: -7.8286\n",
      "Epoch 130/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -8.0642 - val_loss: -7.9058\n",
      "Epoch 131/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -8.0442 - val_loss: -7.8926\n",
      "Epoch 132/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.0594 - val_loss: -7.8971\n",
      "Epoch 133/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.0984 - val_loss: -7.9089\n",
      "Epoch 134/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -8.1462 - val_loss: -7.8973\n",
      "Epoch 135/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.0982 - val_loss: -7.9103\n",
      "Epoch 136/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.0662 - val_loss: -7.9131\n",
      "Epoch 137/5000\n",
      "23/23 [==============================] - 3s 132ms/step - loss: -8.0829 - val_loss: -7.9174\n",
      "Epoch 138/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.1543 - val_loss: -7.8204\n",
      "Epoch 139/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -8.1630 - val_loss: -7.9312\n",
      "Epoch 140/5000\n",
      "23/23 [==============================] - 2s 79ms/step - loss: -8.1146 - val_loss: -7.9217\n",
      "Epoch 141/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -8.1052 - val_loss: -7.9014\n",
      "Epoch 142/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.1015 - val_loss: -7.9321\n",
      "Epoch 143/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -8.1494 - val_loss: -7.6258\n",
      "Epoch 144/5000\n",
      "23/23 [==============================] - 6s 264ms/step - loss: -8.0897 - val_loss: -7.8986\n",
      "Epoch 145/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -8.1293 - val_loss: -7.8882\n",
      "Epoch 146/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.1455 - val_loss: -7.9181\n",
      "Epoch 147/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -8.1258 - val_loss: -7.8880\n",
      "Epoch 148/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -8.0239 - val_loss: -7.9079\n",
      "Epoch 149/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -8.1074 - val_loss: -7.9032\n",
      "Epoch 150/5000\n",
      "23/23 [==============================] - 6s 272ms/step - loss: -8.1804 - val_loss: -7.9485\n",
      "Epoch 151/5000\n",
      "23/23 [==============================] - 4s 185ms/step - loss: -8.1363 - val_loss: -7.8912\n",
      "Epoch 152/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -8.1331 - val_loss: -7.9264\n",
      "Epoch 153/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.0874 - val_loss: -7.9297\n",
      "Epoch 154/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.0869 - val_loss: -7.6954\n",
      "Epoch 155/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -8.2204 - val_loss: -7.9577\n",
      "Epoch 156/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.0692 - val_loss: -7.9234\n",
      "Epoch 157/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.1258 - val_loss: -7.9071\n",
      "Epoch 158/5000\n",
      "23/23 [==============================] - 2s 81ms/step - loss: -8.1297 - val_loss: -7.8886\n",
      "Epoch 159/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.0396 - val_loss: -7.9422\n",
      "Epoch 160/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -8.0892 - val_loss: -7.9503\n",
      "Epoch 161/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.0940 - val_loss: -7.8939\n",
      "Epoch 162/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -8.1663 - val_loss: -7.9543\n",
      "Epoch 163/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -8.1475 - val_loss: -7.9151\n",
      "Epoch 164/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.1217 - val_loss: -7.9772\n",
      "Epoch 165/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.1310 - val_loss: -7.9641\n",
      "Epoch 166/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -8.1778 - val_loss: -7.9652\n",
      "Epoch 167/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -8.1350 - val_loss: -7.9502\n",
      "Epoch 168/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -8.0954 - val_loss: -7.9372\n",
      "Epoch 169/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.1246 - val_loss: -7.9547\n",
      "Epoch 170/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -8.1161 - val_loss: -7.9779\n",
      "Epoch 171/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -8.1636 - val_loss: -7.9756\n",
      "Epoch 172/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -8.1205 - val_loss: -7.9442\n",
      "Epoch 173/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.1245 - val_loss: -7.9630\n",
      "Epoch 174/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -8.0125 - val_loss: -7.9895\n",
      "Epoch 175/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -8.1809 - val_loss: -7.9584\n",
      "Epoch 176/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.1566 - val_loss: -7.9547\n",
      "Epoch 177/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -8.1394 - val_loss: -7.9963\n",
      "Epoch 178/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -8.1331 - val_loss: -7.9665\n",
      "Epoch 179/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -8.2115 - val_loss: -7.9627\n",
      "Epoch 180/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.1553 - val_loss: -7.9754\n",
      "Epoch 181/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -8.1519 - val_loss: -7.9753\n",
      "Epoch 182/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -8.1256 - val_loss: -7.9992\n",
      "Epoch 183/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.1533 - val_loss: -7.9601\n",
      "Epoch 184/5000\n",
      "23/23 [==============================] - 2s 79ms/step - loss: -8.1262 - val_loss: -7.9758\n",
      "Epoch 185/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -7.8312 - val_loss: -7.9812\n",
      "Epoch 186/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.1255 - val_loss: -7.9794\n",
      "Epoch 187/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -8.1825 - val_loss: -7.2130\n",
      "Epoch 188/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.1660 - val_loss: -7.9876\n",
      "Epoch 189/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -8.2034 - val_loss: -7.9988\n",
      "Epoch 190/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.2056 - val_loss: -7.9695\n",
      "Epoch 191/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -8.1216 - val_loss: -7.9620\n",
      "Epoch 192/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.0948 - val_loss: -7.9847\n",
      "Epoch 193/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -8.2387 - val_loss: -7.9762\n",
      "Epoch 194/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.1896 - val_loss: -7.9725\n",
      "Epoch 195/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -8.1099 - val_loss: -7.9920\n",
      "Epoch 196/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.1865 - val_loss: -7.9886\n",
      "Epoch 197/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -8.2209 - val_loss: -7.9973\n",
      "Epoch 198/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.2402 - val_loss: -7.6500\n",
      "Epoch 199/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -8.1658 - val_loss: -7.9871\n",
      "Epoch 200/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.1360 - val_loss: -7.9945\n",
      "Epoch 201/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -8.1754 - val_loss: -8.0211\n",
      "Epoch 202/5000\n",
      "23/23 [==============================] - 2s 76ms/step - loss: -8.1759 - val_loss: -7.9927\n",
      "Epoch 203/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.1832 - val_loss: -7.9902\n",
      "Epoch 204/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.1533 - val_loss: -8.0002\n",
      "Epoch 205/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -8.1591 - val_loss: -7.9836\n",
      "Epoch 206/5000\n",
      "23/23 [==============================] - 4s 201ms/step - loss: -8.2351 - val_loss: -7.9900\n",
      "Epoch 207/5000\n",
      "23/23 [==============================] - 5s 208ms/step - loss: -8.1891 - val_loss: -8.0048\n",
      "Epoch 208/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -8.2438 - val_loss: -7.9971\n",
      "Epoch 209/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.1780 - val_loss: -8.0119\n",
      "Epoch 210/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -8.1915 - val_loss: -7.9788\n",
      "Epoch 211/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.2089 - val_loss: -7.9992\n",
      "Epoch 212/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -8.1812 - val_loss: -7.9458\n",
      "Epoch 213/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -8.2117 - val_loss: -8.0215\n",
      "Epoch 214/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -8.1950 - val_loss: -7.9721\n",
      "Epoch 215/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -8.1343 - val_loss: -8.0079\n",
      "Epoch 216/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -8.1554 - val_loss: -8.0070\n",
      "Epoch 217/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.1898 - val_loss: -8.0123\n",
      "Epoch 218/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -8.1346 - val_loss: -8.0381\n",
      "Epoch 219/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -8.2066 - val_loss: -8.0005\n",
      "Epoch 220/5000\n",
      "23/23 [==============================] - 2s 80ms/step - loss: -8.2154 - val_loss: -8.0004\n",
      "Epoch 221/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -8.1869 - val_loss: -7.5850\n",
      "Epoch 222/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.1623 - val_loss: -8.0257\n",
      "Epoch 223/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.1078 - val_loss: -8.0558\n",
      "Epoch 224/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.2456 - val_loss: -8.0296\n",
      "Epoch 225/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -8.2623 - val_loss: -8.0231\n",
      "Epoch 226/5000\n",
      "23/23 [==============================] - 5s 233ms/step - loss: -8.1722 - val_loss: -8.0170\n",
      "Epoch 227/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -8.2125 - val_loss: -8.0377\n",
      "Epoch 228/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.2299 - val_loss: -8.0257\n",
      "Epoch 229/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -8.1866 - val_loss: -8.0263\n",
      "Epoch 230/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -8.1755 - val_loss: -8.0282\n",
      "Epoch 231/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.2315 - val_loss: -8.0454\n",
      "Epoch 232/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.2461 - val_loss: -8.0360\n",
      "Epoch 233/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -8.1678 - val_loss: -7.9880\n",
      "Epoch 234/5000\n",
      "23/23 [==============================] - 4s 168ms/step - loss: -8.2056 - val_loss: -8.0320\n",
      "Epoch 235/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -8.2552 - val_loss: -8.0032\n",
      "Epoch 236/5000\n",
      "23/23 [==============================] - 5s 239ms/step - loss: -8.2196 - val_loss: -8.0344\n",
      "Epoch 237/5000\n",
      "23/23 [==============================] - 3s 150ms/step - loss: -8.1469 - val_loss: -8.0123\n",
      "Epoch 238/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -8.2421 - val_loss: -8.0315\n",
      "Epoch 239/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -8.2548 - val_loss: -8.0293\n",
      "Epoch 240/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -8.2404 - val_loss: -8.0151\n",
      "Epoch 241/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.1866 - val_loss: -8.0083\n",
      "Epoch 242/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -8.2573 - val_loss: -8.0410\n",
      "Epoch 243/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -8.1333 - val_loss: -8.0260\n",
      "Epoch 244/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -8.2779 - val_loss: -8.0424\n",
      "Epoch 245/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.2085 - val_loss: -8.0598\n",
      "Epoch 246/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.2270 - val_loss: -8.0136\n",
      "Epoch 247/5000\n",
      "23/23 [==============================] - 3s 156ms/step - loss: -8.2843 - val_loss: -8.0427\n",
      "Epoch 248/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -8.2660 - val_loss: -8.0390\n",
      "Epoch 249/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -8.1281 - val_loss: -8.0415\n",
      "Epoch 250/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.2406 - val_loss: -8.0631\n",
      "Epoch 251/5000\n",
      "23/23 [==============================] - 2s 112ms/step - loss: -8.2368 - val_loss: -8.0569\n",
      "Epoch 252/5000\n",
      "23/23 [==============================] - 6s 267ms/step - loss: -8.2560 - val_loss: -8.0726\n",
      "Epoch 253/5000\n",
      "23/23 [==============================] - 5s 223ms/step - loss: -8.2530 - val_loss: -8.0652\n",
      "Epoch 254/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.2195 - val_loss: -8.0572\n",
      "Epoch 255/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -8.1962 - val_loss: -8.0124\n",
      "Epoch 256/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -8.2395 - val_loss: -7.9875\n",
      "Epoch 257/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -8.2187 - val_loss: -8.0509\n",
      "Epoch 258/5000\n",
      "23/23 [==============================] - 5s 209ms/step - loss: -8.2838 - val_loss: -8.0473\n",
      "Epoch 259/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -8.3249 - val_loss: -8.0357\n",
      "Epoch 260/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -8.2653 - val_loss: -8.0720\n",
      "Epoch 261/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -8.2453 - val_loss: -8.0515\n",
      "Epoch 262/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -8.2834 - val_loss: -8.0624\n",
      "Epoch 263/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -8.2263 - val_loss: -8.0582\n",
      "Epoch 264/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.3210 - val_loss: -7.4644\n",
      "Epoch 265/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.2467 - val_loss: -7.4698\n",
      "Epoch 266/5000\n",
      "23/23 [==============================] - 2s 74ms/step - loss: -8.2674 - val_loss: -8.0185\n",
      "Epoch 267/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -8.2483 - val_loss: -8.0773\n",
      "Epoch 268/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.2706 - val_loss: -8.0694\n",
      "Epoch 269/5000\n",
      "23/23 [==============================] - 3s 121ms/step - loss: -8.2591 - val_loss: -8.0259\n",
      "Epoch 270/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -8.2430 - val_loss: -8.0632\n",
      "Epoch 271/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -8.2192 - val_loss: -8.0369\n",
      "Epoch 272/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.2917 - val_loss: -8.0474\n",
      "Epoch 273/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.2485 - val_loss: -8.0667\n",
      "Epoch 274/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -8.2498 - val_loss: -8.0460\n",
      "Epoch 275/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -8.2786 - val_loss: -8.0619\n",
      "Epoch 276/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.2473 - val_loss: -8.0661\n",
      "Epoch 277/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -8.2153 - val_loss: -8.0656\n",
      "Epoch 278/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -8.2469 - val_loss: -8.0897\n",
      "Epoch 279/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.3528 - val_loss: -8.0502\n",
      "Epoch 280/5000\n",
      "23/23 [==============================] - 4s 168ms/step - loss: -8.2819 - val_loss: -8.0841\n",
      "Epoch 281/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.3155 - val_loss: -8.0829\n",
      "Epoch 282/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.3040 - val_loss: -8.0589\n",
      "Epoch 283/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -8.2161 - val_loss: -8.0913\n",
      "Epoch 284/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.2833 - val_loss: -8.0736\n",
      "Epoch 285/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -8.2498 - val_loss: -8.1236\n",
      "Epoch 286/5000\n",
      "23/23 [==============================] - 6s 268ms/step - loss: -8.3272 - val_loss: -8.0906\n",
      "Epoch 287/5000\n",
      "23/23 [==============================] - 2s 104ms/step - loss: -8.2458 - val_loss: -8.0884\n",
      "Epoch 288/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.2459 - val_loss: -8.0929\n",
      "Epoch 289/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -8.1992 - val_loss: -8.0945\n",
      "Epoch 290/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -8.1724 - val_loss: -8.0997\n",
      "Epoch 291/5000\n",
      "23/23 [==============================] - 2s 79ms/step - loss: -8.2981 - val_loss: -8.0760\n",
      "Epoch 292/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.2752 - val_loss: -8.0899\n",
      "Epoch 293/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.2515 - val_loss: -8.1199\n",
      "Epoch 294/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.2878 - val_loss: -8.1035\n",
      "Epoch 295/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.2624 - val_loss: -8.1153\n",
      "Epoch 296/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.2790 - val_loss: -8.0532\n",
      "Epoch 297/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -8.2473 - val_loss: -8.0845\n",
      "Epoch 298/5000\n",
      "23/23 [==============================] - 6s 266ms/step - loss: -8.2958 - val_loss: -8.0994\n",
      "Epoch 299/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -8.2304 - val_loss: -8.1342\n",
      "Epoch 300/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -8.3414 - val_loss: -7.9793\n",
      "Epoch 301/5000\n",
      "23/23 [==============================] - 3s 135ms/step - loss: -8.2976 - val_loss: -8.0979\n",
      "Epoch 302/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -8.3221 - val_loss: -8.0947\n",
      "Epoch 303/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.2813 - val_loss: -8.0742\n",
      "Epoch 304/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.3257 - val_loss: -8.1194\n",
      "Epoch 305/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.2013 - val_loss: -8.1138\n",
      "Epoch 306/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -8.2900 - val_loss: -8.0974\n",
      "Epoch 307/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -8.2459 - val_loss: -8.0951\n",
      "Epoch 308/5000\n",
      "23/23 [==============================] - 2s 108ms/step - loss: -8.2901 - val_loss: -8.1068\n",
      "Epoch 309/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.3114 - val_loss: -8.1075\n",
      "Epoch 310/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.2751 - val_loss: -8.1245\n",
      "Epoch 311/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -8.3105 - val_loss: -8.0941\n",
      "Epoch 312/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.2746 - val_loss: -8.1224\n",
      "Epoch 313/5000\n",
      "23/23 [==============================] - 5s 227ms/step - loss: -8.3380 - val_loss: -8.1278\n",
      "Epoch 314/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -8.3416 - val_loss: -8.1271\n",
      "Epoch 315/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.3536 - val_loss: -8.1202\n",
      "Epoch 316/5000\n",
      "23/23 [==============================] - 3s 121ms/step - loss: -8.3338 - val_loss: -8.1357\n",
      "Epoch 317/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -8.2875 - val_loss: -8.0953\n",
      "Epoch 318/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.3135 - val_loss: -8.0894\n",
      "Epoch 319/5000\n",
      "23/23 [==============================] - 2s 110ms/step - loss: -8.2532 - val_loss: -8.1053\n",
      "Epoch 320/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -8.3595 - val_loss: -8.1260\n",
      "Epoch 321/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -8.2835 - val_loss: -8.0427\n",
      "Epoch 322/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.2770 - val_loss: -8.1158\n",
      "Epoch 323/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.2612 - val_loss: -8.1341\n",
      "Epoch 324/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -8.3111 - val_loss: -8.1298\n",
      "Epoch 325/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -8.3112 - val_loss: -8.0886\n",
      "Epoch 326/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -8.1491 - val_loss: -8.1472\n",
      "Epoch 327/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.3164 - val_loss: -8.0473\n",
      "Epoch 328/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.1851 - val_loss: -8.1518\n",
      "Epoch 329/5000\n",
      "23/23 [==============================] - 3s 132ms/step - loss: -8.3501 - val_loss: -8.1443\n",
      "Epoch 330/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -8.3257 - val_loss: -8.0847\n",
      "Epoch 331/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.1989 - val_loss: -8.1584\n",
      "Epoch 332/5000\n",
      "23/23 [==============================] - 3s 121ms/step - loss: -8.2566 - val_loss: -8.1298\n",
      "Epoch 333/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -8.3291 - val_loss: -8.1166\n",
      "Epoch 334/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.2464 - val_loss: -8.1492\n",
      "Epoch 335/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -8.3007 - val_loss: -8.1355\n",
      "Epoch 336/5000\n",
      "23/23 [==============================] - 2s 81ms/step - loss: -8.3690 - val_loss: -8.1516\n",
      "Epoch 337/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -8.3158 - val_loss: -8.1388\n",
      "Epoch 338/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.3000 - val_loss: -8.1456\n",
      "Epoch 339/5000\n",
      "23/23 [==============================] - 2s 113ms/step - loss: -8.3655 - val_loss: -8.1668\n",
      "Epoch 340/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.3083 - val_loss: -8.1565\n",
      "Epoch 341/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.3367 - val_loss: -8.1431\n",
      "Epoch 342/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -8.3380 - val_loss: -8.1586\n",
      "Epoch 343/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -8.3543 - val_loss: -8.1515\n",
      "Epoch 344/5000\n",
      "23/23 [==============================] - 3s 116ms/step - loss: -8.2518 - val_loss: -8.1115\n",
      "Epoch 345/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -8.2685 - val_loss: -8.0095\n",
      "Epoch 346/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -8.3153 - val_loss: -8.1292\n",
      "Epoch 347/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -8.3332 - val_loss: -8.1798\n",
      "Epoch 348/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.3096 - val_loss: -8.1282\n",
      "Epoch 349/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -8.2986 - val_loss: -8.1701\n",
      "Epoch 350/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -8.3361 - val_loss: -8.1326\n",
      "Epoch 351/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -8.3720 - val_loss: -8.1411\n",
      "Epoch 352/5000\n",
      "23/23 [==============================] - 6s 258ms/step - loss: -8.3204 - val_loss: -8.1519\n",
      "Epoch 353/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.2702 - val_loss: -8.1726\n",
      "Epoch 354/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.3702 - val_loss: -8.1502\n",
      "Epoch 355/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -8.3904 - val_loss: -8.1727\n",
      "Epoch 356/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -8.3787 - val_loss: -8.1845\n",
      "Epoch 357/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -8.3556 - val_loss: -8.1834\n",
      "Epoch 358/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -8.3778 - val_loss: -8.1484\n",
      "Epoch 359/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -8.3711 - val_loss: -8.1710\n",
      "Epoch 360/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.3680 - val_loss: -8.1448\n",
      "Epoch 361/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.3141 - val_loss: -8.1714\n",
      "Epoch 362/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -8.2700 - val_loss: -8.1956\n",
      "Epoch 363/5000\n",
      "23/23 [==============================] - 2s 104ms/step - loss: -8.3531 - val_loss: -8.1966\n",
      "Epoch 364/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -8.2179 - val_loss: -8.1904\n",
      "Epoch 365/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -8.3988 - val_loss: -8.1913\n",
      "Epoch 366/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -8.3492 - val_loss: -7.8295\n",
      "Epoch 367/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.4167 - val_loss: -8.1831\n",
      "Epoch 368/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.2960 - val_loss: -8.1810\n",
      "Epoch 369/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -8.4027 - val_loss: -8.1857\n",
      "Epoch 370/5000\n",
      "23/23 [==============================] - 2s 81ms/step - loss: -8.4045 - val_loss: -8.1255\n",
      "Epoch 371/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.3655 - val_loss: -8.1750\n",
      "Epoch 372/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.3667 - val_loss: -8.1967\n",
      "Epoch 373/5000\n",
      "23/23 [==============================] - 2s 80ms/step - loss: -8.4147 - val_loss: -8.1915\n",
      "Epoch 374/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -8.3611 - val_loss: -8.2036\n",
      "Epoch 375/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -8.3342 - val_loss: -8.1960\n",
      "Epoch 376/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -8.3696 - val_loss: -8.1912\n",
      "Epoch 377/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -8.4040 - val_loss: -8.1805\n",
      "Epoch 378/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.3720 - val_loss: -8.1494\n",
      "Epoch 379/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -8.3487 - val_loss: -8.2063\n",
      "Epoch 380/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -8.3504 - val_loss: -8.2082\n",
      "Epoch 381/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -8.3423 - val_loss: -8.2037\n",
      "Epoch 382/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -8.3934 - val_loss: -8.2100\n",
      "Epoch 383/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -8.4311 - val_loss: -8.1961\n",
      "Epoch 384/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -8.3051 - val_loss: -8.1929\n",
      "Epoch 385/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.3956 - val_loss: -8.2053\n",
      "Epoch 386/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.3495 - val_loss: -8.2053\n",
      "Epoch 387/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -8.3838 - val_loss: -8.2095\n",
      "Epoch 388/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -8.3784 - val_loss: -8.2241\n",
      "Epoch 389/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.4407 - val_loss: -8.2122\n",
      "Epoch 390/5000\n",
      "23/23 [==============================] - 2s 81ms/step - loss: -8.2988 - val_loss: -8.2080\n",
      "Epoch 391/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -8.4411 - val_loss: -8.2206\n",
      "Epoch 392/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -8.4165 - val_loss: -8.1305\n",
      "Epoch 393/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.3912 - val_loss: -8.2091\n",
      "Epoch 394/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -8.3874 - val_loss: -8.2049\n",
      "Epoch 395/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -8.3765 - val_loss: -8.2097\n",
      "Epoch 396/5000\n",
      "23/23 [==============================] - 4s 193ms/step - loss: -8.4779 - val_loss: -8.1702\n",
      "Epoch 397/5000\n",
      "23/23 [==============================] - 4s 161ms/step - loss: -8.3969 - val_loss: -7.9377\n",
      "Epoch 398/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -8.3848 - val_loss: -8.2250\n",
      "Epoch 399/5000\n",
      "23/23 [==============================] - 5s 219ms/step - loss: -8.4462 - val_loss: -8.2131\n",
      "Epoch 400/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.3752 - val_loss: -8.2170\n",
      "Epoch 401/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -8.3725 - val_loss: -8.2189\n",
      "Epoch 402/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -8.4554 - val_loss: -8.2142\n",
      "Epoch 403/5000\n",
      "23/23 [==============================] - 4s 173ms/step - loss: -8.3917 - val_loss: -8.2291\n",
      "Epoch 404/5000\n",
      "23/23 [==============================] - 2s 79ms/step - loss: -8.3774 - val_loss: -8.2075\n",
      "Epoch 405/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.3656 - val_loss: -8.2370\n",
      "Epoch 406/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -8.4163 - val_loss: -8.1438\n",
      "Epoch 407/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -8.4302 - val_loss: -8.2146\n",
      "Epoch 408/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -8.3879 - val_loss: -8.2191\n",
      "Epoch 409/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.4256 - val_loss: -8.2497\n",
      "Epoch 410/5000\n",
      "23/23 [==============================] - 4s 166ms/step - loss: -8.4040 - val_loss: -8.2137\n",
      "Epoch 411/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -8.3812 - val_loss: -8.2464\n",
      "Epoch 412/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.4438 - val_loss: -8.1278\n",
      "Epoch 413/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.4253 - val_loss: -8.2492\n",
      "Epoch 414/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -8.3914 - val_loss: -8.2469\n",
      "Epoch 415/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.4003 - val_loss: -8.2380\n",
      "Epoch 416/5000\n",
      "23/23 [==============================] - 4s 163ms/step - loss: -8.4183 - val_loss: -8.2410\n",
      "Epoch 417/5000\n",
      "23/23 [==============================] - 6s 261ms/step - loss: -8.3909 - val_loss: -8.2465\n",
      "Epoch 418/5000\n",
      "23/23 [==============================] - 6s 264ms/step - loss: -8.3363 - val_loss: -8.2340\n",
      "Epoch 419/5000\n",
      "23/23 [==============================] - 6s 263ms/step - loss: -8.4212 - val_loss: -8.2370\n",
      "Epoch 420/5000\n",
      "23/23 [==============================] - 6s 263ms/step - loss: -8.4813 - val_loss: -8.2417\n",
      "Epoch 421/5000\n",
      "23/23 [==============================] - 2s 104ms/step - loss: -8.4247 - val_loss: -8.1996\n",
      "Epoch 422/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -8.4538 - val_loss: -8.2586\n",
      "Epoch 423/5000\n",
      "23/23 [==============================] - 6s 265ms/step - loss: -8.3467 - val_loss: -8.2574\n",
      "Epoch 424/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -8.4762 - val_loss: -8.2422\n",
      "Epoch 425/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -8.4827 - val_loss: -8.2503\n",
      "Epoch 426/5000\n",
      "23/23 [==============================] - 2s 80ms/step - loss: -8.4395 - val_loss: -8.2512\n",
      "Epoch 427/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.4367 - val_loss: -8.2343\n",
      "Epoch 428/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -8.4509 - val_loss: -8.2419\n",
      "Epoch 429/5000\n",
      "23/23 [==============================] - 2s 81ms/step - loss: -8.3323 - val_loss: -8.2568\n",
      "Epoch 430/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -8.4129 - val_loss: -8.2232\n",
      "Epoch 431/5000\n",
      "23/23 [==============================] - 6s 266ms/step - loss: -8.4200 - val_loss: -8.2690\n",
      "Epoch 432/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.3954 - val_loss: -8.2435\n",
      "Epoch 433/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -8.3659 - val_loss: -8.2786\n",
      "Epoch 434/5000\n",
      "23/23 [==============================] - 3s 121ms/step - loss: -8.4248 - val_loss: -8.2572\n",
      "Epoch 435/5000\n",
      "23/23 [==============================] - 2s 104ms/step - loss: -8.4549 - val_loss: -8.2529\n",
      "Epoch 436/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.4744 - val_loss: -8.2144\n",
      "Epoch 437/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -8.4434 - val_loss: -8.2540\n",
      "Epoch 438/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.3721 - val_loss: -8.2382\n",
      "Epoch 439/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -8.3908 - val_loss: -8.2411\n",
      "Epoch 440/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -8.4763 - val_loss: -8.2005\n",
      "Epoch 441/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -8.4943 - val_loss: -8.2593\n",
      "Epoch 442/5000\n",
      "23/23 [==============================] - 2s 81ms/step - loss: -8.4823 - val_loss: -8.2765\n",
      "Epoch 443/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.4991 - val_loss: -8.2576\n",
      "Epoch 444/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -8.4786 - val_loss: -8.2730\n",
      "Epoch 445/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -8.4148 - val_loss: -8.2756\n",
      "Epoch 446/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -8.4721 - val_loss: -8.2448\n",
      "Epoch 447/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.4440 - val_loss: -8.2515\n",
      "Epoch 448/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.4532 - val_loss: -8.2732\n",
      "Epoch 449/5000\n",
      "23/23 [==============================] - 5s 245ms/step - loss: -8.4934 - val_loss: -7.8889\n",
      "Epoch 450/5000\n",
      "23/23 [==============================] - 3s 116ms/step - loss: -8.4296 - val_loss: -8.2897\n",
      "Epoch 451/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -8.4596 - val_loss: -8.2654\n",
      "Epoch 452/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -8.4955 - val_loss: -8.0986\n",
      "Epoch 453/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -8.4749 - val_loss: -8.2698\n",
      "Epoch 454/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.5107 - val_loss: -8.2759\n",
      "Epoch 455/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -8.4650 - val_loss: -8.2747\n",
      "Epoch 456/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.5006 - val_loss: -8.2691\n",
      "Epoch 457/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -8.3308 - val_loss: -8.2937\n",
      "Epoch 458/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -8.3899 - val_loss: -8.2792\n",
      "Epoch 459/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -8.4653 - val_loss: -8.2895\n",
      "Epoch 460/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -8.4863 - val_loss: -8.2755\n",
      "Epoch 461/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -8.4958 - val_loss: -8.2895\n",
      "Epoch 462/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -8.4869 - val_loss: -8.2948\n",
      "Epoch 463/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.3867 - val_loss: -8.3154\n",
      "Epoch 464/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -8.4493 - val_loss: -7.8128\n",
      "Epoch 465/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -8.4707 - val_loss: -8.2661\n",
      "Epoch 466/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -8.3081 - val_loss: -8.3004\n",
      "Epoch 467/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.4779 - val_loss: -8.2980\n",
      "Epoch 468/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -8.5040 - val_loss: -8.2870\n",
      "Epoch 469/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -8.5109 - val_loss: -8.3139\n",
      "Epoch 470/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.5241 - val_loss: -8.2992\n",
      "Epoch 471/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.4882 - val_loss: -8.2573\n",
      "Epoch 472/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.4753 - val_loss: -8.3118\n",
      "Epoch 473/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.4879 - val_loss: -8.2831\n",
      "Epoch 474/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.5053 - val_loss: -8.3132\n",
      "Epoch 475/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -8.5227 - val_loss: -8.3218\n",
      "Epoch 476/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -8.4942 - val_loss: -8.3214\n",
      "Epoch 477/5000\n",
      "23/23 [==============================] - 2s 108ms/step - loss: -8.5850 - val_loss: -8.3070\n",
      "Epoch 478/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -8.4718 - val_loss: -8.3298\n",
      "Epoch 479/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.5322 - val_loss: -8.3175\n",
      "Epoch 480/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.4535 - val_loss: -8.0170\n",
      "Epoch 481/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.4950 - val_loss: -8.2868\n",
      "Epoch 482/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -8.4937 - val_loss: -8.3271\n",
      "Epoch 483/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -8.4796 - val_loss: -8.3108\n",
      "Epoch 484/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.5031 - val_loss: -8.3079\n",
      "Epoch 485/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -8.4898 - val_loss: -8.3092\n",
      "Epoch 486/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -8.4904 - val_loss: -8.3248\n",
      "Epoch 487/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.4600 - val_loss: -8.3273\n",
      "Epoch 488/5000\n",
      "23/23 [==============================] - 4s 189ms/step - loss: -8.5729 - val_loss: -8.3089\n",
      "Epoch 489/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.5469 - val_loss: -8.3008\n",
      "Epoch 490/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -8.5405 - val_loss: -8.2980\n",
      "Epoch 491/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -8.4779 - val_loss: -8.3142\n",
      "Epoch 492/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.4955 - val_loss: -8.2177\n",
      "Epoch 493/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.4842 - val_loss: -8.2647\n",
      "Epoch 494/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.5660 - val_loss: -8.2589\n",
      "Epoch 495/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.5221 - val_loss: -8.3252\n",
      "Epoch 496/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -8.5130 - val_loss: -8.3199\n",
      "Epoch 497/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.4917 - val_loss: -8.3175\n",
      "Epoch 498/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -8.5022 - val_loss: -8.3299\n",
      "Epoch 499/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -8.3831 - val_loss: -8.3399\n",
      "Epoch 500/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.5444 - val_loss: -8.3398\n",
      "Epoch 501/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.5185 - val_loss: -8.2740\n",
      "Epoch 502/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.5028 - val_loss: -8.3162\n",
      "Epoch 503/5000\n",
      "23/23 [==============================] - 5s 232ms/step - loss: -8.5060 - val_loss: -8.3393\n",
      "Epoch 504/5000\n",
      "23/23 [==============================] - 6s 263ms/step - loss: -8.4776 - val_loss: -8.3225\n",
      "Epoch 505/5000\n",
      "23/23 [==============================] - 6s 251ms/step - loss: -8.5185 - val_loss: -8.3322\n",
      "Epoch 506/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.4155 - val_loss: -8.3043\n",
      "Epoch 507/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -8.5560 - val_loss: -8.3335\n",
      "Epoch 508/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.4975 - val_loss: -8.3470\n",
      "Epoch 509/5000\n",
      "23/23 [==============================] - 5s 233ms/step - loss: -8.4882 - val_loss: -8.3111\n",
      "Epoch 510/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -8.5596 - val_loss: -8.3310\n",
      "Epoch 511/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -8.5318 - val_loss: -8.3632\n",
      "Epoch 512/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -8.5455 - val_loss: -8.3328\n",
      "Epoch 513/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.5044 - val_loss: -8.3591\n",
      "Epoch 514/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -8.4893 - val_loss: -8.3703\n",
      "Epoch 515/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -8.3915 - val_loss: -8.3451\n",
      "Epoch 516/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.4659 - val_loss: -8.3527\n",
      "Epoch 517/5000\n",
      "23/23 [==============================] - 2s 109ms/step - loss: -8.4284 - val_loss: -8.3528\n",
      "Epoch 518/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -8.5055 - val_loss: -8.3499\n",
      "Epoch 519/5000\n",
      "23/23 [==============================] - 4s 168ms/step - loss: -8.5894 - val_loss: -8.3578\n",
      "Epoch 520/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -8.5466 - val_loss: -8.3064\n",
      "Epoch 521/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.5652 - val_loss: -8.3660\n",
      "Epoch 522/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -8.5460 - val_loss: -8.3516\n",
      "Epoch 523/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -8.5686 - val_loss: -8.3607\n",
      "Epoch 524/5000\n",
      "23/23 [==============================] - 3s 137ms/step - loss: -8.5256 - val_loss: -8.3592\n",
      "Epoch 525/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -8.5482 - val_loss: -8.3468\n",
      "Epoch 526/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.5556 - val_loss: -8.3665\n",
      "Epoch 527/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -8.5661 - val_loss: -8.3591\n",
      "Epoch 528/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.5865 - val_loss: -8.1313\n",
      "Epoch 529/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.4674 - val_loss: -8.3799\n",
      "Epoch 530/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -8.5500 - val_loss: -8.3659\n",
      "Epoch 531/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -8.5638 - val_loss: -8.3263\n",
      "Epoch 532/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.4568 - val_loss: -8.3254\n",
      "Epoch 533/5000\n",
      "23/23 [==============================] - 2s 110ms/step - loss: -8.5053 - val_loss: -8.3803\n",
      "Epoch 534/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.5697 - val_loss: -8.3797\n",
      "Epoch 535/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.4777 - val_loss: -8.3653\n",
      "Epoch 536/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.5682 - val_loss: -8.3698\n",
      "Epoch 537/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.5759 - val_loss: -8.3682\n",
      "Epoch 538/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -8.5992 - val_loss: -8.3733\n",
      "Epoch 539/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.5937 - val_loss: -8.3773\n",
      "Epoch 540/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.4859 - val_loss: -8.3914\n",
      "Epoch 541/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -8.5979 - val_loss: -8.3632\n",
      "Epoch 542/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -8.5250 - val_loss: -8.3617\n",
      "Epoch 543/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -8.5403 - val_loss: -8.3430\n",
      "Epoch 544/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -8.5767 - val_loss: -8.3700\n",
      "Epoch 545/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -8.5191 - val_loss: -8.3803\n",
      "Epoch 546/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.6317 - val_loss: -8.3778\n",
      "Epoch 547/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.5782 - val_loss: -8.3709\n",
      "Epoch 548/5000\n",
      "23/23 [==============================] - 2s 78ms/step - loss: -8.5112 - val_loss: -8.3881\n",
      "Epoch 549/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -8.6111 - val_loss: -8.3635\n",
      "Epoch 550/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -8.6192 - val_loss: -8.3888\n",
      "Epoch 551/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -8.5230 - val_loss: -8.3727\n",
      "Epoch 552/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -8.5749 - val_loss: -8.2279\n",
      "Epoch 553/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.5127 - val_loss: -8.3056\n",
      "Epoch 554/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.6019 - val_loss: -8.3887\n",
      "Epoch 555/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.5921 - val_loss: -8.3806\n",
      "Epoch 556/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.5861 - val_loss: -8.3928\n",
      "Epoch 557/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -8.5826 - val_loss: -8.3783\n",
      "Epoch 558/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -8.5710 - val_loss: -8.3815\n",
      "Epoch 559/5000\n",
      "23/23 [==============================] - 6s 271ms/step - loss: -8.6001 - val_loss: -8.3968\n",
      "Epoch 560/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -8.5207 - val_loss: -8.4009\n",
      "Epoch 561/5000\n",
      "23/23 [==============================] - 3s 117ms/step - loss: -8.6125 - val_loss: -8.3904\n",
      "Epoch 562/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -8.5483 - val_loss: -8.3869\n",
      "Epoch 563/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.5632 - val_loss: -8.4108\n",
      "Epoch 564/5000\n",
      "23/23 [==============================] - 2s 81ms/step - loss: -8.6363 - val_loss: -8.3810\n",
      "Epoch 565/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -8.5634 - val_loss: -8.3960\n",
      "Epoch 566/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -8.5566 - val_loss: -8.3450\n",
      "Epoch 567/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.5625 - val_loss: -7.9222\n",
      "Epoch 568/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.5748 - val_loss: -8.4072\n",
      "Epoch 569/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.5257 - val_loss: -8.3974\n",
      "Epoch 570/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.5869 - val_loss: -8.3886\n",
      "Epoch 571/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.5723 - val_loss: -8.3842\n",
      "Epoch 572/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -8.5892 - val_loss: -8.2908\n",
      "Epoch 573/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -8.6180 - val_loss: -8.2955\n",
      "Epoch 574/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -8.6259 - val_loss: -8.4136\n",
      "Epoch 575/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -8.5508 - val_loss: -8.4124\n",
      "Epoch 576/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -8.5617 - val_loss: -8.4167\n",
      "Epoch 577/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.6326 - val_loss: -8.3834\n",
      "Epoch 578/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.5465 - val_loss: -8.4272\n",
      "Epoch 579/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -8.5998 - val_loss: -8.4037\n",
      "Epoch 580/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -8.6158 - val_loss: -8.4189\n",
      "Epoch 581/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -8.6472 - val_loss: -8.4224\n",
      "Epoch 582/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -8.5866 - val_loss: -8.4274\n",
      "Epoch 583/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.5464 - val_loss: -8.4096\n",
      "Epoch 584/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.6252 - val_loss: -8.2882\n",
      "Epoch 585/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.5713 - val_loss: -8.4136\n",
      "Epoch 586/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -8.6049 - val_loss: -8.4083\n",
      "Epoch 587/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -8.6577 - val_loss: -3.6263\n",
      "Epoch 588/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.5822 - val_loss: -8.4211\n",
      "Epoch 589/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -8.5939 - val_loss: -8.3901\n",
      "Epoch 590/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -8.5465 - val_loss: -8.4081\n",
      "Epoch 591/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -8.5931 - val_loss: -8.4110\n",
      "Epoch 592/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -8.6389 - val_loss: -8.4369\n",
      "Epoch 593/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -8.5028 - val_loss: -8.4059\n",
      "Epoch 594/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -8.5983 - val_loss: -8.4404\n",
      "Epoch 595/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -8.6984 - val_loss: -8.4258\n",
      "Epoch 596/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -8.5479 - val_loss: -8.4142\n",
      "Epoch 597/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.6002 - val_loss: -8.4366\n",
      "Epoch 598/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.6659 - val_loss: -8.4271\n",
      "Epoch 599/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.6392 - val_loss: -8.4180\n",
      "Epoch 600/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.5727 - val_loss: -8.4191\n",
      "Epoch 601/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -8.5262 - val_loss: -8.4417\n",
      "Epoch 602/5000\n",
      "23/23 [==============================] - 6s 259ms/step - loss: -8.6271 - val_loss: -8.4273\n",
      "Epoch 603/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -8.6775 - val_loss: -8.4077\n",
      "Epoch 604/5000\n",
      "23/23 [==============================] - 2s 80ms/step - loss: -8.6570 - val_loss: -8.4359\n",
      "Epoch 605/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -8.6079 - val_loss: -8.4304\n",
      "Epoch 606/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -8.5965 - val_loss: -8.4335\n",
      "Epoch 607/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.6172 - val_loss: -8.3897\n",
      "Epoch 608/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -8.6011 - val_loss: -8.4078\n",
      "Epoch 609/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -8.6349 - val_loss: -8.4527\n",
      "Epoch 610/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.5908 - val_loss: -8.4390\n",
      "Epoch 611/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.6345 - val_loss: -8.4467\n",
      "Epoch 612/5000\n",
      "23/23 [==============================] - 3s 131ms/step - loss: -8.6448 - val_loss: -8.4671\n",
      "Epoch 613/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -8.5211 - val_loss: -8.4387\n",
      "Epoch 614/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -8.6291 - val_loss: -8.4389\n",
      "Epoch 615/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -8.6405 - val_loss: -8.4713\n",
      "Epoch 616/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.6325 - val_loss: -8.4348\n",
      "Epoch 617/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -8.5917 - val_loss: -8.4633\n",
      "Epoch 618/5000\n",
      "23/23 [==============================] - 4s 181ms/step - loss: -8.5560 - val_loss: -8.4612\n",
      "Epoch 619/5000\n",
      "23/23 [==============================] - 3s 135ms/step - loss: -8.6534 - val_loss: -8.3903\n",
      "Epoch 620/5000\n",
      "23/23 [==============================] - 2s 81ms/step - loss: -8.6359 - val_loss: -8.4414\n",
      "Epoch 621/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -8.6377 - val_loss: -8.4451\n",
      "Epoch 622/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.6343 - val_loss: -8.4388\n",
      "Epoch 623/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -8.6293 - val_loss: -8.4645\n",
      "Epoch 624/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -8.6677 - val_loss: -8.4590\n",
      "Epoch 625/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -8.6862 - val_loss: -8.3924\n",
      "Epoch 626/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -8.6484 - val_loss: -8.4323\n",
      "Epoch 627/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.6776 - val_loss: -8.4626\n",
      "Epoch 628/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.6854 - val_loss: -8.4560\n",
      "Epoch 629/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.6508 - val_loss: -8.4488\n",
      "Epoch 630/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.6092 - val_loss: -8.4472\n",
      "Epoch 631/5000\n",
      "23/23 [==============================] - 5s 241ms/step - loss: -8.6119 - val_loss: -8.4560\n",
      "Epoch 632/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -8.6747 - val_loss: -8.4679\n",
      "Epoch 633/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -8.6833 - val_loss: -8.4790\n",
      "Epoch 634/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -8.6393 - val_loss: -8.4675\n",
      "Epoch 635/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.6022 - val_loss: -8.3091\n",
      "Epoch 636/5000\n",
      "23/23 [==============================] - 2s 79ms/step - loss: -8.6219 - val_loss: -8.4710\n",
      "Epoch 637/5000\n",
      "23/23 [==============================] - 2s 104ms/step - loss: -8.6784 - val_loss: -8.4347\n",
      "Epoch 638/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -8.6571 - val_loss: -8.4623\n",
      "Epoch 639/5000\n",
      "23/23 [==============================] - 3s 131ms/step - loss: -8.6429 - val_loss: -8.4538\n",
      "Epoch 640/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.6039 - val_loss: -8.4571\n",
      "Epoch 641/5000\n",
      "23/23 [==============================] - 5s 232ms/step - loss: -8.6561 - val_loss: -8.4534\n",
      "Epoch 642/5000\n",
      "23/23 [==============================] - 3s 131ms/step - loss: -8.6773 - val_loss: -8.4525\n",
      "Epoch 643/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -8.6531 - val_loss: -8.3238\n",
      "Epoch 644/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -8.6502 - val_loss: -8.4824\n",
      "Epoch 645/5000\n",
      "23/23 [==============================] - 2s 75ms/step - loss: -8.6468 - val_loss: -8.4623\n",
      "Epoch 646/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.6467 - val_loss: -8.4815\n",
      "Epoch 647/5000\n",
      "23/23 [==============================] - 4s 182ms/step - loss: -8.6787 - val_loss: -8.4937\n",
      "Epoch 648/5000\n",
      "23/23 [==============================] - 5s 241ms/step - loss: -8.6712 - val_loss: -8.4077\n",
      "Epoch 649/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -8.6591 - val_loss: -8.4616\n",
      "Epoch 650/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -8.6530 - val_loss: -8.4909\n",
      "Epoch 651/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -8.7097 - val_loss: -8.4727\n",
      "Epoch 652/5000\n",
      "23/23 [==============================] - 3s 117ms/step - loss: -8.6522 - val_loss: -8.4590\n",
      "Epoch 653/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -8.6576 - val_loss: -8.4953\n",
      "Epoch 654/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -8.6716 - val_loss: -8.4850\n",
      "Epoch 655/5000\n",
      "23/23 [==============================] - 4s 201ms/step - loss: -8.6609 - val_loss: -8.4968\n",
      "Epoch 656/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -8.6883 - val_loss: -8.4981\n",
      "Epoch 657/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -8.6803 - val_loss: -8.4718\n",
      "Epoch 658/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.6394 - val_loss: -8.4994\n",
      "Epoch 659/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.7102 - val_loss: -7.6858\n",
      "Epoch 660/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -8.6681 - val_loss: -8.4770\n",
      "Epoch 661/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.6849 - val_loss: -8.4866\n",
      "Epoch 662/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -8.6644 - val_loss: -8.4911\n",
      "Epoch 663/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.6334 - val_loss: -8.4923\n",
      "Epoch 664/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.6810 - val_loss: -8.4826\n",
      "Epoch 665/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -8.6811 - val_loss: -8.4982\n",
      "Epoch 666/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.6530 - val_loss: -8.5224\n",
      "Epoch 667/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -8.7161 - val_loss: -8.5017\n",
      "Epoch 668/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.7400 - val_loss: -8.4956\n",
      "Epoch 669/5000\n",
      "23/23 [==============================] - 6s 267ms/step - loss: -8.6493 - val_loss: -8.4908\n",
      "Epoch 670/5000\n",
      "23/23 [==============================] - 6s 265ms/step - loss: -8.6990 - val_loss: -8.4878\n",
      "Epoch 671/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -8.6515 - val_loss: -8.4660\n",
      "Epoch 672/5000\n",
      "23/23 [==============================] - 3s 143ms/step - loss: -8.7073 - val_loss: -8.5027\n",
      "Epoch 673/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -8.6939 - val_loss: -8.4951\n",
      "Epoch 674/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -8.7153 - val_loss: -8.5048\n",
      "Epoch 675/5000\n",
      "23/23 [==============================] - 3s 118ms/step - loss: -8.7433 - val_loss: -8.4911\n",
      "Epoch 676/5000\n",
      "23/23 [==============================] - 2s 109ms/step - loss: -8.7401 - val_loss: -8.4998\n",
      "Epoch 677/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.7450 - val_loss: -8.5076\n",
      "Epoch 678/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -8.6940 - val_loss: -8.5293\n",
      "Epoch 679/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.7190 - val_loss: -8.4616\n",
      "Epoch 680/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -8.7532 - val_loss: -8.5156\n",
      "Epoch 681/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.6784 - val_loss: -8.4844\n",
      "Epoch 682/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.7018 - val_loss: -8.5060\n",
      "Epoch 683/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -8.7741 - val_loss: -8.5187\n",
      "Epoch 684/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.7206 - val_loss: -8.5234\n",
      "Epoch 685/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -8.6701 - val_loss: -8.5148\n",
      "Epoch 686/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -8.6581 - val_loss: -8.5176\n",
      "Epoch 687/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -8.7012 - val_loss: -8.4773\n",
      "Epoch 688/5000\n",
      "23/23 [==============================] - 6s 273ms/step - loss: -8.6991 - val_loss: -8.5322\n",
      "Epoch 689/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -8.6358 - val_loss: -8.5295\n",
      "Epoch 690/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -8.6744 - val_loss: -8.4605\n",
      "Epoch 691/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -8.6955 - val_loss: -8.5050\n",
      "Epoch 692/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.6930 - val_loss: -8.5038\n",
      "Epoch 693/5000\n",
      "23/23 [==============================] - 5s 234ms/step - loss: -8.6667 - val_loss: -8.5258\n",
      "Epoch 694/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -8.6662 - val_loss: -8.5296\n",
      "Epoch 695/5000\n",
      "23/23 [==============================] - 2s 81ms/step - loss: -8.7048 - val_loss: -8.5492\n",
      "Epoch 696/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -8.7180 - val_loss: -8.5321\n",
      "Epoch 697/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -8.7053 - val_loss: -8.5368\n",
      "Epoch 698/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.7538 - val_loss: -8.5052\n",
      "Epoch 699/5000\n",
      "23/23 [==============================] - 2s 81ms/step - loss: -8.6972 - val_loss: -8.5409\n",
      "Epoch 700/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -8.7270 - val_loss: -8.4626\n",
      "Epoch 701/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -8.8118 - val_loss: -8.5408\n",
      "Epoch 702/5000\n",
      "23/23 [==============================] - 2s 80ms/step - loss: -8.6824 - val_loss: -8.5473\n",
      "Epoch 703/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -8.7102 - val_loss: -8.5341\n",
      "Epoch 704/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.7036 - val_loss: -8.5217\n",
      "Epoch 705/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.6607 - val_loss: -8.5405\n",
      "Epoch 706/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -8.7531 - val_loss: -8.5169\n",
      "Epoch 707/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.6691 - val_loss: -8.4934\n",
      "Epoch 708/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -8.7152 - val_loss: -8.5311\n",
      "Epoch 709/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -8.7052 - val_loss: -8.5333\n",
      "Epoch 710/5000\n",
      "23/23 [==============================] - 6s 266ms/step - loss: -8.7420 - val_loss: -8.5570\n",
      "Epoch 711/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -8.7824 - val_loss: -8.5460\n",
      "Epoch 712/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -8.6813 - val_loss: -8.4917\n",
      "Epoch 713/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.7015 - val_loss: -8.5396\n",
      "Epoch 714/5000\n",
      "23/23 [==============================] - 2s 80ms/step - loss: -8.7256 - val_loss: -8.5389\n",
      "Epoch 715/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -8.7601 - val_loss: -8.5379\n",
      "Epoch 716/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.7148 - val_loss: -8.5370\n",
      "Epoch 717/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -8.7341 - val_loss: -8.5239\n",
      "Epoch 718/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.7189 - val_loss: -8.5355\n",
      "Epoch 719/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.7273 - val_loss: -8.5161\n",
      "Epoch 720/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -8.7190 - val_loss: -8.5320\n",
      "Epoch 721/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.6279 - val_loss: -8.5505\n",
      "Epoch 722/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.7304 - val_loss: -8.5323\n",
      "Epoch 723/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -8.7637 - val_loss: -8.5576\n",
      "Epoch 724/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.7249 - val_loss: -8.5020\n",
      "Epoch 725/5000\n",
      "23/23 [==============================] - 3s 158ms/step - loss: -8.7535 - val_loss: -8.5538\n",
      "Epoch 726/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -8.7263 - val_loss: -8.5277\n",
      "Epoch 727/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.7236 - val_loss: -8.5466\n",
      "Epoch 728/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.7528 - val_loss: -8.5413\n",
      "Epoch 729/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.7571 - val_loss: -8.5146\n",
      "Epoch 730/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -8.7373 - val_loss: -8.5531\n",
      "Epoch 731/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.7276 - val_loss: -8.5612\n",
      "Epoch 732/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.7913 - val_loss: -8.5668\n",
      "Epoch 733/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.7431 - val_loss: -8.5350\n",
      "Epoch 734/5000\n",
      "23/23 [==============================] - 5s 211ms/step - loss: -8.7796 - val_loss: -8.5732\n",
      "Epoch 735/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.7796 - val_loss: -8.5191\n",
      "Epoch 736/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -8.7370 - val_loss: -8.5433\n",
      "Epoch 737/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -8.7292 - val_loss: -8.5741\n",
      "Epoch 738/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -8.7054 - val_loss: -8.5585\n",
      "Epoch 739/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -8.7988 - val_loss: -8.5755\n",
      "Epoch 740/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.7740 - val_loss: -8.5717\n",
      "Epoch 741/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.7732 - val_loss: -8.4496\n",
      "Epoch 742/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -8.7439 - val_loss: -8.5745\n",
      "Epoch 743/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.8451 - val_loss: -8.5493\n",
      "Epoch 744/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.7057 - val_loss: -8.5666\n",
      "Epoch 745/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.7087 - val_loss: -8.5722\n",
      "Epoch 746/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -8.6961 - val_loss: -8.5563\n",
      "Epoch 747/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.7427 - val_loss: -8.5733\n",
      "Epoch 748/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -8.7557 - val_loss: -8.5578\n",
      "Epoch 749/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -8.7541 - val_loss: -8.4970\n",
      "Epoch 750/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.7203 - val_loss: -8.5532\n",
      "Epoch 751/5000\n",
      "23/23 [==============================] - 2s 109ms/step - loss: -8.8214 - val_loss: -8.5822\n",
      "Epoch 752/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -8.8197 - val_loss: -8.5607\n",
      "Epoch 753/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.8417 - val_loss: -8.3584\n",
      "Epoch 754/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.7445 - val_loss: -8.5824\n",
      "Epoch 755/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.7894 - val_loss: -8.5688\n",
      "Epoch 756/5000\n",
      "23/23 [==============================] - 3s 134ms/step - loss: -8.7493 - val_loss: -8.5822\n",
      "Epoch 757/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -8.7835 - val_loss: -8.5660\n",
      "Epoch 758/5000\n",
      "23/23 [==============================] - 2s 80ms/step - loss: -8.7504 - val_loss: -8.5542\n",
      "Epoch 759/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -8.7465 - val_loss: -8.5748\n",
      "Epoch 760/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -8.7677 - val_loss: -8.5675\n",
      "Epoch 761/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.7505 - val_loss: -8.5661\n",
      "Epoch 762/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -8.7452 - val_loss: -8.5743\n",
      "Epoch 763/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -8.7972 - val_loss: -8.5876\n",
      "Epoch 764/5000\n",
      "23/23 [==============================] - 3s 145ms/step - loss: -8.7670 - val_loss: -8.6005\n",
      "Epoch 765/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.7285 - val_loss: -8.6012\n",
      "Epoch 766/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -8.5797 - val_loss: -8.5692\n",
      "Epoch 767/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -8.7858 - val_loss: -8.5835\n",
      "Epoch 768/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.6622 - val_loss: -8.5802\n",
      "Epoch 769/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.7716 - val_loss: -8.5948\n",
      "Epoch 770/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -8.6926 - val_loss: -8.5796\n",
      "Epoch 771/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.7909 - val_loss: -8.5654\n",
      "Epoch 772/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -8.7819 - val_loss: -8.5867\n",
      "Epoch 773/5000\n",
      "23/23 [==============================] - 2s 81ms/step - loss: -8.7965 - val_loss: -8.5790\n",
      "Epoch 774/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -8.8121 - val_loss: -8.5792\n",
      "Epoch 775/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -8.8073 - val_loss: -8.5861\n",
      "Epoch 776/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.8069 - val_loss: -8.5996\n",
      "Epoch 777/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.7667 - val_loss: -8.5960\n",
      "Epoch 778/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -8.7688 - val_loss: -8.5795\n",
      "Epoch 779/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -8.8142 - val_loss: -8.6054\n",
      "Epoch 780/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -8.7130 - val_loss: -8.5906\n",
      "Epoch 781/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -8.8213 - val_loss: -8.5855\n",
      "Epoch 782/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -8.7230 - val_loss: -8.5684\n",
      "Epoch 783/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -8.7262 - val_loss: -8.5712\n",
      "Epoch 784/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -8.7747 - val_loss: -8.5970\n",
      "Epoch 785/5000\n",
      "23/23 [==============================] - 2s 81ms/step - loss: -8.7959 - val_loss: -8.6033\n",
      "Epoch 786/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.8117 - val_loss: -8.5755\n",
      "Epoch 787/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.8540 - val_loss: -8.6039\n",
      "Epoch 788/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -8.8062 - val_loss: -8.6132\n",
      "Epoch 789/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.6254 - val_loss: -8.5712\n",
      "Epoch 790/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.7900 - val_loss: -8.6096\n",
      "Epoch 791/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.7467 - val_loss: -8.6007\n",
      "Epoch 792/5000\n",
      "23/23 [==============================] - 2s 79ms/step - loss: -8.7874 - val_loss: -8.6088\n",
      "Epoch 793/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.8256 - val_loss: -8.5855\n",
      "Epoch 794/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -8.8045 - val_loss: -8.5945\n",
      "Epoch 795/5000\n",
      "23/23 [==============================] - 4s 201ms/step - loss: -8.7768 - val_loss: -8.6045\n",
      "Epoch 796/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -8.7837 - val_loss: -8.5982\n",
      "Epoch 797/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.8319 - val_loss: -8.5958\n",
      "Epoch 798/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.8386 - val_loss: -8.5934\n",
      "Epoch 799/5000\n",
      "23/23 [==============================] - 2s 80ms/step - loss: -8.8025 - val_loss: -8.6062\n",
      "Epoch 800/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -8.8011 - val_loss: -8.5904\n",
      "Epoch 801/5000\n",
      "23/23 [==============================] - 6s 267ms/step - loss: -8.8408 - val_loss: -8.6220\n",
      "Epoch 802/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -8.8313 - val_loss: -8.6127\n",
      "Epoch 803/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -8.8026 - val_loss: -8.5861\n",
      "Epoch 804/5000\n",
      "23/23 [==============================] - 3s 141ms/step - loss: -8.7636 - val_loss: -8.6381\n",
      "Epoch 805/5000\n",
      "23/23 [==============================] - 4s 164ms/step - loss: -8.8094 - val_loss: -8.6186\n",
      "Epoch 806/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -8.8064 - val_loss: -8.6213\n",
      "Epoch 807/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -8.8131 - val_loss: -8.5977\n",
      "Epoch 808/5000\n",
      "23/23 [==============================] - 6s 251ms/step - loss: -8.8226 - val_loss: -8.5972\n",
      "Epoch 809/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -8.7713 - val_loss: -8.6138\n",
      "Epoch 810/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -8.8403 - val_loss: -8.6171\n",
      "Epoch 811/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.7725 - val_loss: -8.5995\n",
      "Epoch 812/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.8196 - val_loss: -8.6138\n",
      "Epoch 813/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -8.7984 - val_loss: -8.5921\n",
      "Epoch 814/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -8.8174 - val_loss: -8.6228\n",
      "Epoch 815/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -8.8379 - val_loss: -8.6301\n",
      "Epoch 816/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -8.7761 - val_loss: -8.6053\n",
      "Epoch 817/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -8.8697 - val_loss: -8.5656\n",
      "Epoch 818/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -8.8199 - val_loss: -8.6164\n",
      "Epoch 819/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -8.8610 - val_loss: -8.6012\n",
      "Epoch 820/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.7206 - val_loss: -8.6237\n",
      "Epoch 821/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -8.7921 - val_loss: -8.6256\n",
      "Epoch 822/5000\n",
      "23/23 [==============================] - 4s 197ms/step - loss: -8.7643 - val_loss: -8.6375\n",
      "Epoch 823/5000\n",
      "23/23 [==============================] - 2s 110ms/step - loss: -8.8419 - val_loss: -8.6237\n",
      "Epoch 824/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.8976 - val_loss: -8.5982\n",
      "Epoch 825/5000\n",
      "23/23 [==============================] - 4s 164ms/step - loss: -8.8056 - val_loss: -8.6532\n",
      "Epoch 826/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -8.7489 - val_loss: -8.6237\n",
      "Epoch 827/5000\n",
      "23/23 [==============================] - 2s 80ms/step - loss: -8.8373 - val_loss: -8.6343\n",
      "Epoch 828/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -8.8221 - val_loss: -8.5743\n",
      "Epoch 829/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -8.7626 - val_loss: -8.5981\n",
      "Epoch 830/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -8.7538 - val_loss: -8.6361\n",
      "Epoch 831/5000\n",
      "23/23 [==============================] - 2s 81ms/step - loss: -8.8360 - val_loss: -8.6190\n",
      "Epoch 832/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -8.8727 - val_loss: -8.6378\n",
      "Epoch 833/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.8432 - val_loss: -8.5994\n",
      "Epoch 834/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.7192 - val_loss: -8.6481\n",
      "Epoch 835/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.8635 - val_loss: -8.6358\n",
      "Epoch 836/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.8593 - val_loss: -8.6229\n",
      "Epoch 837/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -8.7838 - val_loss: -8.6487\n",
      "Epoch 838/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.8232 - val_loss: -8.4990\n",
      "Epoch 839/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -8.8556 - val_loss: -8.5585\n",
      "Epoch 840/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.8708 - val_loss: -8.6333\n",
      "Epoch 841/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -8.8261 - val_loss: -8.6163\n",
      "Epoch 842/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -8.9116 - val_loss: -8.6566\n",
      "Epoch 843/5000\n",
      "23/23 [==============================] - 2s 109ms/step - loss: -8.7736 - val_loss: -8.6318\n",
      "Epoch 844/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -8.8404 - val_loss: -8.6401\n",
      "Epoch 845/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.8203 - val_loss: -8.6623\n",
      "Epoch 846/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.8699 - val_loss: -8.6526\n",
      "Epoch 847/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.7806 - val_loss: -8.6364\n",
      "Epoch 848/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.8653 - val_loss: -8.6472\n",
      "Epoch 849/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -8.8454 - val_loss: -8.6509\n",
      "Epoch 850/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -8.7891 - val_loss: -8.6078\n",
      "Epoch 851/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -8.8841 - val_loss: -8.6577\n",
      "Epoch 852/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -8.8093 - val_loss: -8.6480\n",
      "Epoch 853/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -8.8684 - val_loss: -8.6446\n",
      "Epoch 854/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.7280 - val_loss: -8.6215\n",
      "Epoch 855/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.7842 - val_loss: -8.6197\n",
      "Epoch 856/5000\n",
      "23/23 [==============================] - 6s 265ms/step - loss: -8.8266 - val_loss: -8.6613\n",
      "Epoch 857/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -8.7861 - val_loss: -8.6275\n",
      "Epoch 858/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.8635 - val_loss: -8.6557\n",
      "Epoch 859/5000\n",
      "23/23 [==============================] - 2s 73ms/step - loss: -8.8409 - val_loss: -8.6201\n",
      "Epoch 860/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -8.7097 - val_loss: -8.6448\n",
      "Epoch 861/5000\n",
      "23/23 [==============================] - 6s 262ms/step - loss: -8.8016 - val_loss: -8.6636\n",
      "Epoch 862/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.7816 - val_loss: -8.6106\n",
      "Epoch 863/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -8.8559 - val_loss: -8.6311\n",
      "Epoch 864/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.8260 - val_loss: -8.6277\n",
      "Epoch 865/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -8.9124 - val_loss: -8.6480\n",
      "Epoch 866/5000\n",
      "23/23 [==============================] - 4s 165ms/step - loss: -8.8298 - val_loss: -8.5317\n",
      "Epoch 867/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.8255 - val_loss: -8.6159\n",
      "Epoch 868/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.8561 - val_loss: -8.6253\n",
      "Epoch 869/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -8.8009 - val_loss: -8.6300\n",
      "Epoch 870/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -8.8085 - val_loss: -8.6528\n",
      "Epoch 871/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.8361 - val_loss: -8.6500\n",
      "Epoch 872/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.8035 - val_loss: -8.6623\n",
      "Epoch 873/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -8.8839 - val_loss: -8.6655\n",
      "Epoch 874/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.7726 - val_loss: -8.6662\n",
      "Epoch 875/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.8578 - val_loss: -8.6486\n",
      "Epoch 876/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.8386 - val_loss: -8.6473\n",
      "Epoch 877/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.8352 - val_loss: -8.6696\n",
      "Epoch 878/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.8943 - val_loss: -8.0084\n",
      "Epoch 879/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -8.7978 - val_loss: -8.6695\n",
      "Epoch 880/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -8.8917 - val_loss: -8.6507\n",
      "Epoch 881/5000\n",
      "23/23 [==============================] - 3s 135ms/step - loss: -8.8709 - val_loss: -8.6651\n",
      "Epoch 882/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.8485 - val_loss: -8.6670\n",
      "Epoch 883/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.8593 - val_loss: -8.6610\n",
      "Epoch 884/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.9031 - val_loss: -8.6535\n",
      "Epoch 885/5000\n",
      "23/23 [==============================] - 3s 140ms/step - loss: -8.8129 - val_loss: -8.6531\n",
      "Epoch 886/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -8.8409 - val_loss: -8.6500\n",
      "Epoch 887/5000\n",
      "23/23 [==============================] - 3s 145ms/step - loss: -8.8276 - val_loss: -8.6763\n",
      "Epoch 888/5000\n",
      "23/23 [==============================] - 3s 133ms/step - loss: -8.7959 - val_loss: -8.6168\n",
      "Epoch 889/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.8403 - val_loss: -8.5943\n",
      "Epoch 890/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.7107 - val_loss: -8.6544\n",
      "Epoch 891/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.8790 - val_loss: -8.6284\n",
      "Epoch 892/5000\n",
      "23/23 [==============================] - 2s 79ms/step - loss: -8.8533 - val_loss: -8.6654\n",
      "Epoch 893/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.8784 - val_loss: -8.6714\n",
      "Epoch 894/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -8.8642 - val_loss: -8.6381\n",
      "Epoch 895/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -8.8655 - val_loss: -8.6770\n",
      "Epoch 896/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -8.8448 - val_loss: -8.6867\n",
      "Epoch 897/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -8.8224 - val_loss: -8.5747\n",
      "Epoch 898/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.8398 - val_loss: -8.6633\n",
      "Epoch 899/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.8909 - val_loss: -8.6457\n",
      "Epoch 900/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -8.8281 - val_loss: -8.6929\n",
      "Epoch 901/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -8.8449 - val_loss: -8.6839\n",
      "Epoch 902/5000\n",
      "23/23 [==============================] - 5s 204ms/step - loss: -8.7580 - val_loss: -8.6851\n",
      "Epoch 903/5000\n",
      "23/23 [==============================] - 5s 222ms/step - loss: -8.8043 - val_loss: -8.6742\n",
      "Epoch 904/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -8.9474 - val_loss: -8.6442\n",
      "Epoch 905/5000\n",
      "23/23 [==============================] - 2s 81ms/step - loss: -8.8714 - val_loss: -8.6754\n",
      "Epoch 906/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.8357 - val_loss: -8.6858\n",
      "Epoch 907/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -8.8780 - val_loss: -8.6949\n",
      "Epoch 908/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -8.8425 - val_loss: -8.6964\n",
      "Epoch 909/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.8729 - val_loss: -8.6494\n",
      "Epoch 910/5000\n",
      "23/23 [==============================] - 4s 188ms/step - loss: -8.8622 - val_loss: -8.6330\n",
      "Epoch 911/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -8.8336 - val_loss: -8.6866\n",
      "Epoch 912/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.8965 - val_loss: -8.6920\n",
      "Epoch 913/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.8568 - val_loss: -8.6991\n",
      "Epoch 914/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -8.8637 - val_loss: -8.6731\n",
      "Epoch 915/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.7996 - val_loss: -8.6497\n",
      "Epoch 916/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -8.8524 - val_loss: -8.6753\n",
      "Epoch 917/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -8.9254 - val_loss: -8.6684\n",
      "Epoch 918/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.8389 - val_loss: -8.6923\n",
      "Epoch 919/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -8.8213 - val_loss: -8.6757\n",
      "Epoch 920/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -8.9131 - val_loss: -8.6916\n",
      "Epoch 921/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -8.8453 - val_loss: -8.6803\n",
      "Epoch 922/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.8373 - val_loss: -8.6729\n",
      "Epoch 923/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -8.8315 - val_loss: -8.6864\n",
      "Epoch 924/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.7021 - val_loss: -8.7015\n",
      "Epoch 925/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -8.8822 - val_loss: -8.7017\n",
      "Epoch 926/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.8650 - val_loss: -8.6906\n",
      "Epoch 927/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.9091 - val_loss: -8.6687\n",
      "Epoch 928/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.8867 - val_loss: -8.7035\n",
      "Epoch 929/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -8.8589 - val_loss: -8.6753\n",
      "Epoch 930/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -8.8983 - val_loss: -8.6606\n",
      "Epoch 931/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -8.8453 - val_loss: -8.6875\n",
      "Epoch 932/5000\n",
      "23/23 [==============================] - 2s 80ms/step - loss: -8.9072 - val_loss: -8.6705\n",
      "Epoch 933/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -8.7147 - val_loss: -8.6838\n",
      "Epoch 934/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.8388 - val_loss: -8.6968\n",
      "Epoch 935/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.8325 - val_loss: -8.6934\n",
      "Epoch 936/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.8388 - val_loss: -8.6776\n",
      "Epoch 937/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -8.9025 - val_loss: -8.6805\n",
      "Epoch 938/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.8849 - val_loss: -8.6861\n",
      "Epoch 939/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -8.9231 - val_loss: -8.7009\n",
      "Epoch 940/5000\n",
      "23/23 [==============================] - 5s 217ms/step - loss: -8.8268 - val_loss: -8.7126\n",
      "Epoch 941/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -8.8276 - val_loss: -8.7010\n",
      "Epoch 942/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.8990 - val_loss: -8.7070\n",
      "Epoch 943/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.8425 - val_loss: -8.7070\n",
      "Epoch 944/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.8311 - val_loss: -8.6995\n",
      "Epoch 945/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -8.9267 - val_loss: -8.7164\n",
      "Epoch 946/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -8.8931 - val_loss: -8.6973\n",
      "Epoch 947/5000\n",
      "23/23 [==============================] - 2s 110ms/step - loss: -8.8687 - val_loss: -8.6648\n",
      "Epoch 948/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.8852 - val_loss: -8.6806\n",
      "Epoch 949/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -8.8876 - val_loss: -8.6952\n",
      "Epoch 950/5000\n",
      "23/23 [==============================] - 3s 116ms/step - loss: -8.9500 - val_loss: -8.6859\n",
      "Epoch 951/5000\n",
      "23/23 [==============================] - 6s 262ms/step - loss: -8.9572 - val_loss: -8.7096\n",
      "Epoch 952/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -8.9220 - val_loss: -8.6674\n",
      "Epoch 953/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.8471 - val_loss: -8.6952\n",
      "Epoch 954/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -8.9364 - val_loss: -8.7182\n",
      "Epoch 955/5000\n",
      "23/23 [==============================] - 3s 139ms/step - loss: -8.9865 - val_loss: -8.7047\n",
      "Epoch 956/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -8.8555 - val_loss: -8.6942\n",
      "Epoch 957/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -8.9001 - val_loss: -8.5673\n",
      "Epoch 958/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -8.8429 - val_loss: -8.7114\n",
      "Epoch 959/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.8200 - val_loss: -8.7062\n",
      "Epoch 960/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.9175 - val_loss: -8.7113\n",
      "Epoch 961/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -8.9345 - val_loss: -8.7057\n",
      "Epoch 962/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -8.8075 - val_loss: -8.7130\n",
      "Epoch 963/5000\n",
      "23/23 [==============================] - 2s 104ms/step - loss: -8.9115 - val_loss: -8.7313\n",
      "Epoch 964/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -8.8596 - val_loss: -8.7252\n",
      "Epoch 965/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -8.8345 - val_loss: -8.7206\n",
      "Epoch 966/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.8902 - val_loss: -8.7137\n",
      "Epoch 967/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.9097 - val_loss: -8.7030\n",
      "Epoch 968/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -8.9363 - val_loss: -8.7123\n",
      "Epoch 969/5000\n",
      "23/23 [==============================] - 2s 81ms/step - loss: -8.8491 - val_loss: -8.7108\n",
      "Epoch 970/5000\n",
      "23/23 [==============================] - 2s 110ms/step - loss: -8.8178 - val_loss: -8.7427\n",
      "Epoch 971/5000\n",
      "23/23 [==============================] - 5s 241ms/step - loss: -8.9429 - val_loss: -8.7190\n",
      "Epoch 972/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.8942 - val_loss: -8.7159\n",
      "Epoch 973/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -8.9339 - val_loss: -8.7275\n",
      "Epoch 974/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.8851 - val_loss: -8.7125\n",
      "Epoch 975/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -8.9473 - val_loss: -8.7151\n",
      "Epoch 976/5000\n",
      "23/23 [==============================] - 2s 104ms/step - loss: -8.9033 - val_loss: -8.7124\n",
      "Epoch 977/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -8.8593 - val_loss: -8.7195\n",
      "Epoch 978/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -8.8229 - val_loss: -8.7092\n",
      "Epoch 979/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -8.8532 - val_loss: -8.7126\n",
      "Epoch 980/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -8.8329 - val_loss: -8.7214\n",
      "Epoch 981/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.8343 - val_loss: -8.6943\n",
      "Epoch 982/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.8717 - val_loss: -8.7040\n",
      "Epoch 983/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.9305 - val_loss: -8.7050\n",
      "Epoch 984/5000\n",
      "23/23 [==============================] - 4s 194ms/step - loss: -8.9464 - val_loss: -8.7115\n",
      "Epoch 985/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -8.8262 - val_loss: -8.7400\n",
      "Epoch 986/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.9377 - val_loss: -8.6931\n",
      "Epoch 987/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.9389 - val_loss: -8.7192\n",
      "Epoch 988/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -8.8856 - val_loss: -8.7388\n",
      "Epoch 989/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -8.8909 - val_loss: -8.7383\n",
      "Epoch 990/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -8.8855 - val_loss: -8.7407\n",
      "Epoch 991/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.9136 - val_loss: -8.7076\n",
      "Epoch 992/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -8.9222 - val_loss: -8.7380\n",
      "Epoch 993/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.9538 - val_loss: -8.7340\n",
      "Epoch 994/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.9319 - val_loss: -8.7398\n",
      "Epoch 995/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -8.9274 - val_loss: -8.7381\n",
      "Epoch 996/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -8.8535 - val_loss: -8.7246\n",
      "Epoch 997/5000\n",
      "23/23 [==============================] - 2s 80ms/step - loss: -8.9235 - val_loss: -8.7337\n",
      "Epoch 998/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -8.8461 - val_loss: -8.7354\n",
      "Epoch 999/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -8.9236 - val_loss: -8.7214\n",
      "Epoch 1000/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -8.9251 - val_loss: -8.7309\n",
      "Epoch 1001/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -8.9109 - val_loss: -8.7467\n",
      "Epoch 1002/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.9055 - val_loss: -8.6763\n",
      "Epoch 1003/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -8.8502 - val_loss: -8.7409\n",
      "Epoch 1004/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -8.9621 - val_loss: -8.7302\n",
      "Epoch 1005/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -8.8036 - val_loss: -8.7181\n",
      "Epoch 1006/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.8962 - val_loss: -8.7352\n",
      "Epoch 1007/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -8.9576 - val_loss: -8.7412\n",
      "Epoch 1008/5000\n",
      "23/23 [==============================] - 2s 78ms/step - loss: -8.8914 - val_loss: -8.7336\n",
      "Epoch 1009/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -8.9034 - val_loss: -8.7413\n",
      "Epoch 1010/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.8344 - val_loss: -8.7447\n",
      "Epoch 1011/5000\n",
      "23/23 [==============================] - 2s 112ms/step - loss: -8.8861 - val_loss: -8.7625\n",
      "Epoch 1012/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.8489 - val_loss: -8.7195\n",
      "Epoch 1013/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -8.8620 - val_loss: -8.7314\n",
      "Epoch 1014/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.9284 - val_loss: -8.7287\n",
      "Epoch 1015/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.9034 - val_loss: -8.7445\n",
      "Epoch 1016/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -8.9288 - val_loss: -8.7143\n",
      "Epoch 1017/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -8.9310 - val_loss: -8.7484\n",
      "Epoch 1018/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -8.9074 - val_loss: -8.7491\n",
      "Epoch 1019/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.9149 - val_loss: -8.7512\n",
      "Epoch 1020/5000\n",
      "23/23 [==============================] - 2s 80ms/step - loss: -8.9558 - val_loss: -8.7578\n",
      "Epoch 1021/5000\n",
      "23/23 [==============================] - 4s 199ms/step - loss: -8.9529 - val_loss: -8.7127\n",
      "Epoch 1022/5000\n",
      "23/23 [==============================] - 6s 264ms/step - loss: -8.9394 - val_loss: -8.7130\n",
      "Epoch 1023/5000\n",
      "23/23 [==============================] - 6s 261ms/step - loss: -8.9121 - val_loss: -8.7478\n",
      "Epoch 1024/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -8.8615 - val_loss: -8.7281\n",
      "Epoch 1025/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -8.9335 - val_loss: -8.7333\n",
      "Epoch 1026/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -8.9079 - val_loss: -8.7442\n",
      "Epoch 1027/5000\n",
      "23/23 [==============================] - 2s 77ms/step - loss: -8.9315 - val_loss: -8.7553\n",
      "Epoch 1028/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.9669 - val_loss: -8.7656\n",
      "Epoch 1029/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -8.8469 - val_loss: -8.7595\n",
      "Epoch 1030/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -8.9337 - val_loss: -8.7565\n",
      "Epoch 1031/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.9732 - val_loss: -8.6728\n",
      "Epoch 1032/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.9693 - val_loss: -8.6772\n",
      "Epoch 1033/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -8.9267 - val_loss: -8.7445\n",
      "Epoch 1034/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.9716 - val_loss: -8.7476\n",
      "Epoch 1035/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -8.9271 - val_loss: -8.7458\n",
      "Epoch 1036/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -8.9582 - val_loss: -8.7482\n",
      "Epoch 1037/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -8.9402 - val_loss: -8.7498\n",
      "Epoch 1038/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -8.9681 - val_loss: -8.7507\n",
      "Epoch 1039/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -8.9542 - val_loss: -8.7643\n",
      "Epoch 1040/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -8.8744 - val_loss: -8.7364\n",
      "Epoch 1041/5000\n",
      "23/23 [==============================] - 5s 241ms/step - loss: -8.9522 - val_loss: -8.7565\n",
      "Epoch 1042/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -8.9724 - val_loss: -8.7461\n",
      "Epoch 1043/5000\n",
      "23/23 [==============================] - 6s 265ms/step - loss: -8.9439 - val_loss: -8.7557\n",
      "Epoch 1044/5000\n",
      "23/23 [==============================] - 4s 181ms/step - loss: -8.9332 - val_loss: -8.7552\n",
      "Epoch 1045/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.9536 - val_loss: -8.7568\n",
      "Epoch 1046/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -8.9860 - val_loss: -8.7700\n",
      "Epoch 1047/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.9670 - val_loss: -8.7395\n",
      "Epoch 1048/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.9311 - val_loss: -8.7555\n",
      "Epoch 1049/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -8.9234 - val_loss: -8.7482\n",
      "Epoch 1050/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -8.9092 - val_loss: -8.7736\n",
      "Epoch 1051/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -8.8695 - val_loss: -8.7765\n",
      "Epoch 1052/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.9303 - val_loss: -8.7364\n",
      "Epoch 1053/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.9432 - val_loss: -8.7537\n",
      "Epoch 1054/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -8.9296 - val_loss: -8.7692\n",
      "Epoch 1055/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -8.9426 - val_loss: -8.7489\n",
      "Epoch 1056/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -8.9651 - val_loss: -8.6999\n",
      "Epoch 1057/5000\n",
      "23/23 [==============================] - 5s 225ms/step - loss: -8.9231 - val_loss: -8.7449\n",
      "Epoch 1058/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -8.9578 - val_loss: -8.7653\n",
      "Epoch 1059/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.9821 - val_loss: -8.7571\n",
      "Epoch 1060/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.9367 - val_loss: -8.7690\n",
      "Epoch 1061/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -8.9351 - val_loss: -8.7360\n",
      "Epoch 1062/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -9.0085 - val_loss: -8.7625\n",
      "Epoch 1063/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -8.9361 - val_loss: -8.7638\n",
      "Epoch 1064/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -8.9491 - val_loss: -8.7631\n",
      "Epoch 1065/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -8.8781 - val_loss: -8.6662\n",
      "Epoch 1066/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.8905 - val_loss: -8.7545\n",
      "Epoch 1067/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -8.9591 - val_loss: -8.7669\n",
      "Epoch 1068/5000\n",
      "23/23 [==============================] - 5s 247ms/step - loss: -8.9769 - val_loss: -8.7594\n",
      "Epoch 1069/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -8.9897 - val_loss: -8.7707\n",
      "Epoch 1070/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -8.9351 - val_loss: -8.7781\n",
      "Epoch 1071/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -9.0061 - val_loss: -8.7893\n",
      "Epoch 1072/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -9.0291 - val_loss: -8.7643\n",
      "Epoch 1073/5000\n",
      "23/23 [==============================] - 2s 81ms/step - loss: -8.9881 - val_loss: -8.7694\n",
      "Epoch 1074/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -8.9272 - val_loss: -8.7639\n",
      "Epoch 1075/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.9333 - val_loss: -8.7649\n",
      "Epoch 1076/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -8.9382 - val_loss: -8.7651\n",
      "Epoch 1077/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -8.9636 - val_loss: -8.7709\n",
      "Epoch 1078/5000\n",
      "23/23 [==============================] - 3s 120ms/step - loss: -9.0178 - val_loss: -8.7534\n",
      "Epoch 1079/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -8.9150 - val_loss: -8.7747\n",
      "Epoch 1080/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.9902 - val_loss: -8.7585\n",
      "Epoch 1081/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.9860 - val_loss: -8.8086\n",
      "Epoch 1082/5000\n",
      "23/23 [==============================] - 5s 248ms/step - loss: -9.0335 - val_loss: -8.7910\n",
      "Epoch 1083/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -8.9732 - val_loss: -8.7720\n",
      "Epoch 1084/5000\n",
      "23/23 [==============================] - 6s 265ms/step - loss: -8.9577 - val_loss: -8.7460\n",
      "Epoch 1085/5000\n",
      "23/23 [==============================] - 6s 265ms/step - loss: -8.9901 - val_loss: -8.7610\n",
      "Epoch 1086/5000\n",
      "23/23 [==============================] - 6s 264ms/step - loss: -8.9981 - val_loss: -8.7912\n",
      "Epoch 1087/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.9254 - val_loss: -8.7816\n",
      "Epoch 1088/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.9378 - val_loss: -8.7678\n",
      "Epoch 1089/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -8.9963 - val_loss: -8.7724\n",
      "Epoch 1090/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.9767 - val_loss: -8.7937\n",
      "Epoch 1091/5000\n",
      "23/23 [==============================] - 3s 113ms/step - loss: -9.0149 - val_loss: -8.7803\n",
      "Epoch 1092/5000\n",
      "23/23 [==============================] - 6s 260ms/step - loss: -9.0118 - val_loss: -8.7695\n",
      "Epoch 1093/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -8.9771 - val_loss: -8.7596\n",
      "Epoch 1094/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.0264 - val_loss: -8.7557\n",
      "Epoch 1095/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -8.9494 - val_loss: -8.7958\n",
      "Epoch 1096/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.9750 - val_loss: -8.7792\n",
      "Epoch 1097/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.8878 - val_loss: -8.7555\n",
      "Epoch 1098/5000\n",
      "23/23 [==============================] - 2s 81ms/step - loss: -9.0354 - val_loss: -8.7728\n",
      "Epoch 1099/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -8.9168 - val_loss: -8.7793\n",
      "Epoch 1100/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -8.9884 - val_loss: -8.7768\n",
      "Epoch 1101/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.9572 - val_loss: -8.7853\n",
      "Epoch 1102/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -8.9978 - val_loss: -8.7769\n",
      "Epoch 1103/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.0095 - val_loss: -8.7945\n",
      "Epoch 1104/5000\n",
      "23/23 [==============================] - 2s 81ms/step - loss: -9.0248 - val_loss: -8.7789\n",
      "Epoch 1105/5000\n",
      "23/23 [==============================] - 5s 241ms/step - loss: -8.9045 - val_loss: -8.8029\n",
      "Epoch 1106/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -8.9872 - val_loss: -8.7794\n",
      "Epoch 1107/5000\n",
      "23/23 [==============================] - 3s 138ms/step - loss: -9.0294 - val_loss: -8.8012\n",
      "Epoch 1108/5000\n",
      "23/23 [==============================] - 6s 261ms/step - loss: -8.9826 - val_loss: -8.8085\n",
      "Epoch 1109/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -8.9622 - val_loss: -8.7995\n",
      "Epoch 1110/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.0151 - val_loss: -8.7952\n",
      "Epoch 1111/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -8.9689 - val_loss: -8.7917\n",
      "Epoch 1112/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -8.9812 - val_loss: -8.7797\n",
      "Epoch 1113/5000\n",
      "23/23 [==============================] - 2s 81ms/step - loss: -8.9568 - val_loss: -8.7887\n",
      "Epoch 1114/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.0295 - val_loss: -8.7846\n",
      "Epoch 1115/5000\n",
      "23/23 [==============================] - 4s 191ms/step - loss: -8.9793 - val_loss: -8.7935\n",
      "Epoch 1116/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.9179 - val_loss: -8.7844\n",
      "Epoch 1117/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.0019 - val_loss: -8.7865\n",
      "Epoch 1118/5000\n",
      "23/23 [==============================] - 6s 263ms/step - loss: -9.0011 - val_loss: -8.8041\n",
      "Epoch 1119/5000\n",
      "23/23 [==============================] - 6s 264ms/step - loss: -8.9886 - val_loss: -8.7953\n",
      "Epoch 1120/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.0441 - val_loss: -8.8113\n",
      "Epoch 1121/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -8.9495 - val_loss: -8.7811\n",
      "Epoch 1122/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -9.0098 - val_loss: -8.8068\n",
      "Epoch 1123/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.9877 - val_loss: -8.8047\n",
      "Epoch 1124/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -8.9602 - val_loss: -8.8111\n",
      "Epoch 1125/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.0275 - val_loss: -8.8111\n",
      "Epoch 1126/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.9626 - val_loss: -8.7714\n",
      "Epoch 1127/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -8.9534 - val_loss: -8.7403\n",
      "Epoch 1128/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.9791 - val_loss: -8.7911\n",
      "Epoch 1129/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.9914 - val_loss: -8.8012\n",
      "Epoch 1130/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -8.9930 - val_loss: -8.7918\n",
      "Epoch 1131/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -8.9922 - val_loss: -8.7838\n",
      "Epoch 1132/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.0109 - val_loss: -8.7895\n",
      "Epoch 1133/5000\n",
      "23/23 [==============================] - 2s 81ms/step - loss: -9.0307 - val_loss: -8.7906\n",
      "Epoch 1134/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.9823 - val_loss: -8.7965\n",
      "Epoch 1135/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -8.9927 - val_loss: -8.8121\n",
      "Epoch 1136/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.9883 - val_loss: -8.7619\n",
      "Epoch 1137/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -8.8954 - val_loss: -8.8015\n",
      "Epoch 1138/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.9845 - val_loss: -8.8072\n",
      "Epoch 1139/5000\n",
      "23/23 [==============================] - 3s 150ms/step - loss: -8.9827 - val_loss: -8.7792\n",
      "Epoch 1140/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -9.0091 - val_loss: -8.7922\n",
      "Epoch 1141/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.0082 - val_loss: -8.7868\n",
      "Epoch 1142/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -8.8996 - val_loss: -8.8176\n",
      "Epoch 1143/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.9743 - val_loss: -8.7909\n",
      "Epoch 1144/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -8.9825 - val_loss: -8.8039\n",
      "Epoch 1145/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.0256 - val_loss: -8.8095\n",
      "Epoch 1146/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.0330 - val_loss: -8.8241\n",
      "Epoch 1147/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -9.0308 - val_loss: -8.8081\n",
      "Epoch 1148/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.0040 - val_loss: -8.7834\n",
      "Epoch 1149/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.0314 - val_loss: -8.7924\n",
      "Epoch 1150/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.0200 - val_loss: -8.7816\n",
      "Epoch 1151/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.0161 - val_loss: -8.8102\n",
      "Epoch 1152/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.0441 - val_loss: -8.7926\n",
      "Epoch 1153/5000\n",
      "23/23 [==============================] - 2s 104ms/step - loss: -9.0151 - val_loss: -8.8175\n",
      "Epoch 1154/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.0047 - val_loss: -8.8159\n",
      "Epoch 1155/5000\n",
      "23/23 [==============================] - 5s 249ms/step - loss: -8.9434 - val_loss: -8.8028\n",
      "Epoch 1156/5000\n",
      "23/23 [==============================] - 6s 268ms/step - loss: -9.0236 - val_loss: -8.8048\n",
      "Epoch 1157/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -8.9680 - val_loss: -8.8009\n",
      "Epoch 1158/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -9.0291 - val_loss: -8.8162\n",
      "Epoch 1159/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.0674 - val_loss: -8.8103\n",
      "Epoch 1160/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.0279 - val_loss: -8.8057\n",
      "Epoch 1161/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.0370 - val_loss: -8.7776\n",
      "Epoch 1162/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -8.8746 - val_loss: -8.8282\n",
      "Epoch 1163/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.0378 - val_loss: -8.7682\n",
      "Epoch 1164/5000\n",
      "23/23 [==============================] - 2s 108ms/step - loss: -8.9572 - val_loss: -8.8186\n",
      "Epoch 1165/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.0349 - val_loss: -8.8187\n",
      "Epoch 1166/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.9864 - val_loss: -8.8290\n",
      "Epoch 1167/5000\n",
      "23/23 [==============================] - 2s 79ms/step - loss: -9.0632 - val_loss: -8.8018\n",
      "Epoch 1168/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.9623 - val_loss: -8.8105\n",
      "Epoch 1169/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.0700 - val_loss: -8.8190\n",
      "Epoch 1170/5000\n",
      "23/23 [==============================] - 2s 77ms/step - loss: -8.9904 - val_loss: -8.7854\n",
      "Epoch 1171/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.0433 - val_loss: -8.8238\n",
      "Epoch 1172/5000\n",
      "23/23 [==============================] - 3s 144ms/step - loss: -8.9876 - val_loss: -8.8219\n",
      "Epoch 1173/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -8.9894 - val_loss: -8.8259\n",
      "Epoch 1174/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.9209 - val_loss: -8.8132\n",
      "Epoch 1175/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -9.0285 - val_loss: -8.8256\n",
      "Epoch 1176/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.9804 - val_loss: -8.8069\n",
      "Epoch 1177/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -8.9768 - val_loss: -8.8125\n",
      "Epoch 1178/5000\n",
      "23/23 [==============================] - 3s 155ms/step - loss: -8.9715 - val_loss: -8.8184\n",
      "Epoch 1179/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.0039 - val_loss: -8.8382\n",
      "Epoch 1180/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -8.9934 - val_loss: -8.8461\n",
      "Epoch 1181/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.9763 - val_loss: -8.8323\n",
      "Epoch 1182/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -8.9920 - val_loss: -8.7977\n",
      "Epoch 1183/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -9.0166 - val_loss: -8.8217\n",
      "Epoch 1184/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.0534 - val_loss: -8.8140\n",
      "Epoch 1185/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.0336 - val_loss: -8.6661\n",
      "Epoch 1186/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.0314 - val_loss: -8.8195\n",
      "Epoch 1187/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -9.0384 - val_loss: -8.8286\n",
      "Epoch 1188/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -9.0524 - val_loss: -8.8121\n",
      "Epoch 1189/5000\n",
      "23/23 [==============================] - 2s 81ms/step - loss: -9.0078 - val_loss: -8.7829\n",
      "Epoch 1190/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.9902 - val_loss: -8.8088\n",
      "Epoch 1191/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.0092 - val_loss: -8.8134\n",
      "Epoch 1192/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.9123 - val_loss: -8.8117\n",
      "Epoch 1193/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.9961 - val_loss: -8.8057\n",
      "Epoch 1194/5000\n",
      "23/23 [==============================] - 6s 265ms/step - loss: -9.0433 - val_loss: -8.8277\n",
      "Epoch 1195/5000\n",
      "23/23 [==============================] - 3s 113ms/step - loss: -8.9744 - val_loss: -8.8315\n",
      "Epoch 1196/5000\n",
      "23/23 [==============================] - 2s 81ms/step - loss: -9.0513 - val_loss: -8.8179\n",
      "Epoch 1197/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -9.0589 - val_loss: -8.8311\n",
      "Epoch 1198/5000\n",
      "23/23 [==============================] - 2s 74ms/step - loss: -8.9255 - val_loss: -8.8131\n",
      "Epoch 1199/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.0083 - val_loss: -8.8233\n",
      "Epoch 1200/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.0404 - val_loss: -8.8339\n",
      "Epoch 1201/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.0527 - val_loss: -8.8031\n",
      "Epoch 1202/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -9.0152 - val_loss: -8.8315\n",
      "Epoch 1203/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.0375 - val_loss: -8.8109\n",
      "Epoch 1204/5000\n",
      "23/23 [==============================] - 2s 80ms/step - loss: -9.0273 - val_loss: -8.8299\n",
      "Epoch 1205/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.0401 - val_loss: -8.8142\n",
      "Epoch 1206/5000\n",
      "23/23 [==============================] - 2s 80ms/step - loss: -8.9875 - val_loss: -8.8433\n",
      "Epoch 1207/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -8.9289 - val_loss: -8.8095\n",
      "Epoch 1208/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -8.8932 - val_loss: -8.8381\n",
      "Epoch 1209/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.9800 - val_loss: -8.8417\n",
      "Epoch 1210/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -9.0057 - val_loss: -8.8319\n",
      "Epoch 1211/5000\n",
      "23/23 [==============================] - 3s 132ms/step - loss: -8.9709 - val_loss: -8.8140\n",
      "Epoch 1212/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.0613 - val_loss: -8.8256\n",
      "Epoch 1213/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -9.0002 - val_loss: -8.8400\n",
      "Epoch 1214/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -9.0166 - val_loss: -8.8185\n",
      "Epoch 1215/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.0296 - val_loss: -8.8185\n",
      "Epoch 1216/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.9682 - val_loss: -8.8503\n",
      "Epoch 1217/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.0339 - val_loss: -8.8020\n",
      "Epoch 1218/5000\n",
      "23/23 [==============================] - 2s 79ms/step - loss: -8.9961 - val_loss: -8.8333\n",
      "Epoch 1219/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.0345 - val_loss: -8.8409\n",
      "Epoch 1220/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.0620 - val_loss: -8.8306\n",
      "Epoch 1221/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.0847 - val_loss: -8.8441\n",
      "Epoch 1222/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -9.0616 - val_loss: -8.8383\n",
      "Epoch 1223/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -8.9998 - val_loss: -8.8466\n",
      "Epoch 1224/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.0433 - val_loss: -8.8399\n",
      "Epoch 1225/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.0433 - val_loss: -8.8225\n",
      "Epoch 1226/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.0215 - val_loss: -8.8521\n",
      "Epoch 1227/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.0726 - val_loss: -8.8515\n",
      "Epoch 1228/5000\n",
      "23/23 [==============================] - 2s 81ms/step - loss: -9.0259 - val_loss: -8.8442\n",
      "Epoch 1229/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -9.0447 - val_loss: -8.8643\n",
      "Epoch 1230/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.0341 - val_loss: -8.8353\n",
      "Epoch 1231/5000\n",
      "23/23 [==============================] - 2s 104ms/step - loss: -8.9431 - val_loss: -8.8601\n",
      "Epoch 1232/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.0750 - val_loss: -8.8030\n",
      "Epoch 1233/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -8.9852 - val_loss: -8.8043\n",
      "Epoch 1234/5000\n",
      "23/23 [==============================] - 2s 81ms/step - loss: -9.1070 - val_loss: -8.8293\n",
      "Epoch 1235/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -8.9881 - val_loss: -8.8533\n",
      "Epoch 1236/5000\n",
      "23/23 [==============================] - 5s 239ms/step - loss: -9.0955 - val_loss: -8.8448\n",
      "Epoch 1237/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -9.0410 - val_loss: -8.8440\n",
      "Epoch 1238/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.0078 - val_loss: -8.8704\n",
      "Epoch 1239/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.9568 - val_loss: -8.8461\n",
      "Epoch 1240/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.0424 - val_loss: -8.8460\n",
      "Epoch 1241/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.0705 - val_loss: -8.8333\n",
      "Epoch 1242/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -8.9562 - val_loss: -8.8588\n",
      "Epoch 1243/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.0456 - val_loss: -8.8635\n",
      "Epoch 1244/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.0721 - val_loss: -8.8384\n",
      "Epoch 1245/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.0439 - val_loss: -8.8428\n",
      "Epoch 1246/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -8.9726 - val_loss: -8.8504\n",
      "Epoch 1247/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -8.9750 - val_loss: -8.8512\n",
      "Epoch 1248/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -9.0342 - val_loss: -8.8576\n",
      "Epoch 1249/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -9.0597 - val_loss: -8.8665\n",
      "Epoch 1250/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.0212 - val_loss: -8.8678\n",
      "Epoch 1251/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -8.9991 - val_loss: -8.8337\n",
      "Epoch 1252/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.0693 - val_loss: -8.8519\n",
      "Epoch 1253/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -9.0887 - val_loss: -8.8621\n",
      "Epoch 1254/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -9.0588 - val_loss: -8.8604\n",
      "Epoch 1255/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.0244 - val_loss: -8.8470\n",
      "Epoch 1256/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -9.0344 - val_loss: -8.8392\n",
      "Epoch 1257/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -9.0008 - val_loss: -8.8646\n",
      "Epoch 1258/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -8.9859 - val_loss: -8.8843\n",
      "Epoch 1259/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -9.0510 - val_loss: -8.8360\n",
      "Epoch 1260/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -9.0136 - val_loss: -8.8537\n",
      "Epoch 1261/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.0241 - val_loss: -8.8523\n",
      "Epoch 1262/5000\n",
      "23/23 [==============================] - 2s 81ms/step - loss: -9.0608 - val_loss: -8.8501\n",
      "Epoch 1263/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -9.0498 - val_loss: -8.8722\n",
      "Epoch 1264/5000\n",
      "23/23 [==============================] - 2s 110ms/step - loss: -9.0456 - val_loss: -8.8808\n",
      "Epoch 1265/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -8.9720 - val_loss: -8.8672\n",
      "Epoch 1266/5000\n",
      "23/23 [==============================] - 5s 245ms/step - loss: -9.0418 - val_loss: -8.8778\n",
      "Epoch 1267/5000\n",
      "23/23 [==============================] - 5s 230ms/step - loss: -9.0405 - val_loss: -8.8592\n",
      "Epoch 1268/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.0139 - val_loss: -8.8446\n",
      "Epoch 1269/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.0087 - val_loss: -8.8643\n",
      "Epoch 1270/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.0474 - val_loss: -8.8692\n",
      "Epoch 1271/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.0711 - val_loss: -8.8130\n",
      "Epoch 1272/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.0269 - val_loss: -8.8697\n",
      "Epoch 1273/5000\n",
      "23/23 [==============================] - 2s 81ms/step - loss: -9.0926 - val_loss: -8.8531\n",
      "Epoch 1274/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.0292 - val_loss: -8.8611\n",
      "Epoch 1275/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.9860 - val_loss: -8.8330\n",
      "Epoch 1276/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.9666 - val_loss: -8.8831\n",
      "Epoch 1277/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.0977 - val_loss: -8.8853\n",
      "Epoch 1278/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.0479 - val_loss: -8.8743\n",
      "Epoch 1279/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.0433 - val_loss: -8.8701\n",
      "Epoch 1280/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.0785 - val_loss: -8.8670\n",
      "Epoch 1281/5000\n",
      "23/23 [==============================] - 6s 264ms/step - loss: -8.9514 - val_loss: -8.8409\n",
      "Epoch 1282/5000\n",
      "23/23 [==============================] - 11s 476ms/step - loss: -9.0298 - val_loss: -8.8565\n",
      "Epoch 1283/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.0380 - val_loss: -8.8423\n",
      "Epoch 1284/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -9.0576 - val_loss: -8.8701\n",
      "Epoch 1285/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -9.0605 - val_loss: -8.8722\n",
      "Epoch 1286/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.0464 - val_loss: -8.8443\n",
      "Epoch 1287/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -9.0337 - val_loss: -8.8000\n",
      "Epoch 1288/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.0575 - val_loss: -8.8636\n",
      "Epoch 1289/5000\n",
      "23/23 [==============================] - 5s 219ms/step - loss: -8.8647 - val_loss: -8.8630\n",
      "Epoch 1290/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -9.1232 - val_loss: -8.8570\n",
      "Epoch 1291/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.0712 - val_loss: -8.8860\n",
      "Epoch 1292/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.0769 - val_loss: -8.8895\n",
      "Epoch 1293/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.0345 - val_loss: -8.8552\n",
      "Epoch 1294/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.0862 - val_loss: -8.8684\n",
      "Epoch 1295/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.0315 - val_loss: -8.8709\n",
      "Epoch 1296/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.0706 - val_loss: -8.8550\n",
      "Epoch 1297/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.0166 - val_loss: -8.8809\n",
      "Epoch 1298/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -8.9802 - val_loss: -8.8665\n",
      "Epoch 1299/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -8.9202 - val_loss: -8.8608\n",
      "Epoch 1300/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.1029 - val_loss: -8.8897\n",
      "Epoch 1301/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.0117 - val_loss: -8.8624\n",
      "Epoch 1302/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.0700 - val_loss: -8.8534\n",
      "Epoch 1303/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -9.0341 - val_loss: -8.8755\n",
      "Epoch 1304/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.0576 - val_loss: -8.8981\n",
      "Epoch 1305/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.0637 - val_loss: -8.8797\n",
      "Epoch 1306/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.0438 - val_loss: -8.8492\n",
      "Epoch 1307/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.0601 - val_loss: -8.8847\n",
      "Epoch 1308/5000\n",
      "23/23 [==============================] - 4s 188ms/step - loss: -9.0277 - val_loss: -8.8553\n",
      "Epoch 1309/5000\n",
      "23/23 [==============================] - 10s 475ms/step - loss: -9.0253 - val_loss: -8.8720\n",
      "Epoch 1310/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.0505 - val_loss: -8.8730\n",
      "Epoch 1311/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -8.9324 - val_loss: -8.8769\n",
      "Epoch 1312/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -9.0846 - val_loss: -8.8809\n",
      "Epoch 1313/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -8.8902 - val_loss: -8.8880\n",
      "Epoch 1314/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.0679 - val_loss: -8.8892\n",
      "Epoch 1315/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -9.0329 - val_loss: -8.8756\n",
      "Epoch 1316/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.0895 - val_loss: -8.8822\n",
      "Epoch 1317/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -9.0539 - val_loss: -8.8785\n",
      "Epoch 1318/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.1241 - val_loss: -8.8958\n",
      "Epoch 1319/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.0641 - val_loss: -8.8884\n",
      "Epoch 1320/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -9.0785 - val_loss: -8.8736\n",
      "Epoch 1321/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -8.9657 - val_loss: -8.8642\n",
      "Epoch 1322/5000\n",
      "23/23 [==============================] - 3s 132ms/step - loss: -9.0420 - val_loss: -8.8645\n",
      "Epoch 1323/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -9.0897 - val_loss: -8.8920\n",
      "Epoch 1324/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.1296 - val_loss: -8.8874\n",
      "Epoch 1325/5000\n",
      "23/23 [==============================] - 2s 104ms/step - loss: -9.0835 - val_loss: -8.8982\n",
      "Epoch 1326/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -9.0781 - val_loss: -8.8890\n",
      "Epoch 1327/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.0776 - val_loss: -8.8763\n",
      "Epoch 1328/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.0717 - val_loss: -8.9098\n",
      "Epoch 1329/5000\n",
      "23/23 [==============================] - 2s 104ms/step - loss: -9.0919 - val_loss: -8.8805\n",
      "Epoch 1330/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.0381 - val_loss: -8.8806\n",
      "Epoch 1331/5000\n",
      "23/23 [==============================] - 2s 109ms/step - loss: -9.0300 - val_loss: -8.8897\n",
      "Epoch 1332/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.0660 - val_loss: -8.8675\n",
      "Epoch 1333/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.1405 - val_loss: -8.8814\n",
      "Epoch 1334/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -9.0696 - val_loss: -8.9052\n",
      "Epoch 1335/5000\n",
      "23/23 [==============================] - 2s 104ms/step - loss: -9.0866 - val_loss: -8.8922\n",
      "Epoch 1336/5000\n",
      "23/23 [==============================] - 6s 267ms/step - loss: -9.1080 - val_loss: -8.9067\n",
      "Epoch 1337/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.0825 - val_loss: -8.8855\n",
      "Epoch 1338/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -8.9225 - val_loss: -8.8441\n",
      "Epoch 1339/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.0871 - val_loss: -8.8787\n",
      "Epoch 1340/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.1001 - val_loss: -8.8965\n",
      "Epoch 1341/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -9.1074 - val_loss: -8.8925\n",
      "Epoch 1342/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.1024 - val_loss: -8.8878\n",
      "Epoch 1343/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.0576 - val_loss: -8.8812\n",
      "Epoch 1344/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.0834 - val_loss: -8.8922\n",
      "Epoch 1345/5000\n",
      "23/23 [==============================] - 2s 81ms/step - loss: -9.0241 - val_loss: -8.8769\n",
      "Epoch 1346/5000\n",
      "23/23 [==============================] - 5s 241ms/step - loss: -9.0894 - val_loss: -8.8626\n",
      "Epoch 1347/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1011 - val_loss: -8.8871\n",
      "Epoch 1348/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.0591 - val_loss: -8.8711\n",
      "Epoch 1349/5000\n",
      "23/23 [==============================] - 6s 266ms/step - loss: -9.0516 - val_loss: -8.8870\n",
      "Epoch 1350/5000\n",
      "23/23 [==============================] - 6s 270ms/step - loss: -9.1108 - val_loss: -8.9208\n",
      "Epoch 1351/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.0176 - val_loss: -8.8891\n",
      "Epoch 1352/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.1359 - val_loss: -8.8816\n",
      "Epoch 1353/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -8.9955 - val_loss: -8.9248\n",
      "Epoch 1354/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.0946 - val_loss: -8.9028\n",
      "Epoch 1355/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.0787 - val_loss: -8.8757\n",
      "Epoch 1356/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.0731 - val_loss: -8.9134\n",
      "Epoch 1357/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -9.1328 - val_loss: -8.8941\n",
      "Epoch 1358/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -9.1053 - val_loss: -8.8912\n",
      "Epoch 1359/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.1176 - val_loss: -8.8826\n",
      "Epoch 1360/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -9.0858 - val_loss: -8.9063\n",
      "Epoch 1361/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.1474 - val_loss: -8.9047\n",
      "Epoch 1362/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1715 - val_loss: -8.9092\n",
      "Epoch 1363/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1439 - val_loss: -8.8933\n",
      "Epoch 1364/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.0878 - val_loss: -8.9245\n",
      "Epoch 1365/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.0654 - val_loss: -8.9060\n",
      "Epoch 1366/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.0910 - val_loss: -8.9034\n",
      "Epoch 1367/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -9.0785 - val_loss: -8.8904\n",
      "Epoch 1368/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.0760 - val_loss: -8.8674\n",
      "Epoch 1369/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -9.0108 - val_loss: -8.8863\n",
      "Epoch 1370/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.1051 - val_loss: -8.8885\n",
      "Epoch 1371/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.0986 - val_loss: -8.9172\n",
      "Epoch 1372/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -9.0314 - val_loss: -8.8906\n",
      "Epoch 1373/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.0620 - val_loss: -8.8917\n",
      "Epoch 1374/5000\n",
      "23/23 [==============================] - 3s 121ms/step - loss: -9.0279 - val_loss: -8.9095\n",
      "Epoch 1375/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -9.1373 - val_loss: -8.8906\n",
      "Epoch 1376/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.1388 - val_loss: -8.8696\n",
      "Epoch 1377/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -9.0907 - val_loss: -8.9152\n",
      "Epoch 1378/5000\n",
      "23/23 [==============================] - 4s 196ms/step - loss: -9.1094 - val_loss: -8.8920\n",
      "Epoch 1379/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1119 - val_loss: -8.8879\n",
      "Epoch 1380/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -9.0966 - val_loss: -8.8824\n",
      "Epoch 1381/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.0834 - val_loss: -8.9149\n",
      "Epoch 1382/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.0914 - val_loss: -8.9176\n",
      "Epoch 1383/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -9.0653 - val_loss: -8.8425\n",
      "Epoch 1384/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.1038 - val_loss: -8.9200\n",
      "Epoch 1385/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1139 - val_loss: -8.9120\n",
      "Epoch 1386/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.1038 - val_loss: -8.8911\n",
      "Epoch 1387/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.1731 - val_loss: -8.9046\n",
      "Epoch 1388/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -9.0610 - val_loss: -8.9144\n",
      "Epoch 1389/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.1080 - val_loss: -8.9079\n",
      "Epoch 1390/5000\n",
      "23/23 [==============================] - 4s 183ms/step - loss: -9.1254 - val_loss: -8.8911\n",
      "Epoch 1391/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1017 - val_loss: -8.9205\n",
      "Epoch 1392/5000\n",
      "23/23 [==============================] - 6s 269ms/step - loss: -9.0856 - val_loss: -8.9071\n",
      "Epoch 1393/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -9.1440 - val_loss: -8.9190\n",
      "Epoch 1394/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.0332 - val_loss: -8.9156\n",
      "Epoch 1395/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -9.1073 - val_loss: -8.9030\n",
      "Epoch 1396/5000\n",
      "23/23 [==============================] - 2s 81ms/step - loss: -9.1552 - val_loss: -8.8966\n",
      "Epoch 1397/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.1257 - val_loss: -8.9077\n",
      "Epoch 1398/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.0010 - val_loss: -8.9445\n",
      "Epoch 1399/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.0773 - val_loss: -8.9091\n",
      "Epoch 1400/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -9.1154 - val_loss: -8.9252\n",
      "Epoch 1401/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -9.1345 - val_loss: -8.9180\n",
      "Epoch 1402/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.0181 - val_loss: -8.9069\n",
      "Epoch 1403/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.1516 - val_loss: -8.9164\n",
      "Epoch 1404/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -9.1431 - val_loss: -8.9120\n",
      "Epoch 1405/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -9.1341 - val_loss: -8.9154\n",
      "Epoch 1406/5000\n",
      "23/23 [==============================] - 2s 112ms/step - loss: -9.0593 - val_loss: -8.9013\n",
      "Epoch 1407/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.0853 - val_loss: -8.8665\n",
      "Epoch 1408/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.0825 - val_loss: -8.9078\n",
      "Epoch 1409/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.0896 - val_loss: -8.8975\n",
      "Epoch 1410/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.1625 - val_loss: -8.9156\n",
      "Epoch 1411/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -9.1091 - val_loss: -8.9139\n",
      "Epoch 1412/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -9.0203 - val_loss: -8.9180\n",
      "Epoch 1413/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.0994 - val_loss: -8.9062\n",
      "Epoch 1414/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1024 - val_loss: -8.9167\n",
      "Epoch 1415/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.0906 - val_loss: -8.8949\n",
      "Epoch 1416/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.0850 - val_loss: -8.9182\n",
      "Epoch 1417/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.1827 - val_loss: -8.9136\n",
      "Epoch 1418/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1847 - val_loss: -8.9227\n",
      "Epoch 1419/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -8.9298 - val_loss: -8.9218\n",
      "Epoch 1420/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -9.1343 - val_loss: -8.9011\n",
      "Epoch 1421/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -9.1055 - val_loss: -8.9227\n",
      "Epoch 1422/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1448 - val_loss: -8.8960\n",
      "Epoch 1423/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.1089 - val_loss: -8.9122\n",
      "Epoch 1424/5000\n",
      "23/23 [==============================] - 4s 193ms/step - loss: -9.1238 - val_loss: -8.9156\n",
      "Epoch 1425/5000\n",
      "23/23 [==============================] - 2s 108ms/step - loss: -9.1194 - val_loss: -8.9101\n",
      "Epoch 1426/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -9.0899 - val_loss: -8.8918\n",
      "Epoch 1427/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.0591 - val_loss: -8.9081\n",
      "Epoch 1428/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -9.0849 - val_loss: -8.9250\n",
      "Epoch 1429/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -8.9763 - val_loss: -8.9279\n",
      "Epoch 1430/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.1328 - val_loss: -8.9393\n",
      "Epoch 1431/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.0927 - val_loss: -8.9137\n",
      "Epoch 1432/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -9.0811 - val_loss: -8.9204\n",
      "Epoch 1433/5000\n",
      "23/23 [==============================] - 5s 241ms/step - loss: -9.1011 - val_loss: -8.9182\n",
      "Epoch 1434/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.1585 - val_loss: -8.9345\n",
      "Epoch 1435/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1173 - val_loss: -8.9306\n",
      "Epoch 1436/5000\n",
      "23/23 [==============================] - 2s 73ms/step - loss: -9.0825 - val_loss: -8.9095\n",
      "Epoch 1437/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.1883 - val_loss: -8.9318\n",
      "Epoch 1438/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1565 - val_loss: -8.9042\n",
      "Epoch 1439/5000\n",
      "23/23 [==============================] - 4s 163ms/step - loss: -9.0974 - val_loss: -8.9181\n",
      "Epoch 1440/5000\n",
      "23/23 [==============================] - 6s 263ms/step - loss: -9.0525 - val_loss: -8.9063\n",
      "Epoch 1441/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.1601 - val_loss: -8.9216\n",
      "Epoch 1442/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.1234 - val_loss: -8.9244\n",
      "Epoch 1443/5000\n",
      "23/23 [==============================] - 2s 81ms/step - loss: -8.9809 - val_loss: -8.9333\n",
      "Epoch 1444/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -9.1133 - val_loss: -8.9242\n",
      "Epoch 1445/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -9.1913 - val_loss: -8.9183\n",
      "Epoch 1446/5000\n",
      "23/23 [==============================] - 2s 81ms/step - loss: -9.1268 - val_loss: -8.9130\n",
      "Epoch 1447/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.1724 - val_loss: -8.9205\n",
      "Epoch 1448/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.0904 - val_loss: -8.9326\n",
      "Epoch 1449/5000\n",
      "23/23 [==============================] - 2s 79ms/step - loss: -9.0993 - val_loss: -8.9239\n",
      "Epoch 1450/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.1085 - val_loss: -8.9300\n",
      "Epoch 1451/5000\n",
      "23/23 [==============================] - 2s 81ms/step - loss: -9.0134 - val_loss: -8.9273\n",
      "Epoch 1452/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.1076 - val_loss: -8.9391\n",
      "Epoch 1453/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.0259 - val_loss: -8.9096\n",
      "Epoch 1454/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -9.0978 - val_loss: -8.9149\n",
      "Epoch 1455/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.0804 - val_loss: -8.9336\n",
      "Epoch 1456/5000\n",
      "23/23 [==============================] - 2s 80ms/step - loss: -9.1053 - val_loss: -8.9401\n",
      "Epoch 1457/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.0086 - val_loss: -8.9299\n",
      "Epoch 1458/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -9.1121 - val_loss: -8.9341\n",
      "Epoch 1459/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.1199 - val_loss: -8.9489\n",
      "Epoch 1460/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.0992 - val_loss: -8.9291\n",
      "Epoch 1461/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.1243 - val_loss: -8.9325\n",
      "Epoch 1462/5000\n",
      "23/23 [==============================] - 2s 79ms/step - loss: -9.1149 - val_loss: -8.9235\n",
      "Epoch 1463/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -9.1513 - val_loss: -8.9235\n",
      "Epoch 1464/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1228 - val_loss: -8.9053\n",
      "Epoch 1465/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.0655 - val_loss: -8.9008\n",
      "Epoch 1466/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.1551 - val_loss: -8.9317\n",
      "Epoch 1467/5000\n",
      "23/23 [==============================] - 6s 263ms/step - loss: -9.1240 - val_loss: -8.9413\n",
      "Epoch 1468/5000\n",
      "23/23 [==============================] - 2s 80ms/step - loss: -9.0539 - val_loss: -8.9440\n",
      "Epoch 1469/5000\n",
      "23/23 [==============================] - 2s 108ms/step - loss: -9.0422 - val_loss: -8.9010\n",
      "Epoch 1470/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -8.9910 - val_loss: -8.9245\n",
      "Epoch 1471/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.0590 - val_loss: -8.9283\n",
      "Epoch 1472/5000\n",
      "23/23 [==============================] - 2s 81ms/step - loss: -9.1226 - val_loss: -8.9240\n",
      "Epoch 1473/5000\n",
      "23/23 [==============================] - 5s 216ms/step - loss: -9.1214 - val_loss: -8.9425\n",
      "Epoch 1474/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.1744 - val_loss: -8.9482\n",
      "Epoch 1475/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.1287 - val_loss: -8.9286\n",
      "Epoch 1476/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -9.0752 - val_loss: -8.9345\n",
      "Epoch 1477/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.0413 - val_loss: -8.9214\n",
      "Epoch 1478/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -9.1254 - val_loss: -8.9400\n",
      "Epoch 1479/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.0149 - val_loss: -8.9472\n",
      "Epoch 1480/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -9.1542 - val_loss: -8.9428\n",
      "Epoch 1481/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -9.1534 - val_loss: -8.9301\n",
      "Epoch 1482/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.1477 - val_loss: -8.9462\n",
      "Epoch 1483/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -9.1030 - val_loss: -8.9279\n",
      "Epoch 1484/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -8.8474 - val_loss: -8.9298\n",
      "Epoch 1485/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.1415 - val_loss: -8.9309\n",
      "Epoch 1486/5000\n",
      "23/23 [==============================] - 2s 112ms/step - loss: -9.0240 - val_loss: -8.9397\n",
      "Epoch 1487/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.1205 - val_loss: -8.9228\n",
      "Epoch 1488/5000\n",
      "23/23 [==============================] - 2s 104ms/step - loss: -8.9409 - val_loss: -8.9229\n",
      "Epoch 1489/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.1394 - val_loss: -8.9222\n",
      "Epoch 1490/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.1208 - val_loss: -8.9368\n",
      "Epoch 1491/5000\n",
      "23/23 [==============================] - 4s 160ms/step - loss: -9.1535 - val_loss: -8.9352\n",
      "Epoch 1492/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.1214 - val_loss: -8.9407\n",
      "Epoch 1493/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -9.0971 - val_loss: -8.8988\n",
      "Epoch 1494/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.1022 - val_loss: -8.9184\n",
      "Epoch 1495/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.1674 - val_loss: -8.9555\n",
      "Epoch 1496/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.1274 - val_loss: -8.9475\n",
      "Epoch 1497/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1224 - val_loss: -8.9407\n",
      "Epoch 1498/5000\n",
      "23/23 [==============================] - 2s 109ms/step - loss: -9.1472 - val_loss: -8.9394\n",
      "Epoch 1499/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -9.1251 - val_loss: -8.9536\n",
      "Epoch 1500/5000\n",
      "23/23 [==============================] - 5s 246ms/step - loss: -9.1581 - val_loss: -8.9497\n",
      "Epoch 1501/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.1974 - val_loss: -8.9398\n",
      "Epoch 1502/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -9.1477 - val_loss: -8.9397\n",
      "Epoch 1503/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.0837 - val_loss: -8.9439\n",
      "Epoch 1504/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.0852 - val_loss: -8.9210\n",
      "Epoch 1505/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.0733 - val_loss: -8.9365\n",
      "Epoch 1506/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.0806 - val_loss: -8.9244\n",
      "Epoch 1507/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -9.0528 - val_loss: -8.9177\n",
      "Epoch 1508/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -9.1228 - val_loss: -8.9392\n",
      "Epoch 1509/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.1423 - val_loss: -8.9456\n",
      "Epoch 1510/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -9.1319 - val_loss: -8.9254\n",
      "Epoch 1511/5000\n",
      "23/23 [==============================] - 2s 80ms/step - loss: -9.1561 - val_loss: -8.9468\n",
      "Epoch 1512/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1057 - val_loss: -8.9453\n",
      "Epoch 1513/5000\n",
      "23/23 [==============================] - 6s 264ms/step - loss: -9.1578 - val_loss: -8.9541\n",
      "Epoch 1514/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.1118 - val_loss: -8.9511\n",
      "Epoch 1515/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.1411 - val_loss: -8.9604\n",
      "Epoch 1516/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.1346 - val_loss: -8.9504\n",
      "Epoch 1517/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -9.1377 - val_loss: -8.9715\n",
      "Epoch 1518/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -9.0964 - val_loss: -8.9450\n",
      "Epoch 1519/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.0517 - val_loss: -8.9412\n",
      "Epoch 1520/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.1591 - val_loss: -8.9396\n",
      "Epoch 1521/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.2056 - val_loss: -8.9492\n",
      "Epoch 1522/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.1300 - val_loss: -8.9735\n",
      "Epoch 1523/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -9.1140 - val_loss: -8.9599\n",
      "Epoch 1524/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -9.0644 - val_loss: -8.9562\n",
      "Epoch 1525/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -9.1059 - val_loss: -8.9471\n",
      "Epoch 1526/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -9.1667 - val_loss: -8.9234\n",
      "Epoch 1527/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -9.1950 - val_loss: -8.9426\n",
      "Epoch 1528/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1236 - val_loss: -8.9430\n",
      "Epoch 1529/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1117 - val_loss: -8.9433\n",
      "Epoch 1530/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.0943 - val_loss: -8.9373\n",
      "Epoch 1531/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1032 - val_loss: -8.9497\n",
      "Epoch 1532/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.1607 - val_loss: -8.9381\n",
      "Epoch 1533/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -9.1468 - val_loss: -8.9636\n",
      "Epoch 1534/5000\n",
      "23/23 [==============================] - 2s 79ms/step - loss: -9.2211 - val_loss: -8.9562\n",
      "Epoch 1535/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.0116 - val_loss: -8.9345\n",
      "Epoch 1536/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.1308 - val_loss: -8.9630\n",
      "Epoch 1537/5000\n",
      "23/23 [==============================] - 2s 80ms/step - loss: -9.0830 - val_loss: -8.9461\n",
      "Epoch 1538/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.1066 - val_loss: -8.9402\n",
      "Epoch 1539/5000\n",
      "23/23 [==============================] - 6s 273ms/step - loss: -9.1517 - val_loss: -8.9359\n",
      "Epoch 1540/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -9.1339 - val_loss: -8.9526\n",
      "Epoch 1541/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.0765 - val_loss: -8.9698\n",
      "Epoch 1542/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1631 - val_loss: -8.9541\n",
      "Epoch 1543/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -9.1838 - val_loss: -8.9479\n",
      "Epoch 1544/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.1259 - val_loss: -8.9644\n",
      "Epoch 1545/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.2235 - val_loss: -8.9642\n",
      "Epoch 1546/5000\n",
      "23/23 [==============================] - 2s 81ms/step - loss: -9.1145 - val_loss: -8.9538\n",
      "Epoch 1547/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.2172 - val_loss: -8.9478\n",
      "Epoch 1548/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.1422 - val_loss: -8.9554\n",
      "Epoch 1549/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.1572 - val_loss: -8.9598\n",
      "Epoch 1550/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -9.1238 - val_loss: -8.9577\n",
      "Epoch 1551/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.1254 - val_loss: -8.9620\n",
      "Epoch 1552/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.1686 - val_loss: -8.9681\n",
      "Epoch 1553/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.1968 - val_loss: -8.9571\n",
      "Epoch 1554/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.1648 - val_loss: -8.9288\n",
      "Epoch 1555/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.1846 - val_loss: -8.9646\n",
      "Epoch 1556/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.1074 - val_loss: -8.9634\n",
      "Epoch 1557/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.1221 - val_loss: -8.9589\n",
      "Epoch 1558/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1529 - val_loss: -8.9659\n",
      "Epoch 1559/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.0902 - val_loss: -8.9631\n",
      "Epoch 1560/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.1448 - val_loss: -8.9467\n",
      "Epoch 1561/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.1796 - val_loss: -8.9649\n",
      "Epoch 1562/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1851 - val_loss: -8.9495\n",
      "Epoch 1563/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1611 - val_loss: -8.9687\n",
      "Epoch 1564/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.1163 - val_loss: -8.9454\n",
      "Epoch 1565/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1151 - val_loss: -8.9596\n",
      "Epoch 1566/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -9.1460 - val_loss: -8.9611\n",
      "Epoch 1567/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.1653 - val_loss: -8.9405\n",
      "Epoch 1568/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1914 - val_loss: -8.9663\n",
      "Epoch 1569/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -9.1733 - val_loss: -8.9698\n",
      "Epoch 1570/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1723 - val_loss: -8.9654\n",
      "Epoch 1571/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -9.1561 - val_loss: -8.9583\n",
      "Epoch 1572/5000\n",
      "23/23 [==============================] - 6s 263ms/step - loss: -9.1341 - val_loss: -8.9639\n",
      "Epoch 1573/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.0995 - val_loss: -8.9359\n",
      "Epoch 1574/5000\n",
      "23/23 [==============================] - 5s 241ms/step - loss: -9.1763 - val_loss: -8.9301\n",
      "Epoch 1575/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.1717 - val_loss: -8.9760\n",
      "Epoch 1576/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -9.1511 - val_loss: -8.9825\n",
      "Epoch 1577/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.1309 - val_loss: -8.9670\n",
      "Epoch 1578/5000\n",
      "23/23 [==============================] - 3s 137ms/step - loss: -9.1491 - val_loss: -8.9872\n",
      "Epoch 1579/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -9.1665 - val_loss: -8.9592\n",
      "Epoch 1580/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -9.1683 - val_loss: -8.9581\n",
      "Epoch 1581/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.1248 - val_loss: -8.9765\n",
      "Epoch 1582/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -9.2060 - val_loss: -8.9737\n",
      "Epoch 1583/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.1394 - val_loss: -8.9645\n",
      "Epoch 1584/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.1162 - val_loss: -8.9696\n",
      "Epoch 1585/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -9.2044 - val_loss: -8.9920\n",
      "Epoch 1586/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.0990 - val_loss: -8.9663\n",
      "Epoch 1587/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.1923 - val_loss: -8.9254\n",
      "Epoch 1588/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.1144 - val_loss: -8.9610\n",
      "Epoch 1589/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.1909 - val_loss: -8.9626\n",
      "Epoch 1590/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.1095 - val_loss: -8.9828\n",
      "Epoch 1591/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.1684 - val_loss: -8.9817\n",
      "Epoch 1592/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1858 - val_loss: -8.9651\n",
      "Epoch 1593/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -9.1732 - val_loss: -8.9656\n",
      "Epoch 1594/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.2226 - val_loss: -8.9759\n",
      "Epoch 1595/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.1013 - val_loss: -8.9782\n",
      "Epoch 1596/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.1780 - val_loss: -8.9712\n",
      "Epoch 1597/5000\n",
      "23/23 [==============================] - 2s 80ms/step - loss: -9.2200 - val_loss: -8.9833\n",
      "Epoch 1598/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.0961 - val_loss: -8.9794\n",
      "Epoch 1599/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.1409 - val_loss: -8.9714\n",
      "Epoch 1600/5000\n",
      "23/23 [==============================] - 6s 267ms/step - loss: -9.1963 - val_loss: -8.9813\n",
      "Epoch 1601/5000\n",
      "23/23 [==============================] - 5s 246ms/step - loss: -9.1669 - val_loss: -8.9790\n",
      "Epoch 1602/5000\n",
      "23/23 [==============================] - 3s 119ms/step - loss: -9.1851 - val_loss: -8.9663\n",
      "Epoch 1603/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -9.2407 - val_loss: -8.9813\n",
      "Epoch 1604/5000\n",
      "23/23 [==============================] - 2s 79ms/step - loss: -9.1856 - val_loss: -8.9726\n",
      "Epoch 1605/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.1343 - val_loss: -8.9578\n",
      "Epoch 1606/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.1753 - val_loss: -8.9817\n",
      "Epoch 1607/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -9.1539 - val_loss: -8.9815\n",
      "Epoch 1608/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -9.1410 - val_loss: -8.9514\n",
      "Epoch 1609/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.1346 - val_loss: -8.9696\n",
      "Epoch 1610/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.2288 - val_loss: -8.9772\n",
      "Epoch 1611/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.1620 - val_loss: -8.9726\n",
      "Epoch 1612/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.0478 - val_loss: -8.9751\n",
      "Epoch 1613/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.2215 - val_loss: -8.9684\n",
      "Epoch 1614/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1934 - val_loss: -8.9625\n",
      "Epoch 1615/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1789 - val_loss: -8.9663\n",
      "Epoch 1616/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.2043 - val_loss: -8.9573\n",
      "Epoch 1617/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.1638 - val_loss: -8.9792\n",
      "Epoch 1618/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.1115 - val_loss: -8.9660\n",
      "Epoch 1619/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -9.1522 - val_loss: -8.9822\n",
      "Epoch 1620/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1154 - val_loss: -8.9846\n",
      "Epoch 1621/5000\n",
      "23/23 [==============================] - 5s 239ms/step - loss: -9.1528 - val_loss: -8.9777\n",
      "Epoch 1622/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.0624 - val_loss: -8.9826\n",
      "Epoch 1623/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.2423 - val_loss: -8.9485\n",
      "Epoch 1624/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.1688 - val_loss: -8.9833\n",
      "Epoch 1625/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.0991 - val_loss: -9.0001\n",
      "Epoch 1626/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1877 - val_loss: -8.9863\n",
      "Epoch 1627/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.1129 - val_loss: -8.9752\n",
      "Epoch 1628/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.1435 - val_loss: -8.9842\n",
      "Epoch 1629/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -9.2041 - val_loss: -8.9891\n",
      "Epoch 1630/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.1878 - val_loss: -9.0086\n",
      "Epoch 1631/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.2148 - val_loss: -9.0057\n",
      "Epoch 1632/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.1448 - val_loss: -8.9807\n",
      "Epoch 1633/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1885 - val_loss: -8.9706\n",
      "Epoch 1634/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -9.2322 - val_loss: -8.9684\n",
      "Epoch 1635/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.2034 - val_loss: -8.9904\n",
      "Epoch 1636/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -9.0196 - val_loss: -8.9884\n",
      "Epoch 1637/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.2151 - val_loss: -8.9954\n",
      "Epoch 1638/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.1344 - val_loss: -8.9789\n",
      "Epoch 1639/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1505 - val_loss: -8.9860\n",
      "Epoch 1640/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -9.1642 - val_loss: -8.9853\n",
      "Epoch 1641/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.1193 - val_loss: -8.9915\n",
      "Epoch 1642/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.1604 - val_loss: -9.0011\n",
      "Epoch 1643/5000\n",
      "23/23 [==============================] - 6s 267ms/step - loss: -9.1722 - val_loss: -8.9821\n",
      "Epoch 1644/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -8.7043 - val_loss: -8.9882\n",
      "Epoch 1645/5000\n",
      "23/23 [==============================] - 5s 217ms/step - loss: -9.2343 - val_loss: -8.9486\n",
      "Epoch 1646/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.1653 - val_loss: -8.9749\n",
      "Epoch 1647/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.1332 - val_loss: -8.9763\n",
      "Epoch 1648/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.0444 - val_loss: -8.9816\n",
      "Epoch 1649/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -9.1416 - val_loss: -8.9979\n",
      "Epoch 1650/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1431 - val_loss: -8.9909\n",
      "Epoch 1651/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1459 - val_loss: -9.0029\n",
      "Epoch 1652/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -9.2062 - val_loss: -8.9845\n",
      "Epoch 1653/5000\n",
      "23/23 [==============================] - 4s 162ms/step - loss: -9.2186 - val_loss: -8.9896\n",
      "Epoch 1654/5000\n",
      "23/23 [==============================] - 4s 193ms/step - loss: -9.2200 - val_loss: -8.9859\n",
      "Epoch 1655/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.2139 - val_loss: -9.0125\n",
      "Epoch 1656/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -9.1291 - val_loss: -9.0045\n",
      "Epoch 1657/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.1110 - val_loss: -8.9905\n",
      "Epoch 1658/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.1639 - val_loss: -8.9733\n",
      "Epoch 1659/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -9.1821 - val_loss: -8.9863\n",
      "Epoch 1660/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -9.1730 - val_loss: -8.9666\n",
      "Epoch 1661/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.1468 - val_loss: -8.9801\n",
      "Epoch 1662/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.2003 - val_loss: -8.9969\n",
      "Epoch 1663/5000\n",
      "23/23 [==============================] - 4s 176ms/step - loss: -9.1937 - val_loss: -9.0076\n",
      "Epoch 1664/5000\n",
      "23/23 [==============================] - 6s 264ms/step - loss: -9.1086 - val_loss: -8.9899\n",
      "Epoch 1665/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.1137 - val_loss: -9.0062\n",
      "Epoch 1666/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1969 - val_loss: -9.0018\n",
      "Epoch 1667/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.2332 - val_loss: -9.0132\n",
      "Epoch 1668/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.2306 - val_loss: -8.9970\n",
      "Epoch 1669/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -9.2129 - val_loss: -9.0088\n",
      "Epoch 1670/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -9.0899 - val_loss: -9.0067\n",
      "Epoch 1671/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -9.1840 - val_loss: -8.9935\n",
      "Epoch 1672/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.1891 - val_loss: -9.0020\n",
      "Epoch 1673/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -9.2221 - val_loss: -9.0016\n",
      "Epoch 1674/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.1987 - val_loss: -8.9997\n",
      "Epoch 1675/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.2189 - val_loss: -9.0041\n",
      "Epoch 1676/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.1510 - val_loss: -8.9983\n",
      "Epoch 1677/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.2705 - val_loss: -8.9950\n",
      "Epoch 1678/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1809 - val_loss: -8.9917\n",
      "Epoch 1679/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.1006 - val_loss: -8.9794\n",
      "Epoch 1680/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.2200 - val_loss: -8.9823\n",
      "Epoch 1681/5000\n",
      "23/23 [==============================] - 2s 80ms/step - loss: -9.2325 - val_loss: -9.0159\n",
      "Epoch 1682/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.2188 - val_loss: -8.9932\n",
      "Epoch 1683/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.2236 - val_loss: -8.9904\n",
      "Epoch 1684/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.1982 - val_loss: -9.0153\n",
      "Epoch 1685/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1157 - val_loss: -9.0033\n",
      "Epoch 1686/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.1360 - val_loss: -8.9942\n",
      "Epoch 1687/5000\n",
      "23/23 [==============================] - 2s 81ms/step - loss: -9.2157 - val_loss: -9.0020\n",
      "Epoch 1688/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1431 - val_loss: -9.0132\n",
      "Epoch 1689/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.2051 - val_loss: -8.9922\n",
      "Epoch 1690/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.2165 - val_loss: -8.9668\n",
      "Epoch 1691/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.1376 - val_loss: -8.9940\n",
      "Epoch 1692/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.2321 - val_loss: -9.0039\n",
      "Epoch 1693/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.1735 - val_loss: -9.0129\n",
      "Epoch 1694/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.2313 - val_loss: -8.9958\n",
      "Epoch 1695/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.2298 - val_loss: -8.9886\n",
      "Epoch 1696/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.1918 - val_loss: -8.9992\n",
      "Epoch 1697/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.1517 - val_loss: -9.0217\n",
      "Epoch 1698/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.1904 - val_loss: -8.9999\n",
      "Epoch 1699/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.0731 - val_loss: -8.9997\n",
      "Epoch 1700/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1814 - val_loss: -9.0107\n",
      "Epoch 1701/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1950 - val_loss: -9.0132\n",
      "Epoch 1702/5000\n",
      "23/23 [==============================] - 4s 159ms/step - loss: -9.1932 - val_loss: -8.9936\n",
      "Epoch 1703/5000\n",
      "23/23 [==============================] - 6s 268ms/step - loss: -9.1234 - val_loss: -9.0071\n",
      "Epoch 1704/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -9.1862 - val_loss: -9.0080\n",
      "Epoch 1705/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.0235 - val_loss: -9.0038\n",
      "Epoch 1706/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.1454 - val_loss: -8.9927\n",
      "Epoch 1707/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.2491 - val_loss: -9.0094\n",
      "Epoch 1708/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.1555 - val_loss: -9.0039\n",
      "Epoch 1709/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.1397 - val_loss: -8.9783\n",
      "Epoch 1710/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -9.1573 - val_loss: -9.0218\n",
      "Epoch 1711/5000\n",
      "23/23 [==============================] - 2s 82ms/step - loss: -9.2087 - val_loss: -9.0085\n",
      "Epoch 1712/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -8.9993 - val_loss: -9.0175\n",
      "Epoch 1713/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -9.1921 - val_loss: -9.0154\n",
      "Epoch 1714/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -9.1628 - val_loss: -9.0059\n",
      "Epoch 1715/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -9.0003 - val_loss: -9.0237\n",
      "Epoch 1716/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.2202 - val_loss: -8.9750\n",
      "Epoch 1717/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.2347 - val_loss: -9.0048\n",
      "Epoch 1718/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.1712 - val_loss: -9.0123\n",
      "Epoch 1719/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.2046 - val_loss: -9.0080\n",
      "Epoch 1720/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.1781 - val_loss: -9.0304\n",
      "Epoch 1721/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -9.1709 - val_loss: -9.0001\n",
      "Epoch 1722/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.1575 - val_loss: -9.0154\n",
      "Epoch 1723/5000\n",
      "23/23 [==============================] - 2s 80ms/step - loss: -9.1607 - val_loss: -8.9942\n",
      "Epoch 1724/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.2306 - val_loss: -9.0057\n",
      "Epoch 1725/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1044 - val_loss: -9.0089\n",
      "Epoch 1726/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.2164 - val_loss: -9.0247\n",
      "Epoch 1727/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -9.1684 - val_loss: -9.0129\n",
      "Epoch 1728/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.2006 - val_loss: -8.9877\n",
      "Epoch 1729/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.2190 - val_loss: -9.0086\n",
      "Epoch 1730/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -9.2364 - val_loss: -9.0171\n",
      "Epoch 1731/5000\n",
      "23/23 [==============================] - 3s 137ms/step - loss: -9.1104 - val_loss: -9.0112\n",
      "Epoch 1732/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -9.1434 - val_loss: -9.0125\n",
      "Epoch 1733/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.1679 - val_loss: -9.0022\n",
      "Epoch 1734/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.1350 - val_loss: -9.0148\n",
      "Epoch 1735/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.2349 - val_loss: -9.0143\n",
      "Epoch 1736/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.2174 - val_loss: -9.0081\n",
      "Epoch 1737/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.2057 - val_loss: -8.9995\n",
      "Epoch 1738/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -9.1261 - val_loss: -9.0209\n",
      "Epoch 1739/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -9.1948 - val_loss: -9.0098\n",
      "Epoch 1740/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.2293 - val_loss: -9.0195\n",
      "Epoch 1741/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.1943 - val_loss: -9.0208\n",
      "Epoch 1742/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -9.2086 - val_loss: -9.0057\n",
      "Epoch 1743/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.1752 - val_loss: -8.9924\n",
      "Epoch 1744/5000\n",
      "23/23 [==============================] - 4s 203ms/step - loss: -9.1815 - val_loss: -9.0019\n",
      "Epoch 1745/5000\n",
      "23/23 [==============================] - 4s 193ms/step - loss: -9.2048 - val_loss: -9.0153\n",
      "Epoch 1746/5000\n",
      "23/23 [==============================] - 4s 185ms/step - loss: -9.1006 - val_loss: -9.0118\n",
      "Epoch 1747/5000\n",
      "23/23 [==============================] - 4s 170ms/step - loss: -9.1999 - val_loss: -9.0291\n",
      "Epoch 1748/5000\n",
      "23/23 [==============================] - 5s 229ms/step - loss: -9.1299 - val_loss: -9.0084\n",
      "Epoch 1749/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -9.1030 - val_loss: -9.0202\n",
      "Epoch 1750/5000\n",
      "23/23 [==============================] - 6s 271ms/step - loss: -9.1796 - val_loss: -9.0142\n",
      "Epoch 1751/5000\n",
      "23/23 [==============================] - 5s 234ms/step - loss: -9.1168 - val_loss: -9.0184\n",
      "Epoch 1752/5000\n",
      "23/23 [==============================] - 3s 131ms/step - loss: -9.1754 - val_loss: -9.0093\n",
      "Epoch 1753/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.2004 - val_loss: -9.0192\n",
      "Epoch 1754/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.1977 - val_loss: -8.9944\n",
      "Epoch 1755/5000\n",
      "23/23 [==============================] - 3s 152ms/step - loss: -9.2052 - val_loss: -8.9974\n",
      "Epoch 1756/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.1884 - val_loss: -9.0091\n",
      "Epoch 1757/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.2349 - val_loss: -9.0119\n",
      "Epoch 1758/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.1162 - val_loss: -9.0315\n",
      "Epoch 1759/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.1975 - val_loss: -9.0177\n",
      "Epoch 1760/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.1190 - val_loss: -9.0263\n",
      "Epoch 1761/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.2070 - val_loss: -9.0065\n",
      "Epoch 1762/5000\n",
      "23/23 [==============================] - 2s 110ms/step - loss: -9.1988 - val_loss: -9.0213\n",
      "Epoch 1763/5000\n",
      "23/23 [==============================] - 3s 158ms/step - loss: -9.1798 - val_loss: -9.0286\n",
      "Epoch 1764/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.1986 - val_loss: -9.0015\n",
      "Epoch 1765/5000\n",
      "23/23 [==============================] - 4s 202ms/step - loss: -9.2182 - val_loss: -9.0112\n",
      "Epoch 1766/5000\n",
      "23/23 [==============================] - 5s 241ms/step - loss: -9.2597 - val_loss: -9.0044\n",
      "Epoch 1767/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.2342 - val_loss: -9.0262\n",
      "Epoch 1768/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.2526 - val_loss: -9.0332\n",
      "Epoch 1769/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.2274 - val_loss: -9.0145\n",
      "Epoch 1770/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.1625 - val_loss: -9.0285\n",
      "Epoch 1771/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.2500 - val_loss: -9.0146\n",
      "Epoch 1772/5000\n",
      "23/23 [==============================] - 5s 219ms/step - loss: -9.1726 - val_loss: -9.0038\n",
      "Epoch 1773/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.2036 - val_loss: -9.0240\n",
      "Epoch 1774/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.2063 - val_loss: -9.0297\n",
      "Epoch 1775/5000\n",
      "23/23 [==============================] - 4s 192ms/step - loss: -9.2397 - val_loss: -9.0276\n",
      "Epoch 1776/5000\n",
      "23/23 [==============================] - 3s 143ms/step - loss: -9.1846 - val_loss: -9.0186\n",
      "Epoch 1777/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.2044 - val_loss: -9.0010\n",
      "Epoch 1778/5000\n",
      "23/23 [==============================] - 4s 185ms/step - loss: -9.2347 - val_loss: -8.9850\n",
      "Epoch 1779/5000\n",
      "23/23 [==============================] - 3s 119ms/step - loss: -9.2251 - val_loss: -9.0073\n",
      "Epoch 1780/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.2724 - val_loss: -9.0298\n",
      "Epoch 1781/5000\n",
      "23/23 [==============================] - 6s 265ms/step - loss: -9.1926 - val_loss: -9.0195\n",
      "Epoch 1782/5000\n",
      "23/23 [==============================] - 4s 164ms/step - loss: -9.2401 - val_loss: -9.0062\n",
      "Epoch 1783/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.2009 - val_loss: -9.0282\n",
      "Epoch 1784/5000\n",
      "23/23 [==============================] - 2s 110ms/step - loss: -9.1884 - val_loss: -9.0065\n",
      "Epoch 1785/5000\n",
      "23/23 [==============================] - 4s 161ms/step - loss: -9.1991 - val_loss: -9.0290\n",
      "Epoch 1786/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.2121 - val_loss: -9.0067\n",
      "Epoch 1787/5000\n",
      "23/23 [==============================] - 4s 182ms/step - loss: -9.0429 - val_loss: -9.0300\n",
      "Epoch 1788/5000\n",
      "23/23 [==============================] - 6s 250ms/step - loss: -9.1018 - val_loss: -8.9959\n",
      "Epoch 1789/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -9.2124 - val_loss: -9.0157\n",
      "Epoch 1790/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.2256 - val_loss: -9.0238\n",
      "Epoch 1791/5000\n",
      "23/23 [==============================] - 4s 177ms/step - loss: -9.2264 - val_loss: -9.0140\n",
      "Epoch 1792/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.0851 - val_loss: -9.0251\n",
      "Epoch 1793/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.2454 - val_loss: -9.0314\n",
      "Epoch 1794/5000\n",
      "23/23 [==============================] - 3s 117ms/step - loss: -9.2088 - val_loss: -9.0301\n",
      "Epoch 1795/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.2502 - val_loss: -9.0133\n",
      "Epoch 1796/5000\n",
      "23/23 [==============================] - 3s 135ms/step - loss: -9.1734 - val_loss: -9.0222\n",
      "Epoch 1797/5000\n",
      "23/23 [==============================] - 5s 205ms/step - loss: -9.1988 - val_loss: -9.0237\n",
      "Epoch 1798/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.2495 - val_loss: -9.0126\n",
      "Epoch 1799/5000\n",
      "23/23 [==============================] - 3s 145ms/step - loss: -9.2289 - val_loss: -9.0386\n",
      "Epoch 1800/5000\n",
      "23/23 [==============================] - 6s 270ms/step - loss: -9.1491 - val_loss: -9.0433\n",
      "Epoch 1801/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -9.2067 - val_loss: -9.0175\n",
      "Epoch 1802/5000\n",
      "23/23 [==============================] - 4s 202ms/step - loss: -9.1650 - val_loss: -9.0428\n",
      "Epoch 1803/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.2111 - val_loss: -9.0351\n",
      "Epoch 1804/5000\n",
      "23/23 [==============================] - 4s 174ms/step - loss: -9.1851 - val_loss: -9.0142\n",
      "Epoch 1805/5000\n",
      "23/23 [==============================] - 3s 147ms/step - loss: -9.2681 - val_loss: -9.0302\n",
      "Epoch 1806/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.2246 - val_loss: -9.0329\n",
      "Epoch 1807/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.2149 - val_loss: -9.0253\n",
      "Epoch 1808/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.1868 - val_loss: -9.0285\n",
      "Epoch 1809/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.1956 - val_loss: -9.0362\n",
      "Epoch 1810/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.2272 - val_loss: -9.0190\n",
      "Epoch 1811/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -9.1669 - val_loss: -9.0401\n",
      "Epoch 1812/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.2624 - val_loss: -9.0347\n",
      "Epoch 1813/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.2459 - val_loss: -9.0273\n",
      "Epoch 1814/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.2768 - val_loss: -9.0378\n",
      "Epoch 1815/5000\n",
      "23/23 [==============================] - 4s 168ms/step - loss: -9.0647 - val_loss: -9.0478\n",
      "Epoch 1816/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.2337 - val_loss: -9.0205\n",
      "Epoch 1817/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.1438 - val_loss: -9.0148\n",
      "Epoch 1818/5000\n",
      "23/23 [==============================] - 5s 241ms/step - loss: -9.1384 - val_loss: -9.0038\n",
      "Epoch 1819/5000\n",
      "23/23 [==============================] - 3s 116ms/step - loss: -9.1890 - val_loss: -9.0285\n",
      "Epoch 1820/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.2074 - val_loss: -9.0128\n",
      "Epoch 1821/5000\n",
      "23/23 [==============================] - 3s 144ms/step - loss: -9.2302 - val_loss: -9.0279\n",
      "Epoch 1822/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.2103 - val_loss: -9.0480\n",
      "Epoch 1823/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.2150 - val_loss: -9.0287\n",
      "Epoch 1824/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -9.2475 - val_loss: -9.0094\n",
      "Epoch 1825/5000\n",
      "23/23 [==============================] - 5s 246ms/step - loss: -9.2105 - val_loss: -9.0383\n",
      "Epoch 1826/5000\n",
      "23/23 [==============================] - 3s 139ms/step - loss: -9.2348 - val_loss: -9.0410\n",
      "Epoch 1827/5000\n",
      "23/23 [==============================] - 5s 225ms/step - loss: -9.1954 - val_loss: -9.0339\n",
      "Epoch 1828/5000\n",
      "23/23 [==============================] - 3s 136ms/step - loss: -9.2095 - val_loss: -9.0399\n",
      "Epoch 1829/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.1306 - val_loss: -9.0347\n",
      "Epoch 1830/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.2453 - val_loss: -9.0428\n",
      "Epoch 1831/5000\n",
      "23/23 [==============================] - 4s 165ms/step - loss: -9.2351 - val_loss: -9.0354\n",
      "Epoch 1832/5000\n",
      "23/23 [==============================] - 3s 121ms/step - loss: -9.1609 - val_loss: -9.0184\n",
      "Epoch 1833/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.2435 - val_loss: -8.6996\n",
      "Epoch 1834/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -9.2149 - val_loss: -9.0382\n",
      "Epoch 1835/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.2357 - val_loss: -9.0388\n",
      "Epoch 1836/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.2229 - val_loss: -8.9918\n",
      "Epoch 1837/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.2583 - val_loss: -9.0530\n",
      "Epoch 1838/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.2425 - val_loss: -9.0303\n",
      "Epoch 1839/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.2870 - val_loss: -9.0585\n",
      "Epoch 1840/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.2033 - val_loss: -9.0101\n",
      "Epoch 1841/5000\n",
      "23/23 [==============================] - 3s 152ms/step - loss: -9.2636 - val_loss: -9.0467\n",
      "Epoch 1842/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.2462 - val_loss: -9.0247\n",
      "Epoch 1843/5000\n",
      "23/23 [==============================] - 4s 174ms/step - loss: -9.2225 - val_loss: -9.0207\n",
      "Epoch 1844/5000\n",
      "23/23 [==============================] - 2s 108ms/step - loss: -9.2378 - val_loss: -9.0380\n",
      "Epoch 1845/5000\n",
      "23/23 [==============================] - 5s 233ms/step - loss: -9.2396 - val_loss: -9.0248\n",
      "Epoch 1846/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.2668 - val_loss: -9.0395\n",
      "Epoch 1847/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.2735 - val_loss: -9.0494\n",
      "Epoch 1848/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.2267 - val_loss: -9.0440\n",
      "Epoch 1849/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -9.2891 - val_loss: -9.0280\n",
      "Epoch 1850/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.2686 - val_loss: -9.0361\n",
      "Epoch 1851/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.2128 - val_loss: -9.0341\n",
      "Epoch 1852/5000\n",
      "23/23 [==============================] - 2s 112ms/step - loss: -9.2162 - val_loss: -9.0223\n",
      "Epoch 1853/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.2250 - val_loss: -9.0288\n",
      "Epoch 1854/5000\n",
      "23/23 [==============================] - 5s 241ms/step - loss: -9.2484 - val_loss: -9.0381\n",
      "Epoch 1855/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.1789 - val_loss: -9.0463\n",
      "Epoch 1856/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.2099 - val_loss: -9.0494\n",
      "Epoch 1857/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.2568 - val_loss: -9.0143\n",
      "Epoch 1858/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.1909 - val_loss: -9.0482\n",
      "Epoch 1859/5000\n",
      "23/23 [==============================] - 3s 135ms/step - loss: -9.2258 - val_loss: -9.0602\n",
      "Epoch 1860/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.2208 - val_loss: -9.0377\n",
      "Epoch 1861/5000\n",
      "23/23 [==============================] - 3s 114ms/step - loss: -9.2368 - val_loss: -9.0580\n",
      "Epoch 1862/5000\n",
      "23/23 [==============================] - 3s 114ms/step - loss: -9.2670 - val_loss: -9.0358\n",
      "Epoch 1863/5000\n",
      "23/23 [==============================] - 4s 162ms/step - loss: -9.2907 - val_loss: -9.0504\n",
      "Epoch 1864/5000\n",
      "23/23 [==============================] - 5s 213ms/step - loss: -9.2396 - val_loss: -9.0364\n",
      "Epoch 1865/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.1774 - val_loss: -9.0489\n",
      "Epoch 1866/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.2444 - val_loss: -9.0472\n",
      "Epoch 1867/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.2004 - val_loss: -9.0517\n",
      "Epoch 1868/5000\n",
      "23/23 [==============================] - 5s 241ms/step - loss: -9.2379 - val_loss: -9.0443\n",
      "Epoch 1869/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -9.2435 - val_loss: -9.0405\n",
      "Epoch 1870/5000\n",
      "23/23 [==============================] - 3s 154ms/step - loss: -9.2194 - val_loss: -9.0459\n",
      "Epoch 1871/5000\n",
      "23/23 [==============================] - 5s 246ms/step - loss: -9.2244 - val_loss: -9.0635\n",
      "Epoch 1872/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.2397 - val_loss: -9.0570\n",
      "Epoch 1873/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.2556 - val_loss: -9.0379\n",
      "Epoch 1874/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.2910 - val_loss: -9.0690\n",
      "Epoch 1875/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.2212 - val_loss: -9.0390\n",
      "Epoch 1876/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.2898 - val_loss: -9.0413\n",
      "Epoch 1877/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.2235 - val_loss: -9.0438\n",
      "Epoch 1878/5000\n",
      "23/23 [==============================] - 3s 118ms/step - loss: -9.2656 - val_loss: -9.0459\n",
      "Epoch 1879/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.2590 - val_loss: -9.0337\n",
      "Epoch 1880/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -9.3030 - val_loss: -9.0504\n",
      "Epoch 1881/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.2454 - val_loss: -9.0318\n",
      "Epoch 1882/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.2931 - val_loss: -9.0374\n",
      "Epoch 1883/5000\n",
      "23/23 [==============================] - 5s 241ms/step - loss: -9.1290 - val_loss: -9.0536\n",
      "Epoch 1884/5000\n",
      "23/23 [==============================] - 3s 150ms/step - loss: -9.2872 - val_loss: -9.0459\n",
      "Epoch 1885/5000\n",
      "23/23 [==============================] - 5s 245ms/step - loss: -9.2131 - val_loss: -9.0433\n",
      "Epoch 1886/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.2822 - val_loss: -8.9896\n",
      "Epoch 1887/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -9.2342 - val_loss: -9.0555\n",
      "Epoch 1888/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.1769 - val_loss: -9.0339\n",
      "Epoch 1889/5000\n",
      "23/23 [==============================] - 3s 120ms/step - loss: -9.2313 - val_loss: -9.0483\n",
      "Epoch 1890/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.2172 - val_loss: -9.0494\n",
      "Epoch 1891/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.0437 - val_loss: -9.0682\n",
      "Epoch 1892/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.2027 - val_loss: -9.0413\n",
      "Epoch 1893/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.2503 - val_loss: -9.0395\n",
      "Epoch 1894/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.2260 - val_loss: -9.0497\n",
      "Epoch 1895/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.1946 - val_loss: -9.0485\n",
      "Epoch 1896/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.2022 - val_loss: -9.0416\n",
      "Epoch 1897/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1880 - val_loss: -9.0560\n",
      "Epoch 1898/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.2456 - val_loss: -9.0423\n",
      "Epoch 1899/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.2346 - val_loss: -9.0658\n",
      "Epoch 1900/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -9.1652 - val_loss: -9.0357\n",
      "Epoch 1901/5000\n",
      "23/23 [==============================] - 5s 241ms/step - loss: -9.2802 - val_loss: -9.0487\n",
      "Epoch 1902/5000\n",
      "23/23 [==============================] - 4s 162ms/step - loss: -9.2398 - val_loss: -9.0650\n",
      "Epoch 1903/5000\n",
      "23/23 [==============================] - 6s 264ms/step - loss: -9.2477 - val_loss: -9.0447\n",
      "Epoch 1904/5000\n",
      "23/23 [==============================] - 3s 146ms/step - loss: -9.2368 - val_loss: -9.0361\n",
      "Epoch 1905/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.2530 - val_loss: -9.0499\n",
      "Epoch 1906/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.2390 - val_loss: -9.0595\n",
      "Epoch 1907/5000\n",
      "23/23 [==============================] - 3s 113ms/step - loss: -9.2336 - val_loss: -9.0469\n",
      "Epoch 1908/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.1806 - val_loss: -9.0550\n",
      "Epoch 1909/5000\n",
      "23/23 [==============================] - 3s 116ms/step - loss: -9.2600 - val_loss: -9.0438\n",
      "Epoch 1910/5000\n",
      "23/23 [==============================] - 3s 114ms/step - loss: -9.2445 - val_loss: -9.0598\n",
      "Epoch 1911/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -9.2771 - val_loss: -9.0491\n",
      "Epoch 1912/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.2239 - val_loss: -9.0261\n",
      "Epoch 1913/5000\n",
      "23/23 [==============================] - 4s 180ms/step - loss: -9.2688 - val_loss: -9.0561\n",
      "Epoch 1914/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.2760 - val_loss: -9.0485\n",
      "Epoch 1915/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.2462 - val_loss: -9.0281\n",
      "Epoch 1916/5000\n",
      "23/23 [==============================] - 2s 113ms/step - loss: -9.2277 - val_loss: -9.0335\n",
      "Epoch 1917/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.2262 - val_loss: -9.0511\n",
      "Epoch 1918/5000\n",
      "23/23 [==============================] - 2s 109ms/step - loss: -9.2592 - val_loss: -9.0596\n",
      "Epoch 1919/5000\n",
      "23/23 [==============================] - 5s 246ms/step - loss: -9.2643 - val_loss: -9.0810\n",
      "Epoch 1920/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.2591 - val_loss: -9.0612\n",
      "Epoch 1921/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.2274 - val_loss: -9.0507\n",
      "Epoch 1922/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.2706 - val_loss: -9.0337\n",
      "Epoch 1923/5000\n",
      "23/23 [==============================] - 2s 109ms/step - loss: -9.1917 - val_loss: -9.0601\n",
      "Epoch 1924/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.2295 - val_loss: -9.0635\n",
      "Epoch 1925/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.1955 - val_loss: -9.0631\n",
      "Epoch 1926/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.1887 - val_loss: -9.0557\n",
      "Epoch 1927/5000\n",
      "23/23 [==============================] - 3s 113ms/step - loss: -9.2363 - val_loss: -9.0611\n",
      "Epoch 1928/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -9.2257 - val_loss: -9.0583\n",
      "Epoch 1929/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.2541 - val_loss: -9.0615\n",
      "Epoch 1930/5000\n",
      "23/23 [==============================] - 4s 183ms/step - loss: -9.1873 - val_loss: -9.0629\n",
      "Epoch 1931/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.2692 - val_loss: -9.0676\n",
      "Epoch 1932/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.2757 - val_loss: -9.0586\n",
      "Epoch 1933/5000\n",
      "23/23 [==============================] - 3s 135ms/step - loss: -9.2639 - val_loss: -9.0846\n",
      "Epoch 1934/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.2817 - val_loss: -9.0674\n",
      "Epoch 1935/5000\n",
      "23/23 [==============================] - 4s 164ms/step - loss: -9.2209 - val_loss: -9.0679\n",
      "Epoch 1936/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.1988 - val_loss: -9.0430\n",
      "Epoch 1937/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.2686 - val_loss: -9.0742\n",
      "Epoch 1938/5000\n",
      "23/23 [==============================] - 2s 104ms/step - loss: -9.2705 - val_loss: -9.0620\n",
      "Epoch 1939/5000\n",
      "23/23 [==============================] - 5s 246ms/step - loss: -9.2042 - val_loss: -9.0742\n",
      "Epoch 1940/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.2429 - val_loss: -9.0310\n",
      "Epoch 1941/5000\n",
      "23/23 [==============================] - 5s 229ms/step - loss: -9.2463 - val_loss: -9.0813\n",
      "Epoch 1942/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.2763 - val_loss: -9.0700\n",
      "Epoch 1943/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.2062 - val_loss: -9.0690\n",
      "Epoch 1944/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.2208 - val_loss: -9.0671\n",
      "Epoch 1945/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.2538 - val_loss: -9.0533\n",
      "Epoch 1946/5000\n",
      "23/23 [==============================] - 5s 222ms/step - loss: -9.2878 - val_loss: -9.0787\n",
      "Epoch 1947/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.2205 - val_loss: -9.0727\n",
      "Epoch 1948/5000\n",
      "23/23 [==============================] - 3s 132ms/step - loss: -9.2444 - val_loss: -9.0491\n",
      "Epoch 1949/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.2783 - val_loss: -9.0637\n",
      "Epoch 1950/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.2349 - val_loss: -9.0593\n",
      "Epoch 1951/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.3009 - val_loss: -9.0632\n",
      "Epoch 1952/5000\n",
      "23/23 [==============================] - 3s 154ms/step - loss: -9.3066 - val_loss: -9.0289\n",
      "Epoch 1953/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.2506 - val_loss: -9.0581\n",
      "Epoch 1954/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -9.2086 - val_loss: -9.0787\n",
      "Epoch 1955/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.2361 - val_loss: -9.0641\n",
      "Epoch 1956/5000\n",
      "23/23 [==============================] - 3s 113ms/step - loss: -9.1782 - val_loss: -9.0758\n",
      "Epoch 1957/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.2187 - val_loss: -9.0449\n",
      "Epoch 1958/5000\n",
      "23/23 [==============================] - 5s 225ms/step - loss: -9.3393 - val_loss: -9.0587\n",
      "Epoch 1959/5000\n",
      "23/23 [==============================] - 5s 210ms/step - loss: -9.2341 - val_loss: -9.0690\n",
      "Epoch 1960/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.0500 - val_loss: -9.0672\n",
      "Epoch 1961/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.2304 - val_loss: -9.0450\n",
      "Epoch 1962/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.2325 - val_loss: -9.0778\n",
      "Epoch 1963/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -9.2537 - val_loss: -9.0778\n",
      "Epoch 1964/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.3101 - val_loss: -9.0814\n",
      "Epoch 1965/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.2825 - val_loss: -9.0659\n",
      "Epoch 1966/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.2747 - val_loss: -9.0603\n",
      "Epoch 1967/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.2769 - val_loss: -9.0630\n",
      "Epoch 1968/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.1863 - val_loss: -9.0613\n",
      "Epoch 1969/5000\n",
      "23/23 [==============================] - 5s 214ms/step - loss: -9.1729 - val_loss: -9.0770\n",
      "Epoch 1970/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -9.2662 - val_loss: -9.0801\n",
      "Epoch 1971/5000\n",
      "23/23 [==============================] - 5s 236ms/step - loss: -9.2261 - val_loss: -9.0456\n",
      "Epoch 1972/5000\n",
      "23/23 [==============================] - 3s 131ms/step - loss: -9.2563 - val_loss: -9.0675\n",
      "Epoch 1973/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.2386 - val_loss: -9.0825\n",
      "Epoch 1974/5000\n",
      "23/23 [==============================] - 4s 168ms/step - loss: -9.2204 - val_loss: -9.0593\n",
      "Epoch 1975/5000\n",
      "23/23 [==============================] - 5s 215ms/step - loss: -9.2259 - val_loss: -9.0688\n",
      "Epoch 1976/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.2465 - val_loss: -9.0839\n",
      "Epoch 1977/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.2839 - val_loss: -9.0841\n",
      "Epoch 1978/5000\n",
      "23/23 [==============================] - 3s 134ms/step - loss: -9.2663 - val_loss: -9.0741\n",
      "Epoch 1979/5000\n",
      "23/23 [==============================] - 2s 113ms/step - loss: -9.2985 - val_loss: -9.0532\n",
      "Epoch 1980/5000\n",
      "23/23 [==============================] - 6s 256ms/step - loss: -9.1882 - val_loss: -9.0754\n",
      "Epoch 1981/5000\n",
      "23/23 [==============================] - 3s 148ms/step - loss: -9.2395 - val_loss: -9.0616\n",
      "Epoch 1982/5000\n",
      "23/23 [==============================] - 3s 143ms/step - loss: -9.2982 - val_loss: -9.0675\n",
      "Epoch 1983/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.2584 - val_loss: -9.0782\n",
      "Epoch 1984/5000\n",
      "23/23 [==============================] - 5s 240ms/step - loss: -9.2572 - val_loss: -9.0771\n",
      "Epoch 1985/5000\n",
      "23/23 [==============================] - 4s 173ms/step - loss: -9.2936 - val_loss: -9.0883\n",
      "Epoch 1986/5000\n",
      "23/23 [==============================] - 3s 120ms/step - loss: -9.2867 - val_loss: -9.0325\n",
      "Epoch 1987/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -9.3119 - val_loss: -9.0848\n",
      "Epoch 1988/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.2683 - val_loss: -9.0717\n",
      "Epoch 1989/5000\n",
      "23/23 [==============================] - 4s 164ms/step - loss: -9.2655 - val_loss: -9.0751\n",
      "Epoch 1990/5000\n",
      "23/23 [==============================] - 4s 187ms/step - loss: -9.2392 - val_loss: -9.0532\n",
      "Epoch 1991/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.1982 - val_loss: -9.0555\n",
      "Epoch 1992/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.1691 - val_loss: -9.0768\n",
      "Epoch 1993/5000\n",
      "23/23 [==============================] - 6s 261ms/step - loss: -9.2526 - val_loss: -9.0553\n",
      "Epoch 1994/5000\n",
      "23/23 [==============================] - 4s 182ms/step - loss: -9.2590 - val_loss: -9.0717\n",
      "Epoch 1995/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.2254 - val_loss: -9.0608\n",
      "Epoch 1996/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.2564 - val_loss: -9.0944\n",
      "Epoch 1997/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.3174 - val_loss: -9.0607\n",
      "Epoch 1998/5000\n",
      "23/23 [==============================] - 3s 121ms/step - loss: -9.2331 - val_loss: -9.0708\n",
      "Epoch 1999/5000\n",
      "23/23 [==============================] - 6s 256ms/step - loss: -9.1808 - val_loss: -9.0669\n",
      "Epoch 2000/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.2455 - val_loss: -9.0913\n",
      "Epoch 2001/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -9.2556 - val_loss: -9.0536\n",
      "Epoch 2002/5000\n",
      "23/23 [==============================] - 5s 240ms/step - loss: -9.2135 - val_loss: -9.0687\n",
      "Epoch 2003/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.2379 - val_loss: -9.0718\n",
      "Epoch 2004/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.2693 - val_loss: -9.0852\n",
      "Epoch 2005/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.2465 - val_loss: -9.0793\n",
      "Epoch 2006/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.1428 - val_loss: -9.0778\n",
      "Epoch 2007/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.2235 - val_loss: -9.0633\n",
      "Epoch 2008/5000\n",
      "23/23 [==============================] - 6s 259ms/step - loss: -9.2970 - val_loss: -9.0549\n",
      "Epoch 2009/5000\n",
      "23/23 [==============================] - 5s 248ms/step - loss: -9.2335 - val_loss: -9.0897\n",
      "Epoch 2010/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.2376 - val_loss: -9.0812\n",
      "Epoch 2011/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.2808 - val_loss: -9.0801\n",
      "Epoch 2012/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.2037 - val_loss: -9.0781\n",
      "Epoch 2013/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.2484 - val_loss: -9.0836\n",
      "Epoch 2014/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.2150 - val_loss: -9.0887\n",
      "Epoch 2015/5000\n",
      "23/23 [==============================] - 5s 214ms/step - loss: -9.1910 - val_loss: -9.0805\n",
      "Epoch 2016/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.2679 - val_loss: -9.0880\n",
      "Epoch 2017/5000\n",
      "23/23 [==============================] - 5s 220ms/step - loss: -9.3128 - val_loss: -9.0500\n",
      "Epoch 2018/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.3295 - val_loss: -9.0683\n",
      "Epoch 2019/5000\n",
      "23/23 [==============================] - 5s 246ms/step - loss: -9.2746 - val_loss: -9.0780\n",
      "Epoch 2020/5000\n",
      "23/23 [==============================] - 6s 253ms/step - loss: -9.3244 - val_loss: -9.0790\n",
      "Epoch 2021/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.2970 - val_loss: -9.0624\n",
      "Epoch 2022/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.2144 - val_loss: -9.0650\n",
      "Epoch 2023/5000\n",
      "23/23 [==============================] - 3s 138ms/step - loss: -9.3325 - val_loss: -9.0689\n",
      "Epoch 2024/5000\n",
      "23/23 [==============================] - 3s 132ms/step - loss: -9.2080 - val_loss: -9.0833\n",
      "Epoch 2025/5000\n",
      "23/23 [==============================] - 4s 175ms/step - loss: -9.2505 - val_loss: -9.0817\n",
      "Epoch 2026/5000\n",
      "23/23 [==============================] - 6s 251ms/step - loss: -9.2571 - val_loss: -9.0729\n",
      "Epoch 2027/5000\n",
      "23/23 [==============================] - 5s 231ms/step - loss: -9.2725 - val_loss: -9.0852\n",
      "Epoch 2028/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.2538 - val_loss: -9.0934\n",
      "Epoch 2029/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -9.2585 - val_loss: -9.0780\n",
      "Epoch 2030/5000\n",
      "23/23 [==============================] - 4s 201ms/step - loss: -9.2047 - val_loss: -9.0836\n",
      "Epoch 2031/5000\n",
      "23/23 [==============================] - 5s 220ms/step - loss: -9.2945 - val_loss: -9.0697\n",
      "Epoch 2032/5000\n",
      "23/23 [==============================] - 3s 135ms/step - loss: -9.2985 - val_loss: -9.0866\n",
      "Epoch 2033/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.2657 - val_loss: -9.0858\n",
      "Epoch 2034/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.2799 - val_loss: -9.0976\n",
      "Epoch 2035/5000\n",
      "23/23 [==============================] - 2s 109ms/step - loss: -9.3190 - val_loss: -9.0628\n",
      "Epoch 2036/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.2823 - val_loss: -9.0788\n",
      "Epoch 2037/5000\n",
      "23/23 [==============================] - 3s 132ms/step - loss: -9.2651 - val_loss: -9.0793\n",
      "Epoch 2038/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.2578 - val_loss: -9.0725\n",
      "Epoch 2039/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.3276 - val_loss: -9.0799\n",
      "Epoch 2040/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.1688 - val_loss: -9.0673\n",
      "Epoch 2041/5000\n",
      "23/23 [==============================] - 5s 211ms/step - loss: -9.2533 - val_loss: -9.0801\n",
      "Epoch 2042/5000\n",
      "23/23 [==============================] - 3s 116ms/step - loss: -9.2952 - val_loss: -9.0919\n",
      "Epoch 2043/5000\n",
      "23/23 [==============================] - 5s 226ms/step - loss: -9.0176 - val_loss: -9.0678\n",
      "Epoch 2044/5000\n",
      "23/23 [==============================] - 5s 205ms/step - loss: -9.2889 - val_loss: -9.0868\n",
      "Epoch 2045/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.2786 - val_loss: -9.0933\n",
      "Epoch 2046/5000\n",
      "23/23 [==============================] - 4s 165ms/step - loss: -9.2276 - val_loss: -9.0763\n",
      "Epoch 2047/5000\n",
      "23/23 [==============================] - 6s 259ms/step - loss: -9.1889 - val_loss: -9.0644\n",
      "Epoch 2048/5000\n",
      "23/23 [==============================] - 4s 187ms/step - loss: -9.2616 - val_loss: -9.0996\n",
      "Epoch 2049/5000\n",
      "23/23 [==============================] - 4s 166ms/step - loss: -9.3211 - val_loss: -9.0867\n",
      "Epoch 2050/5000\n",
      "23/23 [==============================] - 3s 149ms/step - loss: -9.2504 - val_loss: -9.0646\n",
      "Epoch 2051/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.1540 - val_loss: -9.0494\n",
      "Epoch 2052/5000\n",
      "23/23 [==============================] - 2s 108ms/step - loss: -9.2926 - val_loss: -9.0894\n",
      "Epoch 2053/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.3047 - val_loss: -9.0751\n",
      "Epoch 2054/5000\n",
      "23/23 [==============================] - 4s 197ms/step - loss: -9.3076 - val_loss: -9.0887\n",
      "Epoch 2055/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.3210 - val_loss: -9.0870\n",
      "Epoch 2056/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.2658 - val_loss: -9.0739\n",
      "Epoch 2057/5000\n",
      "23/23 [==============================] - 4s 162ms/step - loss: -9.3286 - val_loss: -9.0798\n",
      "Epoch 2058/5000\n",
      "23/23 [==============================] - 5s 245ms/step - loss: -9.1723 - val_loss: -9.1005\n",
      "Epoch 2059/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.3133 - val_loss: -9.0961\n",
      "Epoch 2060/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.2255 - val_loss: -9.0895\n",
      "Epoch 2061/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.2819 - val_loss: -9.0891\n",
      "Epoch 2062/5000\n",
      "23/23 [==============================] - 3s 116ms/step - loss: -9.2968 - val_loss: -9.0917\n",
      "Epoch 2063/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.2383 - val_loss: -9.0966\n",
      "Epoch 2064/5000\n",
      "23/23 [==============================] - 3s 131ms/step - loss: -9.2659 - val_loss: -9.0819\n",
      "Epoch 2065/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.2573 - val_loss: -9.0760\n",
      "Epoch 2066/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -9.2706 - val_loss: -9.0931\n",
      "Epoch 2067/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.2272 - val_loss: -9.0853\n",
      "Epoch 2068/5000\n",
      "23/23 [==============================] - 5s 245ms/step - loss: -9.2093 - val_loss: -9.1071\n",
      "Epoch 2069/5000\n",
      "23/23 [==============================] - 5s 222ms/step - loss: -9.1980 - val_loss: -9.0940\n",
      "Epoch 2070/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.3409 - val_loss: -9.0853\n",
      "Epoch 2071/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.3040 - val_loss: -9.0984\n",
      "Epoch 2072/5000\n",
      "23/23 [==============================] - 2s 113ms/step - loss: -9.2987 - val_loss: -9.0847\n",
      "Epoch 2073/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -9.0857 - val_loss: -9.0906\n",
      "Epoch 2074/5000\n",
      "23/23 [==============================] - 3s 143ms/step - loss: -9.3293 - val_loss: -9.0860\n",
      "Epoch 2075/5000\n",
      "23/23 [==============================] - 3s 140ms/step - loss: -9.2385 - val_loss: -9.0988\n",
      "Epoch 2076/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.3020 - val_loss: -9.0995\n",
      "Epoch 2077/5000\n",
      "23/23 [==============================] - 4s 199ms/step - loss: -9.3068 - val_loss: -9.0671\n",
      "Epoch 2078/5000\n",
      "23/23 [==============================] - 5s 207ms/step - loss: -9.3348 - val_loss: -9.0984\n",
      "Epoch 2079/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.2654 - val_loss: -9.0913\n",
      "Epoch 2080/5000\n",
      "23/23 [==============================] - 4s 171ms/step - loss: -9.2460 - val_loss: -9.0922\n",
      "Epoch 2081/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.3219 - val_loss: -9.0738\n",
      "Epoch 2082/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.2557 - val_loss: -9.1010\n",
      "Epoch 2083/5000\n",
      "23/23 [==============================] - 3s 114ms/step - loss: -9.2812 - val_loss: -9.0912\n",
      "Epoch 2084/5000\n",
      "23/23 [==============================] - 6s 255ms/step - loss: -9.3236 - val_loss: -9.0866\n",
      "Epoch 2085/5000\n",
      "23/23 [==============================] - 5s 247ms/step - loss: -9.3403 - val_loss: -9.0823\n",
      "Epoch 2086/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.2789 - val_loss: -9.1062\n",
      "Epoch 2087/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.2716 - val_loss: -9.0919\n",
      "Epoch 2088/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.2781 - val_loss: -9.0914\n",
      "Epoch 2089/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.2719 - val_loss: -9.0777\n",
      "Epoch 2090/5000\n",
      "23/23 [==============================] - 5s 227ms/step - loss: -9.1999 - val_loss: -9.1049\n",
      "Epoch 2091/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.2739 - val_loss: -9.1029\n",
      "Epoch 2092/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.3222 - val_loss: -9.0901\n",
      "Epoch 2093/5000\n",
      "23/23 [==============================] - 5s 217ms/step - loss: -9.2791 - val_loss: -9.0981\n",
      "Epoch 2094/5000\n",
      "23/23 [==============================] - 6s 255ms/step - loss: -9.2803 - val_loss: -9.1082\n",
      "Epoch 2095/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.2564 - val_loss: -9.0969\n",
      "Epoch 2096/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.2972 - val_loss: -9.0852\n",
      "Epoch 2097/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -9.2887 - val_loss: -9.0981\n",
      "Epoch 2098/5000\n",
      "23/23 [==============================] - 2s 113ms/step - loss: -9.2741 - val_loss: -9.0983\n",
      "Epoch 2099/5000\n",
      "23/23 [==============================] - 3s 148ms/step - loss: -9.3042 - val_loss: -9.1129\n",
      "Epoch 2100/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.2883 - val_loss: -9.0943\n",
      "Epoch 2101/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.3437 - val_loss: -9.0915\n",
      "Epoch 2102/5000\n",
      "23/23 [==============================] - 5s 246ms/step - loss: -9.2292 - val_loss: -9.1113\n",
      "Epoch 2103/5000\n",
      "23/23 [==============================] - 5s 227ms/step - loss: -9.2623 - val_loss: -9.1074\n",
      "Epoch 2104/5000\n",
      "23/23 [==============================] - 6s 267ms/step - loss: -9.2304 - val_loss: -9.0990\n",
      "Epoch 2105/5000\n",
      "23/23 [==============================] - 6s 265ms/step - loss: -9.3557 - val_loss: -9.0963\n",
      "Epoch 2106/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.3202 - val_loss: -9.1110\n",
      "Epoch 2107/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.3211 - val_loss: -9.0835\n",
      "Epoch 2108/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.2441 - val_loss: -9.1114\n",
      "Epoch 2109/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.3205 - val_loss: -9.1123\n",
      "Epoch 2110/5000\n",
      "23/23 [==============================] - 3s 157ms/step - loss: -9.2887 - val_loss: -9.0918\n",
      "Epoch 2111/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.2738 - val_loss: -9.1025\n",
      "Epoch 2112/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.2828 - val_loss: -9.0940\n",
      "Epoch 2113/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.3175 - val_loss: -9.1050\n",
      "Epoch 2114/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.2955 - val_loss: -9.0961\n",
      "Epoch 2115/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.2494 - val_loss: -9.0979\n",
      "Epoch 2116/5000\n",
      "23/23 [==============================] - 5s 240ms/step - loss: -9.2753 - val_loss: -9.0908\n",
      "Epoch 2117/5000\n",
      "23/23 [==============================] - 6s 266ms/step - loss: -9.3216 - val_loss: -9.1033\n",
      "Epoch 2118/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.2475 - val_loss: -9.1032\n",
      "Epoch 2119/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.3015 - val_loss: -9.1043\n",
      "Epoch 2120/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -9.2630 - val_loss: -9.1111\n",
      "Epoch 2121/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.2021 - val_loss: -9.1035\n",
      "Epoch 2122/5000\n",
      "23/23 [==============================] - 6s 267ms/step - loss: -9.3001 - val_loss: -9.0873\n",
      "Epoch 2123/5000\n",
      "23/23 [==============================] - 5s 247ms/step - loss: -9.2367 - val_loss: -9.1071\n",
      "Epoch 2124/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.2831 - val_loss: -9.1092\n",
      "Epoch 2125/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.3085 - val_loss: -9.0932\n",
      "Epoch 2126/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.2931 - val_loss: -9.0927\n",
      "Epoch 2127/5000\n",
      "23/23 [==============================] - 3s 133ms/step - loss: -9.2951 - val_loss: -9.1120\n",
      "Epoch 2128/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.3271 - val_loss: -9.0981\n",
      "Epoch 2129/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.2853 - val_loss: -9.1117\n",
      "Epoch 2130/5000\n",
      "23/23 [==============================] - 6s 251ms/step - loss: -9.2779 - val_loss: -9.1003\n",
      "Epoch 2131/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.2965 - val_loss: -9.1062\n",
      "Epoch 2132/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.2754 - val_loss: -9.0993\n",
      "Epoch 2133/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.1800 - val_loss: -9.1095\n",
      "Epoch 2134/5000\n",
      "23/23 [==============================] - 4s 173ms/step - loss: -9.2902 - val_loss: -9.0685\n",
      "Epoch 2135/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.2886 - val_loss: -9.1216\n",
      "Epoch 2136/5000\n",
      "23/23 [==============================] - 5s 241ms/step - loss: -9.2906 - val_loss: -9.1037\n",
      "Epoch 2137/5000\n",
      "23/23 [==============================] - 5s 241ms/step - loss: -9.2627 - val_loss: -9.1049\n",
      "Epoch 2138/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -9.2847 - val_loss: -9.0898\n",
      "Epoch 2139/5000\n",
      "23/23 [==============================] - 5s 247ms/step - loss: -9.2961 - val_loss: -9.1148\n",
      "Epoch 2140/5000\n",
      "23/23 [==============================] - 5s 247ms/step - loss: -9.2625 - val_loss: -9.1181\n",
      "Epoch 2141/5000\n",
      "23/23 [==============================] - 4s 200ms/step - loss: -9.2344 - val_loss: -9.1058\n",
      "Epoch 2142/5000\n",
      "23/23 [==============================] - 5s 235ms/step - loss: -9.2372 - val_loss: -9.1053\n",
      "Epoch 2143/5000\n",
      "23/23 [==============================] - 3s 119ms/step - loss: -9.3003 - val_loss: -9.1107\n",
      "Epoch 2144/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.3533 - val_loss: -9.1105\n",
      "Epoch 2145/5000\n",
      "23/23 [==============================] - 4s 193ms/step - loss: -9.3013 - val_loss: -9.1040\n",
      "Epoch 2146/5000\n",
      "23/23 [==============================] - 3s 148ms/step - loss: -9.2725 - val_loss: -9.1021\n",
      "Epoch 2147/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.2790 - val_loss: -9.0990\n",
      "Epoch 2148/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.2934 - val_loss: -9.1077\n",
      "Epoch 2149/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.1544 - val_loss: -9.1090\n",
      "Epoch 2150/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.3344 - val_loss: -9.0905\n",
      "Epoch 2151/5000\n",
      "23/23 [==============================] - 5s 240ms/step - loss: -9.3041 - val_loss: -9.1001\n",
      "Epoch 2152/5000\n",
      "23/23 [==============================] - 3s 158ms/step - loss: -9.3165 - val_loss: -9.1096\n",
      "Epoch 2153/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.2897 - val_loss: -9.1029\n",
      "Epoch 2154/5000\n",
      "23/23 [==============================] - 5s 240ms/step - loss: -9.2560 - val_loss: -9.1062\n",
      "Epoch 2155/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.3429 - val_loss: -9.1030\n",
      "Epoch 2156/5000\n",
      "23/23 [==============================] - 3s 116ms/step - loss: -9.3044 - val_loss: -9.1010\n",
      "Epoch 2157/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.2688 - val_loss: -9.1150\n",
      "Epoch 2158/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.2022 - val_loss: -9.1147\n",
      "Epoch 2159/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.3195 - val_loss: -9.1000\n",
      "Epoch 2160/5000\n",
      "23/23 [==============================] - 4s 178ms/step - loss: -9.2907 - val_loss: -9.1135\n",
      "Epoch 2161/5000\n",
      "23/23 [==============================] - 5s 229ms/step - loss: -9.2933 - val_loss: -9.1053\n",
      "Epoch 2162/5000\n",
      "23/23 [==============================] - 3s 142ms/step - loss: -9.2973 - val_loss: -9.1008\n",
      "Epoch 2163/5000\n",
      "23/23 [==============================] - 6s 262ms/step - loss: -9.2632 - val_loss: -9.1229\n",
      "Epoch 2164/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.2881 - val_loss: -9.1182\n",
      "Epoch 2165/5000\n",
      "23/23 [==============================] - 6s 254ms/step - loss: -9.3371 - val_loss: -9.0993\n",
      "Epoch 2166/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.2968 - val_loss: -9.0991\n",
      "Epoch 2167/5000\n",
      "23/23 [==============================] - 3s 144ms/step - loss: -9.2994 - val_loss: -9.1214\n",
      "Epoch 2168/5000\n",
      "23/23 [==============================] - 5s 217ms/step - loss: -9.2878 - val_loss: -9.1117\n",
      "Epoch 2169/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.3452 - val_loss: -9.0907\n",
      "Epoch 2170/5000\n",
      "23/23 [==============================] - 4s 171ms/step - loss: -9.2863 - val_loss: -9.0937\n",
      "Epoch 2171/5000\n",
      "23/23 [==============================] - 3s 158ms/step - loss: -9.2445 - val_loss: -9.1116\n",
      "Epoch 2172/5000\n",
      "23/23 [==============================] - 4s 195ms/step - loss: -9.2128 - val_loss: -9.0998\n",
      "Epoch 2173/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.2601 - val_loss: -9.1072\n",
      "Epoch 2174/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.2717 - val_loss: -9.1140\n",
      "Epoch 2175/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.3160 - val_loss: -9.0930\n",
      "Epoch 2176/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.2683 - val_loss: -9.1037\n",
      "Epoch 2177/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.2951 - val_loss: -9.1172\n",
      "Epoch 2178/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.3156 - val_loss: -9.1150\n",
      "Epoch 2179/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.3268 - val_loss: -9.0971\n",
      "Epoch 2180/5000\n",
      "23/23 [==============================] - 4s 195ms/step - loss: -9.3255 - val_loss: -9.1233\n",
      "Epoch 2181/5000\n",
      "23/23 [==============================] - 5s 237ms/step - loss: -9.3189 - val_loss: -9.1242\n",
      "Epoch 2182/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.3258 - val_loss: -9.1180\n",
      "Epoch 2183/5000\n",
      "23/23 [==============================] - 5s 215ms/step - loss: -9.2808 - val_loss: -9.1041\n",
      "Epoch 2184/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.3309 - val_loss: -9.1179\n",
      "Epoch 2185/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.2688 - val_loss: -9.1183\n",
      "Epoch 2186/5000\n",
      "23/23 [==============================] - 3s 152ms/step - loss: -9.3211 - val_loss: -9.1191\n",
      "Epoch 2187/5000\n",
      "23/23 [==============================] - 5s 206ms/step - loss: -9.2966 - val_loss: -9.1186\n",
      "Epoch 2188/5000\n",
      "23/23 [==============================] - 4s 193ms/step - loss: -9.2398 - val_loss: -9.1009\n",
      "Epoch 2189/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.3310 - val_loss: -9.1352\n",
      "Epoch 2190/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.2603 - val_loss: -9.1261\n",
      "Epoch 2191/5000\n",
      "23/23 [==============================] - 4s 178ms/step - loss: -9.2529 - val_loss: -9.1172\n",
      "Epoch 2192/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.2831 - val_loss: -9.1236\n",
      "Epoch 2193/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -9.3125 - val_loss: -9.1161\n",
      "Epoch 2194/5000\n",
      "23/23 [==============================] - 6s 257ms/step - loss: -9.3496 - val_loss: -9.1074\n",
      "Epoch 2195/5000\n",
      "23/23 [==============================] - 4s 179ms/step - loss: -9.3150 - val_loss: -9.1043\n",
      "Epoch 2196/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.3005 - val_loss: -9.0977\n",
      "Epoch 2197/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.2754 - val_loss: -9.1183\n",
      "Epoch 2198/5000\n",
      "23/23 [==============================] - 3s 134ms/step - loss: -9.3315 - val_loss: -9.1116\n",
      "Epoch 2199/5000\n",
      "23/23 [==============================] - 5s 211ms/step - loss: -9.2623 - val_loss: -9.1254\n",
      "Epoch 2200/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.2981 - val_loss: -9.1044\n",
      "Epoch 2201/5000\n",
      "23/23 [==============================] - 2s 110ms/step - loss: -9.3885 - val_loss: -9.1251\n",
      "Epoch 2202/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.3131 - val_loss: -9.1129\n",
      "Epoch 2203/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.2875 - val_loss: -9.1116\n",
      "Epoch 2204/5000\n",
      "23/23 [==============================] - 5s 231ms/step - loss: -9.3711 - val_loss: -9.1202\n",
      "Epoch 2205/5000\n",
      "23/23 [==============================] - 10s 475ms/step - loss: -9.2233 - val_loss: -9.1137\n",
      "Epoch 2206/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.3409 - val_loss: -9.1248\n",
      "Epoch 2207/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.2717 - val_loss: -9.1213\n",
      "Epoch 2208/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.2946 - val_loss: -9.1264\n",
      "Epoch 2209/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.2378 - val_loss: -9.1407\n",
      "Epoch 2210/5000\n",
      "23/23 [==============================] - 5s 235ms/step - loss: -9.2724 - val_loss: -9.1030\n",
      "Epoch 2211/5000\n",
      "23/23 [==============================] - 6s 251ms/step - loss: -9.3060 - val_loss: -9.1188\n",
      "Epoch 2212/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.3565 - val_loss: -9.1208\n",
      "Epoch 2213/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.2382 - val_loss: -9.1265\n",
      "Epoch 2214/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.2961 - val_loss: -9.1046\n",
      "Epoch 2215/5000\n",
      "23/23 [==============================] - 4s 196ms/step - loss: -9.3005 - val_loss: -9.1027\n",
      "Epoch 2216/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.2509 - val_loss: -9.1175\n",
      "Epoch 2217/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.2834 - val_loss: -9.1280\n",
      "Epoch 2218/5000\n",
      "23/23 [==============================] - 5s 241ms/step - loss: -9.3163 - val_loss: -9.1234\n",
      "Epoch 2219/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.3412 - val_loss: -9.1149\n",
      "Epoch 2220/5000\n",
      "23/23 [==============================] - 4s 177ms/step - loss: -9.3197 - val_loss: -9.1394\n",
      "Epoch 2221/5000\n",
      "23/23 [==============================] - 4s 200ms/step - loss: -9.3340 - val_loss: -9.1275\n",
      "Epoch 2222/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.3284 - val_loss: -9.1388\n",
      "Epoch 2223/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.3388 - val_loss: -9.1330\n",
      "Epoch 2224/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -9.3140 - val_loss: -9.1310\n",
      "Epoch 2225/5000\n",
      "23/23 [==============================] - 3s 114ms/step - loss: -9.2467 - val_loss: -9.1180\n",
      "Epoch 2226/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.2963 - val_loss: -9.1173\n",
      "Epoch 2227/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.2361 - val_loss: -9.1162\n",
      "Epoch 2228/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -9.3573 - val_loss: -9.1217\n",
      "Epoch 2229/5000\n",
      "23/23 [==============================] - 2s 104ms/step - loss: -9.3165 - val_loss: -9.1151\n",
      "Epoch 2230/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.3020 - val_loss: -9.1136\n",
      "Epoch 2231/5000\n",
      "23/23 [==============================] - 6s 251ms/step - loss: -9.3116 - val_loss: -9.1274\n",
      "Epoch 2232/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.3278 - val_loss: -9.1216\n",
      "Epoch 2233/5000\n",
      "23/23 [==============================] - 2s 109ms/step - loss: -9.3083 - val_loss: -9.1259\n",
      "Epoch 2234/5000\n",
      "23/23 [==============================] - 3s 153ms/step - loss: -9.3221 - val_loss: -9.1250\n",
      "Epoch 2235/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.3584 - val_loss: -9.1189\n",
      "Epoch 2236/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.2889 - val_loss: -9.1341\n",
      "Epoch 2237/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.3177 - val_loss: -9.1147\n",
      "Epoch 2238/5000\n",
      "23/23 [==============================] - 5s 246ms/step - loss: -9.2844 - val_loss: -9.1263\n",
      "Epoch 2239/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.2752 - val_loss: -9.1272\n",
      "Epoch 2240/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.3468 - val_loss: -9.1229\n",
      "Epoch 2241/5000\n",
      "23/23 [==============================] - 5s 221ms/step - loss: -9.2601 - val_loss: -9.1298\n",
      "Epoch 2242/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.3084 - val_loss: -9.1363\n",
      "Epoch 2243/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.3376 - val_loss: -9.1007\n",
      "Epoch 2244/5000\n",
      "23/23 [==============================] - 3s 154ms/step - loss: -9.3298 - val_loss: -9.1397\n",
      "Epoch 2245/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.3124 - val_loss: -9.1388\n",
      "Epoch 2246/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.3403 - val_loss: -9.1234\n",
      "Epoch 2247/5000\n",
      "23/23 [==============================] - 3s 118ms/step - loss: -9.2335 - val_loss: -9.1177\n",
      "Epoch 2248/5000\n",
      "23/23 [==============================] - 5s 245ms/step - loss: -9.2845 - val_loss: -9.1235\n",
      "Epoch 2249/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.3353 - val_loss: -9.1188\n",
      "Epoch 2250/5000\n",
      "23/23 [==============================] - 5s 224ms/step - loss: -9.3214 - val_loss: -9.1305\n",
      "Epoch 2251/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.2963 - val_loss: -9.1430\n",
      "Epoch 2252/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.3389 - val_loss: -9.1070\n",
      "Epoch 2253/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.3431 - val_loss: -9.1339\n",
      "Epoch 2254/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -9.2883 - val_loss: -9.1365\n",
      "Epoch 2255/5000\n",
      "23/23 [==============================] - 5s 232ms/step - loss: -9.3061 - val_loss: -9.1155\n",
      "Epoch 2256/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -9.2897 - val_loss: -9.1393\n",
      "Epoch 2257/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.2225 - val_loss: -9.1151\n",
      "Epoch 2258/5000\n",
      "23/23 [==============================] - 6s 262ms/step - loss: -9.3408 - val_loss: -9.1343\n",
      "Epoch 2259/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.3577 - val_loss: -9.1388\n",
      "Epoch 2260/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.3379 - val_loss: -9.1301\n",
      "Epoch 2261/5000\n",
      "23/23 [==============================] - 4s 197ms/step - loss: -9.2943 - val_loss: -9.1374\n",
      "Epoch 2262/5000\n",
      "23/23 [==============================] - 3s 119ms/step - loss: -9.3278 - val_loss: -9.1356\n",
      "Epoch 2263/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.3077 - val_loss: -9.1279\n",
      "Epoch 2264/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.3397 - val_loss: -9.1477\n",
      "Epoch 2265/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.2629 - val_loss: -9.1275\n",
      "Epoch 2266/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.3559 - val_loss: -9.1261\n",
      "Epoch 2267/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.3116 - val_loss: -9.1433\n",
      "Epoch 2268/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.3215 - val_loss: -9.1366\n",
      "Epoch 2269/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.3125 - val_loss: -9.1269\n",
      "Epoch 2270/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.2534 - val_loss: -9.1330\n",
      "Epoch 2271/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.3023 - val_loss: -9.1247\n",
      "Epoch 2272/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -9.2710 - val_loss: -9.1400\n",
      "Epoch 2273/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.3110 - val_loss: -9.1330\n",
      "Epoch 2274/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.2028 - val_loss: -9.1195\n",
      "Epoch 2275/5000\n",
      "23/23 [==============================] - 3s 147ms/step - loss: -9.2455 - val_loss: -9.1362\n",
      "Epoch 2276/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.2579 - val_loss: -9.1398\n",
      "Epoch 2277/5000\n",
      "23/23 [==============================] - 4s 168ms/step - loss: -9.3295 - val_loss: -9.1404\n",
      "Epoch 2278/5000\n",
      "23/23 [==============================] - 3s 131ms/step - loss: -9.2116 - val_loss: -9.1491\n",
      "Epoch 2279/5000\n",
      "23/23 [==============================] - 3s 132ms/step - loss: -9.3131 - val_loss: -9.1426\n",
      "Epoch 2280/5000\n",
      "23/23 [==============================] - 4s 175ms/step - loss: -9.2991 - val_loss: -9.1335\n",
      "Epoch 2281/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.3271 - val_loss: -9.1325\n",
      "Epoch 2282/5000\n",
      "23/23 [==============================] - 5s 214ms/step - loss: -9.2911 - val_loss: -9.1288\n",
      "Epoch 2283/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.3059 - val_loss: -9.1261\n",
      "Epoch 2284/5000\n",
      "23/23 [==============================] - 3s 117ms/step - loss: -9.2914 - val_loss: -9.1346\n",
      "Epoch 2285/5000\n",
      "23/23 [==============================] - 4s 160ms/step - loss: -9.2563 - val_loss: -9.1277\n",
      "Epoch 2286/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.3317 - val_loss: -9.1313\n",
      "Epoch 2287/5000\n",
      "23/23 [==============================] - 3s 136ms/step - loss: -9.3557 - val_loss: -9.1343\n",
      "Epoch 2288/5000\n",
      "23/23 [==============================] - 3s 120ms/step - loss: -9.3435 - val_loss: -9.1320\n",
      "Epoch 2289/5000\n",
      "23/23 [==============================] - 5s 240ms/step - loss: -9.3177 - val_loss: -9.1434\n",
      "Epoch 2290/5000\n",
      "23/23 [==============================] - 4s 164ms/step - loss: -9.3477 - val_loss: -9.1375\n",
      "Epoch 2291/5000\n",
      "23/23 [==============================] - 3s 137ms/step - loss: -9.3544 - val_loss: -9.1382\n",
      "Epoch 2292/5000\n",
      "23/23 [==============================] - 4s 172ms/step - loss: -9.3524 - val_loss: -9.1375\n",
      "Epoch 2293/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.2965 - val_loss: -9.1213\n",
      "Epoch 2294/5000\n",
      "23/23 [==============================] - 3s 117ms/step - loss: -9.3267 - val_loss: -9.1352\n",
      "Epoch 2295/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.3710 - val_loss: -9.1455\n",
      "Epoch 2296/5000\n",
      "23/23 [==============================] - 3s 150ms/step - loss: -9.3561 - val_loss: -9.1191\n",
      "Epoch 2297/5000\n",
      "23/23 [==============================] - 5s 247ms/step - loss: -9.3380 - val_loss: -9.1281\n",
      "Epoch 2298/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.3076 - val_loss: -9.1209\n",
      "Epoch 2299/5000\n",
      "23/23 [==============================] - 6s 257ms/step - loss: -9.3401 - val_loss: -9.1470\n",
      "Epoch 2300/5000\n",
      "23/23 [==============================] - 3s 131ms/step - loss: -9.3287 - val_loss: -9.1494\n",
      "Epoch 2301/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.3199 - val_loss: -9.1398\n",
      "Epoch 2302/5000\n",
      "23/23 [==============================] - 4s 204ms/step - loss: -9.2697 - val_loss: -9.1336\n",
      "Epoch 2303/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -9.3305 - val_loss: -9.1349\n",
      "Epoch 2304/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.3173 - val_loss: -9.1298\n",
      "Epoch 2305/5000\n",
      "23/23 [==============================] - 3s 146ms/step - loss: -9.3266 - val_loss: -9.1342\n",
      "Epoch 2306/5000\n",
      "23/23 [==============================] - 4s 163ms/step - loss: -9.3245 - val_loss: -9.1576\n",
      "Epoch 2307/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.2829 - val_loss: -9.1544\n",
      "Epoch 2308/5000\n",
      "23/23 [==============================] - 2s 108ms/step - loss: -9.3331 - val_loss: -9.1423\n",
      "Epoch 2309/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.3575 - val_loss: -9.1535\n",
      "Epoch 2310/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.3502 - val_loss: -9.1533\n",
      "Epoch 2311/5000\n",
      "23/23 [==============================] - 5s 226ms/step - loss: -9.3581 - val_loss: -9.1482\n",
      "Epoch 2312/5000\n",
      "23/23 [==============================] - 4s 173ms/step - loss: -9.2745 - val_loss: -9.1402\n",
      "Epoch 2313/5000\n",
      "23/23 [==============================] - 6s 254ms/step - loss: -9.3727 - val_loss: -9.1381\n",
      "Epoch 2314/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.2413 - val_loss: -9.1415\n",
      "Epoch 2315/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.2729 - val_loss: -9.1341\n",
      "Epoch 2316/5000\n",
      "23/23 [==============================] - 5s 240ms/step - loss: -9.3486 - val_loss: -9.1454\n",
      "Epoch 2317/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.3348 - val_loss: -9.1589\n",
      "Epoch 2318/5000\n",
      "23/23 [==============================] - 2s 109ms/step - loss: -9.2835 - val_loss: -9.1402\n",
      "Epoch 2319/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.3368 - val_loss: -9.1465\n",
      "Epoch 2320/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.3269 - val_loss: -9.1405\n",
      "Epoch 2321/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -9.3269 - val_loss: -9.1450\n",
      "Epoch 2322/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.3614 - val_loss: -9.1483\n",
      "Epoch 2323/5000\n",
      "23/23 [==============================] - 5s 247ms/step - loss: -9.2948 - val_loss: -9.1593\n",
      "Epoch 2324/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.3676 - val_loss: -9.1391\n",
      "Epoch 2325/5000\n",
      "23/23 [==============================] - 5s 227ms/step - loss: -9.3155 - val_loss: -9.1391\n",
      "Epoch 2326/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.3490 - val_loss: -9.1498\n",
      "Epoch 2327/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.3260 - val_loss: -9.1418\n",
      "Epoch 2328/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.2337 - val_loss: -9.1497\n",
      "Epoch 2329/5000\n",
      "23/23 [==============================] - 3s 119ms/step - loss: -9.3045 - val_loss: -9.1417\n",
      "Epoch 2330/5000\n",
      "23/23 [==============================] - 4s 184ms/step - loss: -9.3191 - val_loss: -9.1434\n",
      "Epoch 2331/5000\n",
      "23/23 [==============================] - 6s 250ms/step - loss: -9.3386 - val_loss: -9.1399\n",
      "Epoch 2332/5000\n",
      "23/23 [==============================] - 3s 135ms/step - loss: -9.3758 - val_loss: -9.1473\n",
      "Epoch 2333/5000\n",
      "23/23 [==============================] - 3s 133ms/step - loss: -9.3035 - val_loss: -9.1576\n",
      "Epoch 2334/5000\n",
      "23/23 [==============================] - 3s 157ms/step - loss: -9.2729 - val_loss: -9.1573\n",
      "Epoch 2335/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.2794 - val_loss: -9.1597\n",
      "Epoch 2336/5000\n",
      "23/23 [==============================] - 10s 475ms/step - loss: -9.3707 - val_loss: -9.1419\n",
      "Epoch 2337/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.3291 - val_loss: -9.1425\n",
      "Epoch 2338/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.3200 - val_loss: -9.1407\n",
      "Epoch 2339/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.3547 - val_loss: -9.1401\n",
      "Epoch 2340/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.3094 - val_loss: -9.1463\n",
      "Epoch 2341/5000\n",
      "23/23 [==============================] - 5s 235ms/step - loss: -9.3397 - val_loss: -9.1425\n",
      "Epoch 2342/5000\n",
      "23/23 [==============================] - 6s 252ms/step - loss: -9.3478 - val_loss: -9.1396\n",
      "Epoch 2343/5000\n",
      "23/23 [==============================] - 4s 174ms/step - loss: -9.3278 - val_loss: -9.1582\n",
      "Epoch 2344/5000\n",
      "23/23 [==============================] - 5s 211ms/step - loss: -9.3380 - val_loss: -9.1443\n",
      "Epoch 2345/5000\n",
      "23/23 [==============================] - 3s 114ms/step - loss: -9.2805 - val_loss: -9.1321\n",
      "Epoch 2346/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.3963 - val_loss: -9.1498\n",
      "Epoch 2347/5000\n",
      "23/23 [==============================] - 4s 187ms/step - loss: -9.3350 - val_loss: -9.1477\n",
      "Epoch 2348/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.3558 - val_loss: -9.1174\n",
      "Epoch 2349/5000\n",
      "23/23 [==============================] - 3s 115ms/step - loss: -9.3244 - val_loss: -9.1434\n",
      "Epoch 2350/5000\n",
      "23/23 [==============================] - 3s 154ms/step - loss: -9.3536 - val_loss: -9.1479\n",
      "Epoch 2351/5000\n",
      "23/23 [==============================] - 2s 110ms/step - loss: -9.3019 - val_loss: -9.1532\n",
      "Epoch 2352/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.3086 - val_loss: -9.1521\n",
      "Epoch 2353/5000\n",
      "23/23 [==============================] - 4s 171ms/step - loss: -9.3320 - val_loss: -9.1430\n",
      "Epoch 2354/5000\n",
      "23/23 [==============================] - 6s 262ms/step - loss: -9.3619 - val_loss: -9.1366\n",
      "Epoch 2355/5000\n",
      "23/23 [==============================] - 6s 256ms/step - loss: -9.3489 - val_loss: -9.1451\n",
      "Epoch 2356/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -9.3824 - val_loss: -9.1499\n",
      "Epoch 2357/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -9.3607 - val_loss: -9.1440\n",
      "Epoch 2358/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.3271 - val_loss: -9.1515\n",
      "Epoch 2359/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.3187 - val_loss: -9.1484\n",
      "Epoch 2360/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -9.3191 - val_loss: -9.1626\n",
      "Epoch 2361/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.2998 - val_loss: -9.1565\n",
      "Epoch 2362/5000\n",
      "23/23 [==============================] - 5s 246ms/step - loss: -9.3259 - val_loss: -9.1376\n",
      "Epoch 2363/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.3749 - val_loss: -9.1459\n",
      "Epoch 2364/5000\n",
      "23/23 [==============================] - 3s 138ms/step - loss: -9.2925 - val_loss: -9.1561\n",
      "Epoch 2365/5000\n",
      "23/23 [==============================] - 4s 163ms/step - loss: -9.2244 - val_loss: -9.1457\n",
      "Epoch 2366/5000\n",
      "23/23 [==============================] - 3s 138ms/step - loss: -9.3049 - val_loss: -9.1541\n",
      "Epoch 2367/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.3763 - val_loss: -9.1463\n",
      "Epoch 2368/5000\n",
      "23/23 [==============================] - 3s 152ms/step - loss: -9.3178 - val_loss: -9.1449\n",
      "Epoch 2369/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.1951 - val_loss: -9.1401\n",
      "Epoch 2370/5000\n",
      "23/23 [==============================] - 5s 240ms/step - loss: -9.3137 - val_loss: -9.1402\n",
      "Epoch 2371/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.2785 - val_loss: -9.1492\n",
      "Epoch 2372/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.3125 - val_loss: -9.1624\n",
      "Epoch 2373/5000\n",
      "23/23 [==============================] - 3s 141ms/step - loss: -9.2785 - val_loss: -9.1533\n",
      "Epoch 2374/5000\n",
      "23/23 [==============================] - 5s 245ms/step - loss: -9.2815 - val_loss: -9.1649\n",
      "Epoch 2375/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.3580 - val_loss: -9.1481\n",
      "Epoch 2376/5000\n",
      "23/23 [==============================] - 5s 224ms/step - loss: -9.3297 - val_loss: -9.1725\n",
      "Epoch 2377/5000\n",
      "23/23 [==============================] - 2s 108ms/step - loss: -9.3595 - val_loss: -9.1546\n",
      "Epoch 2378/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.3723 - val_loss: -9.1405\n",
      "Epoch 2379/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.3174 - val_loss: -9.1601\n",
      "Epoch 2380/5000\n",
      "23/23 [==============================] - 3s 138ms/step - loss: -9.3642 - val_loss: -9.1621\n",
      "Epoch 2381/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.3348 - val_loss: -9.1739\n",
      "Epoch 2382/5000\n",
      "23/23 [==============================] - 4s 198ms/step - loss: -9.3616 - val_loss: -9.1599\n",
      "Epoch 2383/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -9.3857 - val_loss: -9.1717\n",
      "Epoch 2384/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.3237 - val_loss: -9.1226\n",
      "Epoch 2385/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.3422 - val_loss: -9.1369\n",
      "Epoch 2386/5000\n",
      "23/23 [==============================] - 6s 268ms/step - loss: -9.3454 - val_loss: -9.1452\n",
      "Epoch 2387/5000\n",
      "23/23 [==============================] - 4s 170ms/step - loss: -9.3665 - val_loss: -9.1721\n",
      "Epoch 2388/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.3507 - val_loss: -9.1475\n",
      "Epoch 2389/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.3859 - val_loss: -9.1582\n",
      "Epoch 2390/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.3175 - val_loss: -9.1486\n",
      "Epoch 2391/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.3565 - val_loss: -9.1586\n",
      "Epoch 2392/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.3115 - val_loss: -9.1484\n",
      "Epoch 2393/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.3546 - val_loss: -9.1538\n",
      "Epoch 2394/5000\n",
      "23/23 [==============================] - 4s 202ms/step - loss: -8.9792 - val_loss: -9.1652\n",
      "Epoch 2395/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.3544 - val_loss: -9.1613\n",
      "Epoch 2396/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.3792 - val_loss: -9.1672\n",
      "Epoch 2397/5000\n",
      "23/23 [==============================] - 4s 177ms/step - loss: -9.3271 - val_loss: -9.1332\n",
      "Epoch 2398/5000\n",
      "23/23 [==============================] - 6s 258ms/step - loss: -9.3659 - val_loss: -9.1508\n",
      "Epoch 2399/5000\n",
      "23/23 [==============================] - 3s 141ms/step - loss: -9.3000 - val_loss: -9.1556\n",
      "Epoch 2400/5000\n",
      "23/23 [==============================] - 3s 113ms/step - loss: -9.2928 - val_loss: -9.1413\n",
      "Epoch 2401/5000\n",
      "23/23 [==============================] - 3s 116ms/step - loss: -9.3330 - val_loss: -9.1523\n",
      "Epoch 2402/5000\n",
      "23/23 [==============================] - 5s 245ms/step - loss: -9.3771 - val_loss: -9.1396\n",
      "Epoch 2403/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.2912 - val_loss: -9.1673\n",
      "Epoch 2404/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.3768 - val_loss: -9.1559\n",
      "Epoch 2405/5000\n",
      "23/23 [==============================] - 4s 184ms/step - loss: -9.3461 - val_loss: -9.1677\n",
      "Epoch 2406/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.3001 - val_loss: -9.1565\n",
      "Epoch 2407/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.4117 - val_loss: -9.1696\n",
      "Epoch 2408/5000\n",
      "23/23 [==============================] - 4s 199ms/step - loss: -9.3115 - val_loss: -9.1539\n",
      "Epoch 2409/5000\n",
      "23/23 [==============================] - 2s 108ms/step - loss: -9.3474 - val_loss: -9.1485\n",
      "Epoch 2410/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.3092 - val_loss: -9.1670\n",
      "Epoch 2411/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.2929 - val_loss: -9.1667\n",
      "Epoch 2412/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.3120 - val_loss: -9.1467\n",
      "Epoch 2413/5000\n",
      "23/23 [==============================] - 3s 119ms/step - loss: -9.3260 - val_loss: -9.1673\n",
      "Epoch 2414/5000\n",
      "23/23 [==============================] - 6s 256ms/step - loss: -9.3552 - val_loss: -9.1859\n",
      "Epoch 2415/5000\n",
      "23/23 [==============================] - 5s 240ms/step - loss: -9.2833 - val_loss: -9.1670\n",
      "Epoch 2416/5000\n",
      "23/23 [==============================] - 6s 269ms/step - loss: -9.3885 - val_loss: -9.1573\n",
      "Epoch 2417/5000\n",
      "23/23 [==============================] - 6s 257ms/step - loss: -9.3712 - val_loss: -9.1620\n",
      "Epoch 2418/5000\n",
      "23/23 [==============================] - 5s 245ms/step - loss: -9.3701 - val_loss: -9.1620\n",
      "Epoch 2419/5000\n",
      "23/23 [==============================] - 5s 238ms/step - loss: -9.3527 - val_loss: -9.1543\n",
      "Epoch 2420/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.3253 - val_loss: -9.1689\n",
      "Epoch 2421/5000\n",
      "23/23 [==============================] - 3s 118ms/step - loss: -9.2992 - val_loss: -9.1756\n",
      "Epoch 2422/5000\n",
      "23/23 [==============================] - 3s 135ms/step - loss: -9.3533 - val_loss: -9.1657\n",
      "Epoch 2423/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.3591 - val_loss: -9.1723\n",
      "Epoch 2424/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.3987 - val_loss: -9.1572\n",
      "Epoch 2425/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.1552 - val_loss: -9.1487\n",
      "Epoch 2426/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -9.3326 - val_loss: -9.1540\n",
      "Epoch 2427/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -9.3221 - val_loss: -9.1705\n",
      "Epoch 2428/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.3589 - val_loss: -9.1660\n",
      "Epoch 2429/5000\n",
      "23/23 [==============================] - 4s 195ms/step - loss: -9.3740 - val_loss: -9.1681\n",
      "Epoch 2430/5000\n",
      "23/23 [==============================] - 6s 257ms/step - loss: -9.3742 - val_loss: -9.1570\n",
      "Epoch 2431/5000\n",
      "23/23 [==============================] - 4s 190ms/step - loss: -9.3830 - val_loss: -9.1647\n",
      "Epoch 2432/5000\n",
      "23/23 [==============================] - 6s 262ms/step - loss: -9.4067 - val_loss: -9.1685\n",
      "Epoch 2433/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.3623 - val_loss: -9.1631\n",
      "Epoch 2434/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -9.3488 - val_loss: -9.1556\n",
      "Epoch 2435/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.3410 - val_loss: -9.1583\n",
      "Epoch 2436/5000\n",
      "23/23 [==============================] - 4s 163ms/step - loss: -9.4194 - val_loss: -9.1525\n",
      "Epoch 2437/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.3045 - val_loss: -9.1656\n",
      "Epoch 2438/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.3175 - val_loss: -9.1553\n",
      "Epoch 2439/5000\n",
      "23/23 [==============================] - 3s 134ms/step - loss: -9.3948 - val_loss: -9.1725\n",
      "Epoch 2440/5000\n",
      "23/23 [==============================] - 4s 193ms/step - loss: -9.3027 - val_loss: -9.1797\n",
      "Epoch 2441/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.3639 - val_loss: -9.1712\n",
      "Epoch 2442/5000\n",
      "23/23 [==============================] - 4s 159ms/step - loss: -9.3493 - val_loss: -9.1775\n",
      "Epoch 2443/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.3605 - val_loss: -9.1639\n",
      "Epoch 2444/5000\n",
      "23/23 [==============================] - 4s 193ms/step - loss: -9.3308 - val_loss: -9.1822\n",
      "Epoch 2445/5000\n",
      "23/23 [==============================] - 5s 218ms/step - loss: -9.3358 - val_loss: -9.1603\n",
      "Epoch 2446/5000\n",
      "23/23 [==============================] - 5s 216ms/step - loss: -9.3236 - val_loss: -9.1757\n",
      "Epoch 2447/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.3579 - val_loss: -9.1621\n",
      "Epoch 2448/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.3435 - val_loss: -9.1732\n",
      "Epoch 2449/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.3429 - val_loss: -9.1609\n",
      "Epoch 2450/5000\n",
      "23/23 [==============================] - 3s 152ms/step - loss: -9.3989 - val_loss: -9.1596\n",
      "Epoch 2451/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.3402 - val_loss: -9.1662\n",
      "Epoch 2452/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -9.2942 - val_loss: -9.1792\n",
      "Epoch 2453/5000\n",
      "23/23 [==============================] - 6s 255ms/step - loss: -9.3520 - val_loss: -9.1727\n",
      "Epoch 2454/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.3984 - val_loss: -9.1755\n",
      "Epoch 2455/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.3661 - val_loss: -9.1775\n",
      "Epoch 2456/5000\n",
      "23/23 [==============================] - 3s 117ms/step - loss: -9.3091 - val_loss: -9.1573\n",
      "Epoch 2457/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.2953 - val_loss: -9.1635\n",
      "Epoch 2458/5000\n",
      "23/23 [==============================] - 3s 145ms/step - loss: -9.3440 - val_loss: -9.1688\n",
      "Epoch 2459/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.3396 - val_loss: -9.1679\n",
      "Epoch 2460/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.3214 - val_loss: -9.1717\n",
      "Epoch 2461/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.3529 - val_loss: -9.1614\n",
      "Epoch 2462/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.3582 - val_loss: -9.1810\n",
      "Epoch 2463/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.3347 - val_loss: -9.1655\n",
      "Epoch 2464/5000\n",
      "23/23 [==============================] - 2s 112ms/step - loss: -9.3208 - val_loss: -9.1594\n",
      "Epoch 2465/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -9.3679 - val_loss: -9.1569\n",
      "Epoch 2466/5000\n",
      "23/23 [==============================] - 3s 120ms/step - loss: -9.3981 - val_loss: -9.1643\n",
      "Epoch 2467/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.3703 - val_loss: -9.1609\n",
      "Epoch 2468/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.3303 - val_loss: -9.1856\n",
      "Epoch 2469/5000\n",
      "23/23 [==============================] - 5s 232ms/step - loss: -9.3304 - val_loss: -9.1785\n",
      "Epoch 2470/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.3794 - val_loss: -9.1604\n",
      "Epoch 2471/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.3429 - val_loss: -9.1780\n",
      "Epoch 2472/5000\n",
      "23/23 [==============================] - 4s 186ms/step - loss: -9.3548 - val_loss: -9.1650\n",
      "Epoch 2473/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.3532 - val_loss: -9.1809\n",
      "Epoch 2474/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.2982 - val_loss: -9.1607\n",
      "Epoch 2475/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.3472 - val_loss: -9.1700\n",
      "Epoch 2476/5000\n",
      "23/23 [==============================] - 2s 109ms/step - loss: -9.3406 - val_loss: -9.1657\n",
      "Epoch 2477/5000\n",
      "23/23 [==============================] - 2s 109ms/step - loss: -9.4182 - val_loss: -9.1673\n",
      "Epoch 2478/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.3884 - val_loss: -9.1821\n",
      "Epoch 2479/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.3763 - val_loss: -9.1644\n",
      "Epoch 2480/5000\n",
      "23/23 [==============================] - 4s 171ms/step - loss: -9.3910 - val_loss: -9.1609\n",
      "Epoch 2481/5000\n",
      "23/23 [==============================] - 5s 207ms/step - loss: -9.3152 - val_loss: -9.1634\n",
      "Epoch 2482/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.4024 - val_loss: -9.1869\n",
      "Epoch 2483/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.3489 - val_loss: -9.1540\n",
      "Epoch 2484/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.3636 - val_loss: -9.1767\n",
      "Epoch 2485/5000\n",
      "23/23 [==============================] - 2s 112ms/step - loss: -9.3661 - val_loss: -9.1714\n",
      "Epoch 2486/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.3326 - val_loss: -9.1758\n",
      "Epoch 2487/5000\n",
      "23/23 [==============================] - 4s 181ms/step - loss: -9.3699 - val_loss: -9.1787\n",
      "Epoch 2488/5000\n",
      "23/23 [==============================] - 3s 142ms/step - loss: -9.3592 - val_loss: -9.1690\n",
      "Epoch 2489/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.3717 - val_loss: -9.1671\n",
      "Epoch 2490/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.3756 - val_loss: -9.1780\n",
      "Epoch 2491/5000\n",
      "23/23 [==============================] - 4s 177ms/step - loss: -9.2989 - val_loss: -9.1691\n",
      "Epoch 2492/5000\n",
      "23/23 [==============================] - 6s 255ms/step - loss: -9.2999 - val_loss: -9.1752\n",
      "Epoch 2493/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.3552 - val_loss: -9.1707\n",
      "Epoch 2494/5000\n",
      "23/23 [==============================] - 3s 138ms/step - loss: -9.3671 - val_loss: -9.1778\n",
      "Epoch 2495/5000\n",
      "23/23 [==============================] - 5s 240ms/step - loss: -9.3581 - val_loss: -9.1717\n",
      "Epoch 2496/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -9.3495 - val_loss: -9.1870\n",
      "Epoch 2497/5000\n",
      "23/23 [==============================] - 4s 204ms/step - loss: -9.3976 - val_loss: -9.1769\n",
      "Epoch 2498/5000\n",
      "23/23 [==============================] - 5s 249ms/step - loss: -9.3436 - val_loss: -9.1767\n",
      "Epoch 2499/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.3017 - val_loss: -9.1615\n",
      "Epoch 2500/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.1767 - val_loss: -9.1744\n",
      "Epoch 2501/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -9.3614 - val_loss: -9.1665\n",
      "Epoch 2502/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -9.3534 - val_loss: -9.1758\n",
      "Epoch 2503/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.3746 - val_loss: -9.1649\n",
      "Epoch 2504/5000\n",
      "23/23 [==============================] - 5s 215ms/step - loss: -9.3580 - val_loss: -9.1835\n",
      "Epoch 2505/5000\n",
      "23/23 [==============================] - 5s 236ms/step - loss: -9.3753 - val_loss: -9.1796\n",
      "Epoch 2506/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.3874 - val_loss: -9.1820\n",
      "Epoch 2507/5000\n",
      "23/23 [==============================] - 5s 219ms/step - loss: -9.3550 - val_loss: -9.1911\n",
      "Epoch 2508/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.3718 - val_loss: -9.1882\n",
      "Epoch 2509/5000\n",
      "23/23 [==============================] - 3s 159ms/step - loss: -9.3913 - val_loss: -9.1867\n",
      "Epoch 2510/5000\n",
      "23/23 [==============================] - 4s 203ms/step - loss: -9.4182 - val_loss: -9.1816\n",
      "Epoch 2511/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.3797 - val_loss: -9.1799\n",
      "Epoch 2512/5000\n",
      "23/23 [==============================] - 6s 260ms/step - loss: -9.3758 - val_loss: -9.1765\n",
      "Epoch 2513/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.3670 - val_loss: -9.1731\n",
      "Epoch 2514/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.3940 - val_loss: -9.1815\n",
      "Epoch 2515/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.3513 - val_loss: -9.1658\n",
      "Epoch 2516/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.3574 - val_loss: -9.1834\n",
      "Epoch 2517/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.3241 - val_loss: -9.1790\n",
      "Epoch 2518/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.3788 - val_loss: -9.1695\n",
      "Epoch 2519/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.3528 - val_loss: -9.1889\n",
      "Epoch 2520/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.4112 - val_loss: -9.1812\n",
      "Epoch 2521/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.3757 - val_loss: -9.1849\n",
      "Epoch 2522/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.3478 - val_loss: -9.1812\n",
      "Epoch 2523/5000\n",
      "23/23 [==============================] - 5s 225ms/step - loss: -9.3675 - val_loss: -9.1471\n",
      "Epoch 2524/5000\n",
      "23/23 [==============================] - 5s 214ms/step - loss: -9.3535 - val_loss: -9.1843\n",
      "Epoch 2525/5000\n",
      "23/23 [==============================] - 4s 195ms/step - loss: -9.3630 - val_loss: -9.1709\n",
      "Epoch 2526/5000\n",
      "23/23 [==============================] - 2s 110ms/step - loss: -9.4158 - val_loss: -9.1765\n",
      "Epoch 2527/5000\n",
      "23/23 [==============================] - 4s 185ms/step - loss: -9.3615 - val_loss: -9.1820\n",
      "Epoch 2528/5000\n",
      "23/23 [==============================] - 3s 137ms/step - loss: -9.3154 - val_loss: -9.1987\n",
      "Epoch 2529/5000\n",
      "23/23 [==============================] - 3s 148ms/step - loss: -9.2703 - val_loss: -9.1692\n",
      "Epoch 2530/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.3762 - val_loss: -9.1798\n",
      "Epoch 2531/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.3691 - val_loss: -9.1785\n",
      "Epoch 2532/5000\n",
      "23/23 [==============================] - 4s 200ms/step - loss: -9.3675 - val_loss: -9.1890\n",
      "Epoch 2533/5000\n",
      "23/23 [==============================] - 5s 239ms/step - loss: -9.4047 - val_loss: -9.1740\n",
      "Epoch 2534/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -9.4074 - val_loss: -9.1785\n",
      "Epoch 2535/5000\n",
      "23/23 [==============================] - 5s 223ms/step - loss: -9.3987 - val_loss: -9.2015\n",
      "Epoch 2536/5000\n",
      "23/23 [==============================] - 5s 231ms/step - loss: -9.3166 - val_loss: -9.1854\n",
      "Epoch 2537/5000\n",
      "23/23 [==============================] - 3s 135ms/step - loss: -9.3399 - val_loss: -9.1545\n",
      "Epoch 2538/5000\n",
      "23/23 [==============================] - 4s 176ms/step - loss: -9.3782 - val_loss: -9.1666\n",
      "Epoch 2539/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.2982 - val_loss: -9.1833\n",
      "Epoch 2540/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.3763 - val_loss: -9.1730\n",
      "Epoch 2541/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.3738 - val_loss: -9.1972\n",
      "Epoch 2542/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.3145 - val_loss: -9.1920\n",
      "Epoch 2543/5000\n",
      "23/23 [==============================] - 4s 193ms/step - loss: -9.3864 - val_loss: -9.1868\n",
      "Epoch 2544/5000\n",
      "23/23 [==============================] - 4s 185ms/step - loss: -9.3284 - val_loss: -9.1909\n",
      "Epoch 2545/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.3173 - val_loss: -9.1947\n",
      "Epoch 2546/5000\n",
      "23/23 [==============================] - 3s 117ms/step - loss: -9.3888 - val_loss: -9.1969\n",
      "Epoch 2547/5000\n",
      "23/23 [==============================] - 2s 104ms/step - loss: -9.3065 - val_loss: -9.1995\n",
      "Epoch 2548/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -9.3784 - val_loss: -9.1855\n",
      "Epoch 2549/5000\n",
      "23/23 [==============================] - 5s 248ms/step - loss: -9.4058 - val_loss: -9.1806\n",
      "Epoch 2550/5000\n",
      "23/23 [==============================] - 4s 201ms/step - loss: -9.3740 - val_loss: -9.2038\n",
      "Epoch 2551/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.3279 - val_loss: -9.1821\n",
      "Epoch 2552/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.4039 - val_loss: -9.1815\n",
      "Epoch 2553/5000\n",
      "23/23 [==============================] - 4s 159ms/step - loss: -9.3641 - val_loss: -9.1781\n",
      "Epoch 2554/5000\n",
      "23/23 [==============================] - 5s 235ms/step - loss: -9.4020 - val_loss: -9.1847\n",
      "Epoch 2555/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.4099 - val_loss: -9.1943\n",
      "Epoch 2556/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.3170 - val_loss: -9.1863\n",
      "Epoch 2557/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.3955 - val_loss: -9.1835\n",
      "Epoch 2558/5000\n",
      "23/23 [==============================] - 3s 136ms/step - loss: -9.3311 - val_loss: -9.2068\n",
      "Epoch 2559/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.3476 - val_loss: -9.1934\n",
      "Epoch 2560/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -9.3693 - val_loss: -9.1661\n",
      "Epoch 2561/5000\n",
      "23/23 [==============================] - 4s 190ms/step - loss: -9.3919 - val_loss: -9.1989\n",
      "Epoch 2562/5000\n",
      "23/23 [==============================] - 3s 157ms/step - loss: -9.3873 - val_loss: -9.1856\n",
      "Epoch 2563/5000\n",
      "23/23 [==============================] - 3s 145ms/step - loss: -9.2890 - val_loss: -9.1853\n",
      "Epoch 2564/5000\n",
      "23/23 [==============================] - 6s 255ms/step - loss: -9.3919 - val_loss: -9.1772\n",
      "Epoch 2565/5000\n",
      "23/23 [==============================] - 4s 197ms/step - loss: -9.2975 - val_loss: -9.1819\n",
      "Epoch 2566/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.3333 - val_loss: -9.1859\n",
      "Epoch 2567/5000\n",
      "23/23 [==============================] - 5s 240ms/step - loss: -9.3680 - val_loss: -9.1932\n",
      "Epoch 2568/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -9.3589 - val_loss: -9.1896\n",
      "Epoch 2569/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.3033 - val_loss: -9.1853\n",
      "Epoch 2570/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.4011 - val_loss: -9.1775\n",
      "Epoch 2571/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.3848 - val_loss: -9.1903\n",
      "Epoch 2572/5000\n",
      "23/23 [==============================] - 3s 137ms/step - loss: -9.4510 - val_loss: -9.1824\n",
      "Epoch 2573/5000\n",
      "23/23 [==============================] - 5s 210ms/step - loss: -9.3949 - val_loss: -9.1983\n",
      "Epoch 2574/5000\n",
      "23/23 [==============================] - 4s 199ms/step - loss: -9.3182 - val_loss: -9.1900\n",
      "Epoch 2575/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -9.3115 - val_loss: -9.1943\n",
      "Epoch 2576/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.4200 - val_loss: -9.1874\n",
      "Epoch 2577/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.3313 - val_loss: -9.1956\n",
      "Epoch 2578/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.3716 - val_loss: -9.1963\n",
      "Epoch 2579/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.2435 - val_loss: -9.1911\n",
      "Epoch 2580/5000\n",
      "23/23 [==============================] - 2s 112ms/step - loss: -9.4067 - val_loss: -9.1924\n",
      "Epoch 2581/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.3835 - val_loss: -9.1990\n",
      "Epoch 2582/5000\n",
      "23/23 [==============================] - 4s 173ms/step - loss: -9.3704 - val_loss: -9.1823\n",
      "Epoch 2583/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.3609 - val_loss: -9.2065\n",
      "Epoch 2584/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.3756 - val_loss: -9.1845\n",
      "Epoch 2585/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.3720 - val_loss: -9.1934\n",
      "Epoch 2586/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4290 - val_loss: -9.1794\n",
      "Epoch 2587/5000\n",
      "23/23 [==============================] - 3s 114ms/step - loss: -9.3508 - val_loss: -9.1916\n",
      "Epoch 2588/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.3787 - val_loss: -9.1852\n",
      "Epoch 2589/5000\n",
      "23/23 [==============================] - 5s 235ms/step - loss: -9.4035 - val_loss: -9.1978\n",
      "Epoch 2590/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.3948 - val_loss: -9.1821\n",
      "Epoch 2591/5000\n",
      "23/23 [==============================] - 5s 237ms/step - loss: -9.3599 - val_loss: -9.1880\n",
      "Epoch 2592/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -9.3904 - val_loss: -9.1947\n",
      "Epoch 2593/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.3296 - val_loss: -9.1751\n",
      "Epoch 2594/5000\n",
      "23/23 [==============================] - 3s 134ms/step - loss: -9.3652 - val_loss: -9.1865\n",
      "Epoch 2595/5000\n",
      "23/23 [==============================] - 5s 247ms/step - loss: -9.3440 - val_loss: -9.1941\n",
      "Epoch 2596/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.3631 - val_loss: -9.1930\n",
      "Epoch 2597/5000\n",
      "23/23 [==============================] - 5s 211ms/step - loss: -9.4008 - val_loss: -9.1876\n",
      "Epoch 2598/5000\n",
      "23/23 [==============================] - 5s 213ms/step - loss: -9.3992 - val_loss: -9.1820\n",
      "Epoch 2599/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.2302 - val_loss: -9.1910\n",
      "Epoch 2600/5000\n",
      "23/23 [==============================] - 3s 151ms/step - loss: -9.3858 - val_loss: -9.1944\n",
      "Epoch 2601/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.3554 - val_loss: -9.1986\n",
      "Epoch 2602/5000\n",
      "23/23 [==============================] - 3s 120ms/step - loss: -9.3450 - val_loss: -9.1922\n",
      "Epoch 2603/5000\n",
      "23/23 [==============================] - 4s 167ms/step - loss: -9.4034 - val_loss: -9.1732\n",
      "Epoch 2604/5000\n",
      "23/23 [==============================] - 4s 203ms/step - loss: -9.3681 - val_loss: -9.1918\n",
      "Epoch 2605/5000\n",
      "23/23 [==============================] - 4s 188ms/step - loss: -9.3848 - val_loss: -9.1966\n",
      "Epoch 2606/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.3815 - val_loss: -9.1855\n",
      "Epoch 2607/5000\n",
      "23/23 [==============================] - 3s 137ms/step - loss: -9.3492 - val_loss: -9.1966\n",
      "Epoch 2608/5000\n",
      "23/23 [==============================] - 6s 249ms/step - loss: -9.3688 - val_loss: -9.1885\n",
      "Epoch 2609/5000\n",
      "23/23 [==============================] - 6s 252ms/step - loss: -9.3606 - val_loss: -9.1849\n",
      "Epoch 2610/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.3174 - val_loss: -9.1987\n",
      "Epoch 2611/5000\n",
      "23/23 [==============================] - 4s 189ms/step - loss: -9.3805 - val_loss: -9.2025\n",
      "Epoch 2612/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.4171 - val_loss: -9.2064\n",
      "Epoch 2613/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.4170 - val_loss: -9.1917\n",
      "Epoch 2614/5000\n",
      "23/23 [==============================] - 4s 172ms/step - loss: -9.4204 - val_loss: -9.2071\n",
      "Epoch 2615/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -9.3557 - val_loss: -9.2087\n",
      "Epoch 2616/5000\n",
      "23/23 [==============================] - 5s 226ms/step - loss: -9.4062 - val_loss: -9.2012\n",
      "Epoch 2617/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.3468 - val_loss: -9.2037\n",
      "Epoch 2618/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.3999 - val_loss: -9.1895\n",
      "Epoch 2619/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.2419 - val_loss: -9.1974\n",
      "Epoch 2620/5000\n",
      "23/23 [==============================] - 3s 120ms/step - loss: -9.4483 - val_loss: -9.1922\n",
      "Epoch 2621/5000\n",
      "23/23 [==============================] - 2s 110ms/step - loss: -9.3164 - val_loss: -9.2114\n",
      "Epoch 2622/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -9.3982 - val_loss: -9.1990\n",
      "Epoch 2623/5000\n",
      "23/23 [==============================] - 6s 259ms/step - loss: -9.4011 - val_loss: -9.1949\n",
      "Epoch 2624/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.3130 - val_loss: -9.2016\n",
      "Epoch 2625/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -9.3454 - val_loss: -9.1955\n",
      "Epoch 2626/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -9.3334 - val_loss: -9.1954\n",
      "Epoch 2627/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.3879 - val_loss: -9.2054\n",
      "Epoch 2628/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.3678 - val_loss: -9.2016\n",
      "Epoch 2629/5000\n",
      "23/23 [==============================] - 5s 225ms/step - loss: -9.3740 - val_loss: -9.2058\n",
      "Epoch 2630/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.3557 - val_loss: -9.1957\n",
      "Epoch 2631/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.3746 - val_loss: -9.2001\n",
      "Epoch 2632/5000\n",
      "23/23 [==============================] - 5s 210ms/step - loss: -9.3488 - val_loss: -9.2096\n",
      "Epoch 2633/5000\n",
      "23/23 [==============================] - 6s 253ms/step - loss: -9.3436 - val_loss: -9.1938\n",
      "Epoch 2634/5000\n",
      "23/23 [==============================] - 5s 230ms/step - loss: -9.3638 - val_loss: -9.2023\n",
      "Epoch 2635/5000\n",
      "23/23 [==============================] - 3s 132ms/step - loss: -9.3551 - val_loss: -9.2140\n",
      "Epoch 2636/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.3757 - val_loss: -9.1980\n",
      "Epoch 2637/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.3802 - val_loss: -9.2084\n",
      "Epoch 2638/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.4012 - val_loss: -9.2006\n",
      "Epoch 2639/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.3857 - val_loss: -9.1996\n",
      "Epoch 2640/5000\n",
      "23/23 [==============================] - 3s 148ms/step - loss: -9.3779 - val_loss: -9.1944\n",
      "Epoch 2641/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.3772 - val_loss: -9.1972\n",
      "Epoch 2642/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.3211 - val_loss: -9.2041\n",
      "Epoch 2643/5000\n",
      "23/23 [==============================] - 10s 475ms/step - loss: -9.3323 - val_loss: -9.2025\n",
      "Epoch 2644/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.3872 - val_loss: -9.1843\n",
      "Epoch 2645/5000\n",
      "23/23 [==============================] - 3s 136ms/step - loss: -9.3931 - val_loss: -9.1782\n",
      "Epoch 2646/5000\n",
      "23/23 [==============================] - 6s 251ms/step - loss: -9.3378 - val_loss: -9.1981\n",
      "Epoch 2647/5000\n",
      "23/23 [==============================] - 5s 210ms/step - loss: -9.3844 - val_loss: -9.1974\n",
      "Epoch 2648/5000\n",
      "23/23 [==============================] - 6s 255ms/step - loss: -9.4214 - val_loss: -9.1917\n",
      "Epoch 2649/5000\n",
      "23/23 [==============================] - 6s 252ms/step - loss: -9.4415 - val_loss: -9.2009\n",
      "Epoch 2650/5000\n",
      "23/23 [==============================] - 5s 210ms/step - loss: -9.3867 - val_loss: -9.1946\n",
      "Epoch 2651/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -9.3610 - val_loss: -9.2118\n",
      "Epoch 2652/5000\n",
      "23/23 [==============================] - 2s 109ms/step - loss: -9.3886 - val_loss: -9.1977\n",
      "Epoch 2653/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.4083 - val_loss: -9.1974\n",
      "Epoch 2654/5000\n",
      "23/23 [==============================] - 2s 113ms/step - loss: -9.4125 - val_loss: -9.2043\n",
      "Epoch 2655/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.4359 - val_loss: -9.2010\n",
      "Epoch 2656/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.3821 - val_loss: -9.1960\n",
      "Epoch 2657/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.3520 - val_loss: -9.1940\n",
      "Epoch 2658/5000\n",
      "23/23 [==============================] - 4s 180ms/step - loss: -9.3660 - val_loss: -9.1935\n",
      "Epoch 2659/5000\n",
      "23/23 [==============================] - 5s 220ms/step - loss: -9.3897 - val_loss: -9.1936\n",
      "Epoch 2660/5000\n",
      "23/23 [==============================] - 6s 255ms/step - loss: -9.4102 - val_loss: -9.2139\n",
      "Epoch 2661/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.3594 - val_loss: -9.2042\n",
      "Epoch 2662/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.3864 - val_loss: -9.1989\n",
      "Epoch 2663/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.3191 - val_loss: -9.2068\n",
      "Epoch 2664/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.3800 - val_loss: -9.2078\n",
      "Epoch 2665/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.3126 - val_loss: -9.1909\n",
      "Epoch 2666/5000\n",
      "23/23 [==============================] - 3s 157ms/step - loss: -9.3814 - val_loss: -9.1995\n",
      "Epoch 2667/5000\n",
      "23/23 [==============================] - 4s 196ms/step - loss: -9.3674 - val_loss: -9.2077\n",
      "Epoch 2668/5000\n",
      "23/23 [==============================] - 6s 257ms/step - loss: -9.3492 - val_loss: -9.2185\n",
      "Epoch 2669/5000\n",
      "23/23 [==============================] - 5s 246ms/step - loss: -9.3776 - val_loss: -9.2092\n",
      "Epoch 2670/5000\n",
      "23/23 [==============================] - 5s 232ms/step - loss: -9.4131 - val_loss: -9.1952\n",
      "Epoch 2671/5000\n",
      "23/23 [==============================] - 3s 116ms/step - loss: -9.3556 - val_loss: -9.2184\n",
      "Epoch 2672/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4173 - val_loss: -9.2061\n",
      "Epoch 2673/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.3367 - val_loss: -9.2052\n",
      "Epoch 2674/5000\n",
      "23/23 [==============================] - 4s 193ms/step - loss: -9.3554 - val_loss: -9.2056\n",
      "Epoch 2675/5000\n",
      "23/23 [==============================] - 4s 192ms/step - loss: -9.4019 - val_loss: -9.2129\n",
      "Epoch 2676/5000\n",
      "23/23 [==============================] - 6s 265ms/step - loss: -9.3873 - val_loss: -9.1915\n",
      "Epoch 2677/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.3745 - val_loss: -9.2068\n",
      "Epoch 2678/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.4165 - val_loss: -9.2019\n",
      "Epoch 2679/5000\n",
      "23/23 [==============================] - 6s 257ms/step - loss: -9.3810 - val_loss: -9.1945\n",
      "Epoch 2680/5000\n",
      "23/23 [==============================] - 3s 155ms/step - loss: -9.3883 - val_loss: -9.1963\n",
      "Epoch 2681/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.4205 - val_loss: -9.2060\n",
      "Epoch 2682/5000\n",
      "23/23 [==============================] - 4s 167ms/step - loss: -9.3848 - val_loss: -9.2010\n",
      "Epoch 2683/5000\n",
      "23/23 [==============================] - 6s 259ms/step - loss: -9.4127 - val_loss: -9.2255\n",
      "Epoch 2684/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.3446 - val_loss: -9.1969\n",
      "Epoch 2685/5000\n",
      "23/23 [==============================] - 4s 160ms/step - loss: -9.4009 - val_loss: -9.2207\n",
      "Epoch 2686/5000\n",
      "23/23 [==============================] - 6s 268ms/step - loss: -9.3477 - val_loss: -9.2039\n",
      "Epoch 2687/5000\n",
      "23/23 [==============================] - 3s 115ms/step - loss: -9.3782 - val_loss: -9.2094\n",
      "Epoch 2688/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.4251 - val_loss: -9.1966\n",
      "Epoch 2689/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.4121 - val_loss: -9.2145\n",
      "Epoch 2690/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -9.4101 - val_loss: -9.1940\n",
      "Epoch 2691/5000\n",
      "23/23 [==============================] - 5s 232ms/step - loss: -9.4413 - val_loss: -9.1919\n",
      "Epoch 2692/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -9.4434 - val_loss: -9.2075\n",
      "Epoch 2693/5000\n",
      "23/23 [==============================] - 3s 120ms/step - loss: -9.3541 - val_loss: -9.2030\n",
      "Epoch 2694/5000\n",
      "23/23 [==============================] - 3s 136ms/step - loss: -9.3826 - val_loss: -9.2032\n",
      "Epoch 2695/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.3919 - val_loss: -9.2102\n",
      "Epoch 2696/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.3709 - val_loss: -9.2102\n",
      "Epoch 2697/5000\n",
      "23/23 [==============================] - 3s 144ms/step - loss: -9.3682 - val_loss: -9.2161\n",
      "Epoch 2698/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.3626 - val_loss: -9.2143\n",
      "Epoch 2699/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.3325 - val_loss: -9.2186\n",
      "Epoch 2700/5000\n",
      "23/23 [==============================] - 3s 140ms/step - loss: -9.3804 - val_loss: -9.2197\n",
      "Epoch 2701/5000\n",
      "23/23 [==============================] - 3s 156ms/step - loss: -9.3966 - val_loss: -9.1997\n",
      "Epoch 2702/5000\n",
      "23/23 [==============================] - 4s 175ms/step - loss: -9.4223 - val_loss: -9.2097\n",
      "Epoch 2703/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -9.4063 - val_loss: -9.2217\n",
      "Epoch 2704/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.3519 - val_loss: -9.2118\n",
      "Epoch 2705/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.3314 - val_loss: -9.2134\n",
      "Epoch 2706/5000\n",
      "23/23 [==============================] - 3s 132ms/step - loss: -9.3325 - val_loss: -9.2112\n",
      "Epoch 2707/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.4147 - val_loss: -9.2129\n",
      "Epoch 2708/5000\n",
      "23/23 [==============================] - 5s 245ms/step - loss: -9.3741 - val_loss: -9.2073\n",
      "Epoch 2709/5000\n",
      "23/23 [==============================] - 6s 254ms/step - loss: -9.3125 - val_loss: -9.2103\n",
      "Epoch 2710/5000\n",
      "23/23 [==============================] - 6s 256ms/step - loss: -9.3628 - val_loss: -9.1898\n",
      "Epoch 2711/5000\n",
      "23/23 [==============================] - 6s 249ms/step - loss: -9.3679 - val_loss: -9.2101\n",
      "Epoch 2712/5000\n",
      "23/23 [==============================] - 5s 247ms/step - loss: -9.4295 - val_loss: -9.2136\n",
      "Epoch 2713/5000\n",
      "23/23 [==============================] - 3s 158ms/step - loss: -9.3556 - val_loss: -9.2196\n",
      "Epoch 2714/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.4472 - val_loss: -9.2113\n",
      "Epoch 2715/5000\n",
      "23/23 [==============================] - 2s 109ms/step - loss: -9.3602 - val_loss: -9.2096\n",
      "Epoch 2716/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.3796 - val_loss: -9.2057\n",
      "Epoch 2717/5000\n",
      "23/23 [==============================] - 5s 211ms/step - loss: -9.3397 - val_loss: -9.2087\n",
      "Epoch 2718/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.4174 - val_loss: -9.2132\n",
      "Epoch 2719/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.4258 - val_loss: -9.2097\n",
      "Epoch 2720/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.4127 - val_loss: -9.2225\n",
      "Epoch 2721/5000\n",
      "23/23 [==============================] - 6s 257ms/step - loss: -9.3975 - val_loss: -9.2140\n",
      "Epoch 2722/5000\n",
      "23/23 [==============================] - 5s 206ms/step - loss: -9.3699 - val_loss: -9.2086\n",
      "Epoch 2723/5000\n",
      "23/23 [==============================] - 4s 204ms/step - loss: -9.4097 - val_loss: -9.2208\n",
      "Epoch 2724/5000\n",
      "23/23 [==============================] - 4s 181ms/step - loss: -9.3266 - val_loss: -9.2048\n",
      "Epoch 2725/5000\n",
      "23/23 [==============================] - 3s 155ms/step - loss: -9.4032 - val_loss: -9.2129\n",
      "Epoch 2726/5000\n",
      "23/23 [==============================] - 3s 137ms/step - loss: -9.3948 - val_loss: -9.2189\n",
      "Epoch 2727/5000\n",
      "23/23 [==============================] - 3s 131ms/step - loss: -9.4096 - val_loss: -9.2285\n",
      "Epoch 2728/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.4079 - val_loss: -9.2274\n",
      "Epoch 2729/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4154 - val_loss: -9.2169\n",
      "Epoch 2730/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -9.3992 - val_loss: -9.2077\n",
      "Epoch 2731/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4249 - val_loss: -9.2260\n",
      "Epoch 2732/5000\n",
      "23/23 [==============================] - 5s 240ms/step - loss: -9.4008 - val_loss: -9.2112\n",
      "Epoch 2733/5000\n",
      "23/23 [==============================] - 2s 109ms/step - loss: -9.2655 - val_loss: -9.2249\n",
      "Epoch 2734/5000\n",
      "23/23 [==============================] - 5s 248ms/step - loss: -9.4055 - val_loss: -9.2106\n",
      "Epoch 2735/5000\n",
      "23/23 [==============================] - 4s 159ms/step - loss: -9.4213 - val_loss: -9.2157\n",
      "Epoch 2736/5000\n",
      "23/23 [==============================] - 5s 237ms/step - loss: -9.3726 - val_loss: -9.2163\n",
      "Epoch 2737/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.4129 - val_loss: -9.2263\n",
      "Epoch 2738/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.3249 - val_loss: -9.2170\n",
      "Epoch 2739/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.3850 - val_loss: -9.2201\n",
      "Epoch 2740/5000\n",
      "23/23 [==============================] - 3s 131ms/step - loss: -9.4351 - val_loss: -9.2076\n",
      "Epoch 2741/5000\n",
      "23/23 [==============================] - 6s 255ms/step - loss: -9.4120 - val_loss: -9.2155\n",
      "Epoch 2742/5000\n",
      "23/23 [==============================] - 3s 144ms/step - loss: -9.4026 - val_loss: -9.2094\n",
      "Epoch 2743/5000\n",
      "23/23 [==============================] - 3s 139ms/step - loss: -9.3618 - val_loss: -9.2139\n",
      "Epoch 2744/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.3545 - val_loss: -9.2222\n",
      "Epoch 2745/5000\n",
      "23/23 [==============================] - 2s 104ms/step - loss: -9.4119 - val_loss: -9.2146\n",
      "Epoch 2746/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -9.3969 - val_loss: -9.2318\n",
      "Epoch 2747/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.3641 - val_loss: -9.2177\n",
      "Epoch 2748/5000\n",
      "23/23 [==============================] - 5s 232ms/step - loss: -9.4008 - val_loss: -9.2194\n",
      "Epoch 2749/5000\n",
      "23/23 [==============================] - 5s 227ms/step - loss: -9.2809 - val_loss: -9.2129\n",
      "Epoch 2750/5000\n",
      "23/23 [==============================] - 4s 186ms/step - loss: -9.3664 - val_loss: -9.2148\n",
      "Epoch 2751/5000\n",
      "23/23 [==============================] - 3s 116ms/step - loss: -9.3780 - val_loss: -9.2216\n",
      "Epoch 2752/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.3278 - val_loss: -9.2290\n",
      "Epoch 2753/5000\n",
      "23/23 [==============================] - 3s 147ms/step - loss: -9.3882 - val_loss: -9.2166\n",
      "Epoch 2754/5000\n",
      "23/23 [==============================] - 3s 120ms/step - loss: -9.4048 - val_loss: -9.2162\n",
      "Epoch 2755/5000\n",
      "23/23 [==============================] - 5s 240ms/step - loss: -9.4020 - val_loss: -9.2139\n",
      "Epoch 2756/5000\n",
      "23/23 [==============================] - 3s 159ms/step - loss: -9.4127 - val_loss: -9.2235\n",
      "Epoch 2757/5000\n",
      "23/23 [==============================] - 6s 253ms/step - loss: -9.4188 - val_loss: -9.2212\n",
      "Epoch 2758/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.3561 - val_loss: -9.2133\n",
      "Epoch 2759/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.3416 - val_loss: -9.2196\n",
      "Epoch 2760/5000\n",
      "23/23 [==============================] - 4s 177ms/step - loss: -9.4332 - val_loss: -9.2172\n",
      "Epoch 2761/5000\n",
      "23/23 [==============================] - 3s 120ms/step - loss: -9.3979 - val_loss: -9.2236\n",
      "Epoch 2762/5000\n",
      "23/23 [==============================] - 5s 236ms/step - loss: -9.4230 - val_loss: -9.2299\n",
      "Epoch 2763/5000\n",
      "23/23 [==============================] - 6s 251ms/step - loss: -9.3822 - val_loss: -9.2293\n",
      "Epoch 2764/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.4451 - val_loss: -9.2374\n",
      "Epoch 2765/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.3064 - val_loss: -9.2378\n",
      "Epoch 2766/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.4241 - val_loss: -9.2277\n",
      "Epoch 2767/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.4047 - val_loss: -9.2180\n",
      "Epoch 2768/5000\n",
      "23/23 [==============================] - 3s 115ms/step - loss: -9.3541 - val_loss: -9.2272\n",
      "Epoch 2769/5000\n",
      "23/23 [==============================] - 3s 146ms/step - loss: -9.4332 - val_loss: -9.2280\n",
      "Epoch 2770/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.3262 - val_loss: -9.2313\n",
      "Epoch 2771/5000\n",
      "23/23 [==============================] - 5s 220ms/step - loss: -9.4161 - val_loss: -9.2145\n",
      "Epoch 2772/5000\n",
      "23/23 [==============================] - 5s 237ms/step - loss: -8.7072 - val_loss: -9.2193\n",
      "Epoch 2773/5000\n",
      "23/23 [==============================] - 3s 139ms/step - loss: -9.3724 - val_loss: -9.2288\n",
      "Epoch 2774/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4121 - val_loss: -9.2255\n",
      "Epoch 2775/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.4269 - val_loss: -9.2148\n",
      "Epoch 2776/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.3827 - val_loss: -9.2111\n",
      "Epoch 2777/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.3601 - val_loss: -9.2227\n",
      "Epoch 2778/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -9.3758 - val_loss: -9.2163\n",
      "Epoch 2779/5000\n",
      "23/23 [==============================] - 6s 262ms/step - loss: -9.4148 - val_loss: -9.2213\n",
      "Epoch 2780/5000\n",
      "23/23 [==============================] - 5s 224ms/step - loss: -9.4302 - val_loss: -9.2125\n",
      "Epoch 2781/5000\n",
      "23/23 [==============================] - 4s 173ms/step - loss: -9.3917 - val_loss: -9.2304\n",
      "Epoch 2782/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.4041 - val_loss: -9.2073\n",
      "Epoch 2783/5000\n",
      "23/23 [==============================] - 4s 163ms/step - loss: -9.4117 - val_loss: -9.2164\n",
      "Epoch 2784/5000\n",
      "23/23 [==============================] - 4s 167ms/step - loss: -9.3893 - val_loss: -9.2257\n",
      "Epoch 2785/5000\n",
      "23/23 [==============================] - 4s 204ms/step - loss: -9.4293 - val_loss: -9.2215\n",
      "Epoch 2786/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4407 - val_loss: -9.2053\n",
      "Epoch 2787/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.4369 - val_loss: -9.2226\n",
      "Epoch 2788/5000\n",
      "23/23 [==============================] - 6s 253ms/step - loss: -9.4080 - val_loss: -9.2323\n",
      "Epoch 2789/5000\n",
      "23/23 [==============================] - 4s 165ms/step - loss: -9.3919 - val_loss: -9.2191\n",
      "Epoch 2790/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.3602 - val_loss: -9.2195\n",
      "Epoch 2791/5000\n",
      "23/23 [==============================] - 4s 178ms/step - loss: -9.3915 - val_loss: -9.2320\n",
      "Epoch 2792/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.3960 - val_loss: -9.2120\n",
      "Epoch 2793/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.4057 - val_loss: -9.2219\n",
      "Epoch 2794/5000\n",
      "23/23 [==============================] - 4s 182ms/step - loss: -9.3660 - val_loss: -9.2228\n",
      "Epoch 2795/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -9.4195 - val_loss: -9.2193\n",
      "Epoch 2796/5000\n",
      "23/23 [==============================] - 5s 224ms/step - loss: -9.3818 - val_loss: -9.2327\n",
      "Epoch 2797/5000\n",
      "23/23 [==============================] - 5s 247ms/step - loss: -9.3658 - val_loss: -9.2345\n",
      "Epoch 2798/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.4537 - val_loss: -9.2257\n",
      "Epoch 2799/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.4121 - val_loss: -9.2315\n",
      "Epoch 2800/5000\n",
      "23/23 [==============================] - 3s 148ms/step - loss: -9.4272 - val_loss: -9.2268\n",
      "Epoch 2801/5000\n",
      "23/23 [==============================] - 4s 183ms/step - loss: -9.3826 - val_loss: -9.2253\n",
      "Epoch 2802/5000\n",
      "23/23 [==============================] - 3s 148ms/step - loss: -9.4332 - val_loss: -9.2225\n",
      "Epoch 2803/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.4423 - val_loss: -9.2353\n",
      "Epoch 2804/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.4177 - val_loss: -9.2233\n",
      "Epoch 2805/5000\n",
      "23/23 [==============================] - 4s 178ms/step - loss: -9.4321 - val_loss: -9.2289\n",
      "Epoch 2806/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.3708 - val_loss: -9.2105\n",
      "Epoch 2807/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.4316 - val_loss: -9.2231\n",
      "Epoch 2808/5000\n",
      "23/23 [==============================] - 6s 272ms/step - loss: -9.3189 - val_loss: -9.2163\n",
      "Epoch 2809/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.4061 - val_loss: -9.2240\n",
      "Epoch 2810/5000\n",
      "23/23 [==============================] - 3s 156ms/step - loss: -9.3960 - val_loss: -9.2238\n",
      "Epoch 2811/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.4339 - val_loss: -9.2290\n",
      "Epoch 2812/5000\n",
      "23/23 [==============================] - 2s 108ms/step - loss: -9.3874 - val_loss: -9.2273\n",
      "Epoch 2813/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.3908 - val_loss: -9.2317\n",
      "Epoch 2814/5000\n",
      "23/23 [==============================] - 4s 197ms/step - loss: -9.4298 - val_loss: -9.2185\n",
      "Epoch 2815/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.4138 - val_loss: -9.2251\n",
      "Epoch 2816/5000\n",
      "23/23 [==============================] - 5s 239ms/step - loss: -9.3627 - val_loss: -9.2247\n",
      "Epoch 2817/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.4481 - val_loss: -9.2245\n",
      "Epoch 2818/5000\n",
      "23/23 [==============================] - 4s 179ms/step - loss: -9.4342 - val_loss: -9.2264\n",
      "Epoch 2819/5000\n",
      "23/23 [==============================] - 5s 236ms/step - loss: -9.4163 - val_loss: -9.2095\n",
      "Epoch 2820/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.4246 - val_loss: -9.2276\n",
      "Epoch 2821/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.4112 - val_loss: -9.2336\n",
      "Epoch 2822/5000\n",
      "23/23 [==============================] - 3s 131ms/step - loss: -9.4541 - val_loss: -9.2316\n",
      "Epoch 2823/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.4006 - val_loss: -9.2342\n",
      "Epoch 2824/5000\n",
      "23/23 [==============================] - 4s 182ms/step - loss: -9.4097 - val_loss: -9.2302\n",
      "Epoch 2825/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.4152 - val_loss: -9.2220\n",
      "Epoch 2826/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.4669 - val_loss: -9.2319\n",
      "Epoch 2827/5000\n",
      "23/23 [==============================] - 5s 206ms/step - loss: -9.4334 - val_loss: -9.2241\n",
      "Epoch 2828/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.3778 - val_loss: -9.2199\n",
      "Epoch 2829/5000\n",
      "23/23 [==============================] - 5s 222ms/step - loss: -9.3799 - val_loss: -9.2274\n",
      "Epoch 2830/5000\n",
      "23/23 [==============================] - 3s 113ms/step - loss: -9.4116 - val_loss: -9.2236\n",
      "Epoch 2831/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -9.4050 - val_loss: -9.2249\n",
      "Epoch 2832/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.4336 - val_loss: -9.2267\n",
      "Epoch 2833/5000\n",
      "23/23 [==============================] - 4s 159ms/step - loss: -9.4366 - val_loss: -9.2085\n",
      "Epoch 2834/5000\n",
      "23/23 [==============================] - 4s 166ms/step - loss: -9.4497 - val_loss: -9.2125\n",
      "Epoch 2835/5000\n",
      "23/23 [==============================] - 3s 133ms/step - loss: -9.4255 - val_loss: -9.2355\n",
      "Epoch 2836/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.4065 - val_loss: -9.2245\n",
      "Epoch 2837/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.3949 - val_loss: -9.2183\n",
      "Epoch 2838/5000\n",
      "23/23 [==============================] - 3s 137ms/step - loss: -9.4139 - val_loss: -9.2195\n",
      "Epoch 2839/5000\n",
      "23/23 [==============================] - 5s 233ms/step - loss: -9.4064 - val_loss: -9.2372\n",
      "Epoch 2840/5000\n",
      "23/23 [==============================] - 6s 253ms/step - loss: -9.3902 - val_loss: -9.2290\n",
      "Epoch 2841/5000\n",
      "23/23 [==============================] - 2s 108ms/step - loss: -9.4173 - val_loss: -9.2327\n",
      "Epoch 2842/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.3907 - val_loss: -9.2152\n",
      "Epoch 2843/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.3225 - val_loss: -9.2320\n",
      "Epoch 2844/5000\n",
      "23/23 [==============================] - 4s 160ms/step - loss: -9.4213 - val_loss: -9.2380\n",
      "Epoch 2845/5000\n",
      "23/23 [==============================] - 2s 108ms/step - loss: -9.4071 - val_loss: -9.2224\n",
      "Epoch 2846/5000\n",
      "23/23 [==============================] - 5s 247ms/step - loss: -9.4496 - val_loss: -9.2311\n",
      "Epoch 2847/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.4166 - val_loss: -9.2337\n",
      "Epoch 2848/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.4496 - val_loss: -9.2425\n",
      "Epoch 2849/5000\n",
      "23/23 [==============================] - 3s 153ms/step - loss: -9.4484 - val_loss: -9.2412\n",
      "Epoch 2850/5000\n",
      "23/23 [==============================] - 5s 245ms/step - loss: -9.4522 - val_loss: -9.2500\n",
      "Epoch 2851/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.3535 - val_loss: -9.2174\n",
      "Epoch 2852/5000\n",
      "23/23 [==============================] - 4s 169ms/step - loss: -9.4024 - val_loss: -9.2201\n",
      "Epoch 2853/5000\n",
      "23/23 [==============================] - 5s 241ms/step - loss: -9.3876 - val_loss: -9.2338\n",
      "Epoch 2854/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4469 - val_loss: -9.2280\n",
      "Epoch 2855/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.4033 - val_loss: -9.2294\n",
      "Epoch 2856/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -9.4458 - val_loss: -9.2070\n",
      "Epoch 2857/5000\n",
      "23/23 [==============================] - 5s 205ms/step - loss: -9.4162 - val_loss: -9.2369\n",
      "Epoch 2858/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.4036 - val_loss: -9.2269\n",
      "Epoch 2859/5000\n",
      "23/23 [==============================] - 6s 252ms/step - loss: -9.3937 - val_loss: -9.2247\n",
      "Epoch 2860/5000\n",
      "23/23 [==============================] - 4s 190ms/step - loss: -9.4440 - val_loss: -9.2333\n",
      "Epoch 2861/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.3724 - val_loss: -9.2379\n",
      "Epoch 2862/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.3862 - val_loss: -9.2345\n",
      "Epoch 2863/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -9.4330 - val_loss: -9.2297\n",
      "Epoch 2864/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4402 - val_loss: -9.2304\n",
      "Epoch 2865/5000\n",
      "23/23 [==============================] - 5s 207ms/step - loss: -9.3878 - val_loss: -9.2279\n",
      "Epoch 2866/5000\n",
      "23/23 [==============================] - 4s 182ms/step - loss: -9.3807 - val_loss: -9.2363\n",
      "Epoch 2867/5000\n",
      "23/23 [==============================] - 5s 219ms/step - loss: -9.4463 - val_loss: -9.2331\n",
      "Epoch 2868/5000\n",
      "23/23 [==============================] - 3s 146ms/step - loss: -9.4225 - val_loss: -9.2289\n",
      "Epoch 2869/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.4068 - val_loss: -9.2185\n",
      "Epoch 2870/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.3696 - val_loss: -9.2272\n",
      "Epoch 2871/5000\n",
      "23/23 [==============================] - 5s 211ms/step - loss: -9.3959 - val_loss: -9.2330\n",
      "Epoch 2872/5000\n",
      "23/23 [==============================] - 5s 210ms/step - loss: -9.4325 - val_loss: -9.2231\n",
      "Epoch 2873/5000\n",
      "23/23 [==============================] - 3s 134ms/step - loss: -9.4142 - val_loss: -9.2241\n",
      "Epoch 2874/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.4496 - val_loss: -9.2295\n",
      "Epoch 2875/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.4441 - val_loss: -9.2483\n",
      "Epoch 2876/5000\n",
      "23/23 [==============================] - 3s 155ms/step - loss: -9.4361 - val_loss: -9.2278\n",
      "Epoch 2877/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.4464 - val_loss: -9.2202\n",
      "Epoch 2878/5000\n",
      "23/23 [==============================] - 3s 113ms/step - loss: -9.3634 - val_loss: -9.2396\n",
      "Epoch 2879/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.3591 - val_loss: -9.2482\n",
      "Epoch 2880/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.4389 - val_loss: -9.2370\n",
      "Epoch 2881/5000\n",
      "23/23 [==============================] - 5s 241ms/step - loss: -9.4344 - val_loss: -9.2387\n",
      "Epoch 2882/5000\n",
      "23/23 [==============================] - 5s 232ms/step - loss: -9.4081 - val_loss: -9.2192\n",
      "Epoch 2883/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4370 - val_loss: -9.2240\n",
      "Epoch 2884/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4028 - val_loss: -9.2292\n",
      "Epoch 2885/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.4287 - val_loss: -9.2362\n",
      "Epoch 2886/5000\n",
      "23/23 [==============================] - 3s 144ms/step - loss: -9.4596 - val_loss: -9.2262\n",
      "Epoch 2887/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.4062 - val_loss: -9.2301\n",
      "Epoch 2888/5000\n",
      "23/23 [==============================] - 6s 258ms/step - loss: -9.4136 - val_loss: -9.2324\n",
      "Epoch 2889/5000\n",
      "23/23 [==============================] - 3s 155ms/step - loss: -9.3812 - val_loss: -9.2353\n",
      "Epoch 2890/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.4362 - val_loss: -9.2347\n",
      "Epoch 2891/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.4155 - val_loss: -9.2291\n",
      "Epoch 2892/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.4067 - val_loss: -9.2472\n",
      "Epoch 2893/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.3874 - val_loss: -9.2390\n",
      "Epoch 2894/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.4385 - val_loss: -9.2448\n",
      "Epoch 2895/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.4207 - val_loss: -9.2390\n",
      "Epoch 2896/5000\n",
      "23/23 [==============================] - 3s 114ms/step - loss: -9.4435 - val_loss: -9.2302\n",
      "Epoch 2897/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.4095 - val_loss: -9.2351\n",
      "Epoch 2898/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.3757 - val_loss: -9.2477\n",
      "Epoch 2899/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.4247 - val_loss: -9.2338\n",
      "Epoch 2900/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.4364 - val_loss: -9.2298\n",
      "Epoch 2901/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.4253 - val_loss: -9.2427\n",
      "Epoch 2902/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4512 - val_loss: -9.2487\n",
      "Epoch 2903/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.4502 - val_loss: -9.2318\n",
      "Epoch 2904/5000\n",
      "23/23 [==============================] - 3s 120ms/step - loss: -9.4399 - val_loss: -9.2290\n",
      "Epoch 2905/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.4317 - val_loss: -9.2474\n",
      "Epoch 2906/5000\n",
      "23/23 [==============================] - 5s 228ms/step - loss: -9.4768 - val_loss: -9.2319\n",
      "Epoch 2907/5000\n",
      "23/23 [==============================] - 3s 131ms/step - loss: -9.4065 - val_loss: -9.2447\n",
      "Epoch 2908/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.3989 - val_loss: -9.2263\n",
      "Epoch 2909/5000\n",
      "23/23 [==============================] - 4s 186ms/step - loss: -9.4130 - val_loss: -9.2401\n",
      "Epoch 2910/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.4360 - val_loss: -9.2446\n",
      "Epoch 2911/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.4089 - val_loss: -9.2381\n",
      "Epoch 2912/5000\n",
      "23/23 [==============================] - 5s 245ms/step - loss: -9.4033 - val_loss: -9.2467\n",
      "Epoch 2913/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.3661 - val_loss: -9.2418\n",
      "Epoch 2914/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -9.4450 - val_loss: -9.2356\n",
      "Epoch 2915/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.4051 - val_loss: -9.2499\n",
      "Epoch 2916/5000\n",
      "23/23 [==============================] - 3s 154ms/step - loss: -9.4617 - val_loss: -9.2437\n",
      "Epoch 2917/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -9.4423 - val_loss: -9.2393\n",
      "Epoch 2918/5000\n",
      "23/23 [==============================] - 3s 157ms/step - loss: -9.4172 - val_loss: -9.2316\n",
      "Epoch 2919/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -9.4707 - val_loss: -9.2276\n",
      "Epoch 2920/5000\n",
      "23/23 [==============================] - 3s 139ms/step - loss: -9.3583 - val_loss: -9.2447\n",
      "Epoch 2921/5000\n",
      "23/23 [==============================] - 5s 225ms/step - loss: -9.4103 - val_loss: -9.2375\n",
      "Epoch 2922/5000\n",
      "23/23 [==============================] - 5s 240ms/step - loss: -9.4472 - val_loss: -9.2407\n",
      "Epoch 2923/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.3996 - val_loss: -9.2407\n",
      "Epoch 2924/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.4233 - val_loss: -9.2355\n",
      "Epoch 2925/5000\n",
      "23/23 [==============================] - 4s 191ms/step - loss: -9.3770 - val_loss: -9.2372\n",
      "Epoch 2926/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.3330 - val_loss: -9.2442\n",
      "Epoch 2927/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.4477 - val_loss: -9.2378\n",
      "Epoch 2928/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.4450 - val_loss: -9.2412\n",
      "Epoch 2929/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.4482 - val_loss: -9.2480\n",
      "Epoch 2930/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -9.3890 - val_loss: -9.2360\n",
      "Epoch 2931/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -9.3794 - val_loss: -9.2396\n",
      "Epoch 2932/5000\n",
      "23/23 [==============================] - 5s 240ms/step - loss: -9.4496 - val_loss: -9.2350\n",
      "Epoch 2933/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4417 - val_loss: -9.2493\n",
      "Epoch 2934/5000\n",
      "23/23 [==============================] - 4s 184ms/step - loss: -9.4287 - val_loss: -9.2260\n",
      "Epoch 2935/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4457 - val_loss: -9.2475\n",
      "Epoch 2936/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.4202 - val_loss: -9.2365\n",
      "Epoch 2937/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.4172 - val_loss: -9.2351\n",
      "Epoch 2938/5000\n",
      "23/23 [==============================] - 4s 170ms/step - loss: -9.4689 - val_loss: -9.2303\n",
      "Epoch 2939/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -9.3424 - val_loss: -9.2465\n",
      "Epoch 2940/5000\n",
      "23/23 [==============================] - 5s 249ms/step - loss: -9.4241 - val_loss: -9.2443\n",
      "Epoch 2941/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.4328 - val_loss: -9.2462\n",
      "Epoch 2942/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.4209 - val_loss: -9.2414\n",
      "Epoch 2943/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.4068 - val_loss: -9.2477\n",
      "Epoch 2944/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.4306 - val_loss: -9.2386\n",
      "Epoch 2945/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.4273 - val_loss: -9.2393\n",
      "Epoch 2946/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.4118 - val_loss: -9.2455\n",
      "Epoch 2947/5000\n",
      "23/23 [==============================] - 4s 167ms/step - loss: -9.4253 - val_loss: -9.2466\n",
      "Epoch 2948/5000\n",
      "23/23 [==============================] - 4s 163ms/step - loss: -9.4682 - val_loss: -9.2433\n",
      "Epoch 2949/5000\n",
      "23/23 [==============================] - 6s 266ms/step - loss: -9.3860 - val_loss: -9.2388\n",
      "Epoch 2950/5000\n",
      "23/23 [==============================] - 3s 117ms/step - loss: -9.4570 - val_loss: -9.2558\n",
      "Epoch 2951/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.4599 - val_loss: -9.2372\n",
      "Epoch 2952/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -9.4721 - val_loss: -9.2541\n",
      "Epoch 2953/5000\n",
      "23/23 [==============================] - 3s 141ms/step - loss: -9.4443 - val_loss: -9.2425\n",
      "Epoch 2954/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.4380 - val_loss: -9.2464\n",
      "Epoch 2955/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.4239 - val_loss: -9.2396\n",
      "Epoch 2956/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.3889 - val_loss: -9.2473\n",
      "Epoch 2957/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -9.4259 - val_loss: -9.2544\n",
      "Epoch 2958/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.3551 - val_loss: -9.2477\n",
      "Epoch 2959/5000\n",
      "23/23 [==============================] - 5s 240ms/step - loss: -9.4059 - val_loss: -9.2507\n",
      "Epoch 2960/5000\n",
      "23/23 [==============================] - 5s 240ms/step - loss: -9.4066 - val_loss: -9.2558\n",
      "Epoch 2961/5000\n",
      "23/23 [==============================] - 4s 194ms/step - loss: -9.4523 - val_loss: -9.2388\n",
      "Epoch 2962/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4573 - val_loss: -9.2431\n",
      "Epoch 2963/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.4644 - val_loss: -9.2427\n",
      "Epoch 2964/5000\n",
      "23/23 [==============================] - 6s 256ms/step - loss: -9.4430 - val_loss: -9.2505\n",
      "Epoch 2965/5000\n",
      "23/23 [==============================] - 6s 267ms/step - loss: -9.4190 - val_loss: -9.2571\n",
      "Epoch 2966/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.4457 - val_loss: -9.2328\n",
      "Epoch 2967/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.4175 - val_loss: -9.2454\n",
      "Epoch 2968/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4018 - val_loss: -9.2489\n",
      "Epoch 2969/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.4684 - val_loss: -9.2427\n",
      "Epoch 2970/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.4359 - val_loss: -9.2369\n",
      "Epoch 2971/5000\n",
      "23/23 [==============================] - 3s 138ms/step - loss: -9.3907 - val_loss: -9.2461\n",
      "Epoch 2972/5000\n",
      "23/23 [==============================] - 6s 260ms/step - loss: -9.4323 - val_loss: -9.2440\n",
      "Epoch 2973/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.4331 - val_loss: -9.2431\n",
      "Epoch 2974/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.4573 - val_loss: -9.2328\n",
      "Epoch 2975/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.3415 - val_loss: -9.2516\n",
      "Epoch 2976/5000\n",
      "23/23 [==============================] - 4s 203ms/step - loss: -9.4158 - val_loss: -9.2490\n",
      "Epoch 2977/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.4391 - val_loss: -9.2419\n",
      "Epoch 2978/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.4496 - val_loss: -9.2490\n",
      "Epoch 2979/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.4598 - val_loss: -9.2465\n",
      "Epoch 2980/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.4259 - val_loss: -9.2264\n",
      "Epoch 2981/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.3911 - val_loss: -9.2286\n",
      "Epoch 2982/5000\n",
      "23/23 [==============================] - 5s 237ms/step - loss: -9.4375 - val_loss: -9.2464\n",
      "Epoch 2983/5000\n",
      "23/23 [==============================] - 5s 246ms/step - loss: -9.3997 - val_loss: -9.2476\n",
      "Epoch 2984/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.4285 - val_loss: -9.2536\n",
      "Epoch 2985/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.4170 - val_loss: -9.2381\n",
      "Epoch 2986/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.4344 - val_loss: -9.2488\n",
      "Epoch 2987/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.4302 - val_loss: -9.2536\n",
      "Epoch 2988/5000\n",
      "23/23 [==============================] - 3s 118ms/step - loss: -9.3713 - val_loss: -9.2499\n",
      "Epoch 2989/5000\n",
      "23/23 [==============================] - 4s 165ms/step - loss: -9.4340 - val_loss: -9.2389\n",
      "Epoch 2990/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.3962 - val_loss: -9.2477\n",
      "Epoch 2991/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.4587 - val_loss: -9.2580\n",
      "Epoch 2992/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.3844 - val_loss: -9.2465\n",
      "Epoch 2993/5000\n",
      "23/23 [==============================] - 3s 137ms/step - loss: -9.4687 - val_loss: -9.2631\n",
      "Epoch 2994/5000\n",
      "23/23 [==============================] - 3s 121ms/step - loss: -9.4497 - val_loss: -9.2440\n",
      "Epoch 2995/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4326 - val_loss: -9.2472\n",
      "Epoch 2996/5000\n",
      "23/23 [==============================] - 2s 113ms/step - loss: -9.4167 - val_loss: -9.2447\n",
      "Epoch 2997/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.4952 - val_loss: -9.2587\n",
      "Epoch 2998/5000\n",
      "23/23 [==============================] - 5s 231ms/step - loss: -9.4604 - val_loss: -9.2620\n",
      "Epoch 2999/5000\n",
      "23/23 [==============================] - 4s 197ms/step - loss: -9.4322 - val_loss: -9.2586\n",
      "Epoch 3000/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.4364 - val_loss: -9.2542\n",
      "Epoch 3001/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.3767 - val_loss: -9.2593\n",
      "Epoch 3002/5000\n",
      "23/23 [==============================] - 6s 259ms/step - loss: -9.4399 - val_loss: -9.2467\n",
      "Epoch 3003/5000\n",
      "23/23 [==============================] - 6s 253ms/step - loss: -9.4620 - val_loss: -9.2574\n",
      "Epoch 3004/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.4470 - val_loss: -9.2662\n",
      "Epoch 3005/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.4271 - val_loss: -9.2572\n",
      "Epoch 3006/5000\n",
      "23/23 [==============================] - 5s 212ms/step - loss: -9.4011 - val_loss: -9.2616\n",
      "Epoch 3007/5000\n",
      "23/23 [==============================] - 4s 170ms/step - loss: -9.4541 - val_loss: -9.2530\n",
      "Epoch 3008/5000\n",
      "23/23 [==============================] - 4s 203ms/step - loss: -9.4264 - val_loss: -9.2581\n",
      "Epoch 3009/5000\n",
      "23/23 [==============================] - 5s 221ms/step - loss: -9.4009 - val_loss: -9.2514\n",
      "Epoch 3010/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -9.4109 - val_loss: -9.2598\n",
      "Epoch 3011/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.3837 - val_loss: -9.2603\n",
      "Epoch 3012/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.4221 - val_loss: -9.2424\n",
      "Epoch 3013/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.4173 - val_loss: -9.2454\n",
      "Epoch 3014/5000\n",
      "23/23 [==============================] - 4s 172ms/step - loss: -9.4411 - val_loss: -9.2548\n",
      "Epoch 3015/5000\n",
      "23/23 [==============================] - 5s 246ms/step - loss: -9.4467 - val_loss: -9.2427\n",
      "Epoch 3016/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4809 - val_loss: -9.2553\n",
      "Epoch 3017/5000\n",
      "23/23 [==============================] - 4s 159ms/step - loss: -9.4589 - val_loss: -9.2664\n",
      "Epoch 3018/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.4736 - val_loss: -9.2560\n",
      "Epoch 3019/5000\n",
      "23/23 [==============================] - 3s 131ms/step - loss: -9.4197 - val_loss: -9.2575\n",
      "Epoch 3020/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.4367 - val_loss: -9.2559\n",
      "Epoch 3021/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.4298 - val_loss: -9.2543\n",
      "Epoch 3022/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.4438 - val_loss: -9.2572\n",
      "Epoch 3023/5000\n",
      "23/23 [==============================] - 3s 118ms/step - loss: -9.4428 - val_loss: -9.2557\n",
      "Epoch 3024/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.4094 - val_loss: -9.2517\n",
      "Epoch 3025/5000\n",
      "23/23 [==============================] - 5s 237ms/step - loss: -9.4602 - val_loss: -9.2690\n",
      "Epoch 3026/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.4801 - val_loss: -9.2535\n",
      "Epoch 3027/5000\n",
      "23/23 [==============================] - 4s 191ms/step - loss: -9.4313 - val_loss: -9.2625\n",
      "Epoch 3028/5000\n",
      "23/23 [==============================] - 5s 211ms/step - loss: -9.4168 - val_loss: -9.2445\n",
      "Epoch 3029/5000\n",
      "23/23 [==============================] - 5s 237ms/step - loss: -9.3865 - val_loss: -9.2573\n",
      "Epoch 3030/5000\n",
      "23/23 [==============================] - 5s 249ms/step - loss: -9.4152 - val_loss: -9.2634\n",
      "Epoch 3031/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.4394 - val_loss: -9.2570\n",
      "Epoch 3032/5000\n",
      "23/23 [==============================] - 5s 238ms/step - loss: -9.4159 - val_loss: -9.2528\n",
      "Epoch 3033/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -9.4615 - val_loss: -9.2495\n",
      "Epoch 3034/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -9.4670 - val_loss: -9.2668\n",
      "Epoch 3035/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.3604 - val_loss: -9.2597\n",
      "Epoch 3036/5000\n",
      "23/23 [==============================] - 5s 211ms/step - loss: -9.4161 - val_loss: -9.2571\n",
      "Epoch 3037/5000\n",
      "23/23 [==============================] - 4s 164ms/step - loss: -9.4148 - val_loss: -9.2705\n",
      "Epoch 3038/5000\n",
      "23/23 [==============================] - 5s 205ms/step - loss: -9.4344 - val_loss: -9.2605\n",
      "Epoch 3039/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.4034 - val_loss: -9.2639\n",
      "Epoch 3040/5000\n",
      "23/23 [==============================] - 4s 174ms/step - loss: -9.4436 - val_loss: -9.2531\n",
      "Epoch 3041/5000\n",
      "23/23 [==============================] - 5s 218ms/step - loss: -9.4730 - val_loss: -9.2550\n",
      "Epoch 3042/5000\n",
      "23/23 [==============================] - 4s 176ms/step - loss: -9.4148 - val_loss: -9.2632\n",
      "Epoch 3043/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.4517 - val_loss: -9.2578\n",
      "Epoch 3044/5000\n",
      "23/23 [==============================] - 3s 118ms/step - loss: -9.4282 - val_loss: -9.2608\n",
      "Epoch 3045/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.4758 - val_loss: -9.2612\n",
      "Epoch 3046/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.4976 - val_loss: -9.2509\n",
      "Epoch 3047/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.4663 - val_loss: -9.2603\n",
      "Epoch 3048/5000\n",
      "23/23 [==============================] - 3s 158ms/step - loss: -9.4186 - val_loss: -9.2652\n",
      "Epoch 3049/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.4849 - val_loss: -9.2710\n",
      "Epoch 3050/5000\n",
      "23/23 [==============================] - 4s 160ms/step - loss: -9.4484 - val_loss: -9.2521\n",
      "Epoch 3051/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.4729 - val_loss: -9.2559\n",
      "Epoch 3052/5000\n",
      "23/23 [==============================] - 5s 222ms/step - loss: -9.4404 - val_loss: -9.2576\n",
      "Epoch 3053/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.4617 - val_loss: -9.2628\n",
      "Epoch 3054/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.4586 - val_loss: -9.2679\n",
      "Epoch 3055/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.4605 - val_loss: -9.2625\n",
      "Epoch 3056/5000\n",
      "23/23 [==============================] - 6s 267ms/step - loss: -9.4445 - val_loss: -9.2649\n",
      "Epoch 3057/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.4918 - val_loss: -9.2610\n",
      "Epoch 3058/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.4562 - val_loss: -9.2565\n",
      "Epoch 3059/5000\n",
      "23/23 [==============================] - 4s 179ms/step - loss: -9.3711 - val_loss: -9.2598\n",
      "Epoch 3060/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.4175 - val_loss: -9.2587\n",
      "Epoch 3061/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.4293 - val_loss: -9.2673\n",
      "Epoch 3062/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.4211 - val_loss: -9.2672\n",
      "Epoch 3063/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.4682 - val_loss: -9.2635\n",
      "Epoch 3064/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.4306 - val_loss: -9.2630\n",
      "Epoch 3065/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.4581 - val_loss: -9.2628\n",
      "Epoch 3066/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.4567 - val_loss: -9.2601\n",
      "Epoch 3067/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.4686 - val_loss: -9.2688\n",
      "Epoch 3068/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.4395 - val_loss: -9.2579\n",
      "Epoch 3069/5000\n",
      "23/23 [==============================] - 5s 246ms/step - loss: -9.4386 - val_loss: -9.2720\n",
      "Epoch 3070/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.4901 - val_loss: -9.2679\n",
      "Epoch 3071/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.2486 - val_loss: -9.2685\n",
      "Epoch 3072/5000\n",
      "23/23 [==============================] - 2s 112ms/step - loss: -9.4541 - val_loss: -9.2597\n",
      "Epoch 3073/5000\n",
      "23/23 [==============================] - 4s 181ms/step - loss: -9.4257 - val_loss: -9.2637\n",
      "Epoch 3074/5000\n",
      "23/23 [==============================] - 6s 256ms/step - loss: -9.4274 - val_loss: -9.2648\n",
      "Epoch 3075/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -9.4383 - val_loss: -9.2555\n",
      "Epoch 3076/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.4393 - val_loss: -9.2672\n",
      "Epoch 3077/5000\n",
      "23/23 [==============================] - 5s 249ms/step - loss: -9.4417 - val_loss: -9.2729\n",
      "Epoch 3078/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4323 - val_loss: -9.2628\n",
      "Epoch 3079/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.4809 - val_loss: -9.2648\n",
      "Epoch 3080/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.4231 - val_loss: -9.2722\n",
      "Epoch 3081/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.4305 - val_loss: -9.2621\n",
      "Epoch 3082/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.4686 - val_loss: -9.2672\n",
      "Epoch 3083/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.4368 - val_loss: -9.2628\n",
      "Epoch 3084/5000\n",
      "23/23 [==============================] - 4s 178ms/step - loss: -9.4504 - val_loss: -9.2595\n",
      "Epoch 3085/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.4531 - val_loss: -9.2604\n",
      "Epoch 3086/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.4511 - val_loss: -9.2603\n",
      "Epoch 3087/5000\n",
      "23/23 [==============================] - 5s 220ms/step - loss: -9.4600 - val_loss: -9.2739\n",
      "Epoch 3088/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.4093 - val_loss: -9.2726\n",
      "Epoch 3089/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.4199 - val_loss: -9.2644\n",
      "Epoch 3090/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.4634 - val_loss: -9.2712\n",
      "Epoch 3091/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.4507 - val_loss: -9.2666\n",
      "Epoch 3092/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.4691 - val_loss: -9.2707\n",
      "Epoch 3093/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.4559 - val_loss: -9.2591\n",
      "Epoch 3094/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4381 - val_loss: -9.2592\n",
      "Epoch 3095/5000\n",
      "23/23 [==============================] - 5s 223ms/step - loss: -9.4845 - val_loss: -9.2679\n",
      "Epoch 3096/5000\n",
      "23/23 [==============================] - 3s 147ms/step - loss: -9.3941 - val_loss: -9.2615\n",
      "Epoch 3097/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -9.4702 - val_loss: -9.2620\n",
      "Epoch 3098/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.4788 - val_loss: -9.2639\n",
      "Epoch 3099/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.4815 - val_loss: -9.2482\n",
      "Epoch 3100/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.4794 - val_loss: -9.2702\n",
      "Epoch 3101/5000\n",
      "23/23 [==============================] - 5s 240ms/step - loss: -9.4153 - val_loss: -9.2694\n",
      "Epoch 3102/5000\n",
      "23/23 [==============================] - 5s 235ms/step - loss: -9.4698 - val_loss: -9.2690\n",
      "Epoch 3103/5000\n",
      "23/23 [==============================] - 5s 248ms/step - loss: -9.4699 - val_loss: -9.2688\n",
      "Epoch 3104/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.4529 - val_loss: -9.2631\n",
      "Epoch 3105/5000\n",
      "23/23 [==============================] - 5s 241ms/step - loss: -9.4074 - val_loss: -9.2712\n",
      "Epoch 3106/5000\n",
      "23/23 [==============================] - 6s 263ms/step - loss: -9.4619 - val_loss: -9.2719\n",
      "Epoch 3107/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -9.4629 - val_loss: -9.2617\n",
      "Epoch 3108/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.4994 - val_loss: -9.2647\n",
      "Epoch 3109/5000\n",
      "23/23 [==============================] - 6s 279ms/step - loss: -9.4773 - val_loss: -9.2734\n",
      "Epoch 3110/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.4802 - val_loss: -9.2684\n",
      "Epoch 3111/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.4572 - val_loss: -9.2793\n",
      "Epoch 3112/5000\n",
      "23/23 [==============================] - 3s 157ms/step - loss: -9.4326 - val_loss: -9.2768\n",
      "Epoch 3113/5000\n",
      "23/23 [==============================] - 5s 246ms/step - loss: -9.4723 - val_loss: -9.2658\n",
      "Epoch 3114/5000\n",
      "23/23 [==============================] - 4s 194ms/step - loss: -9.4539 - val_loss: -9.2717\n",
      "Epoch 3115/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.4228 - val_loss: -9.2612\n",
      "Epoch 3116/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.4082 - val_loss: -9.2683\n",
      "Epoch 3117/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.4263 - val_loss: -9.2561\n",
      "Epoch 3118/5000\n",
      "23/23 [==============================] - 4s 170ms/step - loss: -9.4584 - val_loss: -9.2554\n",
      "Epoch 3119/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.4764 - val_loss: -9.2700\n",
      "Epoch 3120/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.3991 - val_loss: -9.2678\n",
      "Epoch 3121/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.4931 - val_loss: -9.2733\n",
      "Epoch 3122/5000\n",
      "23/23 [==============================] - 4s 166ms/step - loss: -9.4283 - val_loss: -9.2588\n",
      "Epoch 3123/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.4515 - val_loss: -9.2743\n",
      "Epoch 3124/5000\n",
      "23/23 [==============================] - 4s 188ms/step - loss: -9.4584 - val_loss: -9.2624\n",
      "Epoch 3125/5000\n",
      "23/23 [==============================] - 5s 211ms/step - loss: -9.4678 - val_loss: -9.2734\n",
      "Epoch 3126/5000\n",
      "23/23 [==============================] - 3s 149ms/step - loss: -9.4733 - val_loss: -9.2622\n",
      "Epoch 3127/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.4933 - val_loss: -9.2747\n",
      "Epoch 3128/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.4073 - val_loss: -9.2787\n",
      "Epoch 3129/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.4562 - val_loss: -9.2666\n",
      "Epoch 3130/5000\n",
      "23/23 [==============================] - 5s 239ms/step - loss: -9.4595 - val_loss: -9.2839\n",
      "Epoch 3131/5000\n",
      "23/23 [==============================] - 5s 245ms/step - loss: -9.4604 - val_loss: -9.2781\n",
      "Epoch 3132/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.4639 - val_loss: -9.2752\n",
      "Epoch 3133/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -9.4381 - val_loss: -9.2760\n",
      "Epoch 3134/5000\n",
      "23/23 [==============================] - 3s 156ms/step - loss: -9.5007 - val_loss: -9.2656\n",
      "Epoch 3135/5000\n",
      "23/23 [==============================] - 3s 152ms/step - loss: -9.4762 - val_loss: -9.2681\n",
      "Epoch 3136/5000\n",
      "23/23 [==============================] - 5s 232ms/step - loss: -9.4244 - val_loss: -9.2665\n",
      "Epoch 3137/5000\n",
      "23/23 [==============================] - 5s 245ms/step - loss: -9.4550 - val_loss: -9.2765\n",
      "Epoch 3138/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.4789 - val_loss: -9.2820\n",
      "Epoch 3139/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -9.4814 - val_loss: -9.2898\n",
      "Epoch 3140/5000\n",
      "23/23 [==============================] - 3s 153ms/step - loss: -9.3805 - val_loss: -9.2750\n",
      "Epoch 3141/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.4982 - val_loss: -9.2705\n",
      "Epoch 3142/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.4736 - val_loss: -9.2668\n",
      "Epoch 3143/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.4195 - val_loss: -9.2718\n",
      "Epoch 3144/5000\n",
      "23/23 [==============================] - 4s 181ms/step - loss: -9.4273 - val_loss: -9.2779\n",
      "Epoch 3145/5000\n",
      "23/23 [==============================] - 6s 250ms/step - loss: -9.4727 - val_loss: -9.2748\n",
      "Epoch 3146/5000\n",
      "23/23 [==============================] - 5s 248ms/step - loss: -9.4849 - val_loss: -9.2737\n",
      "Epoch 3147/5000\n",
      "23/23 [==============================] - 2s 108ms/step - loss: -9.4414 - val_loss: -9.2769\n",
      "Epoch 3148/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.4105 - val_loss: -9.2771\n",
      "Epoch 3149/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4419 - val_loss: -9.2691\n",
      "Epoch 3150/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.4802 - val_loss: -9.2781\n",
      "Epoch 3151/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.4432 - val_loss: -9.2745\n",
      "Epoch 3152/5000\n",
      "23/23 [==============================] - 3s 133ms/step - loss: -9.4689 - val_loss: -9.2607\n",
      "Epoch 3153/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.4500 - val_loss: -9.2664\n",
      "Epoch 3154/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -9.4398 - val_loss: -9.2745\n",
      "Epoch 3155/5000\n",
      "23/23 [==============================] - 3s 137ms/step - loss: -9.4804 - val_loss: -9.2747\n",
      "Epoch 3156/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -9.4679 - val_loss: -9.2816\n",
      "Epoch 3157/5000\n",
      "23/23 [==============================] - 4s 184ms/step - loss: -9.4636 - val_loss: -9.2848\n",
      "Epoch 3158/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.4477 - val_loss: -9.2664\n",
      "Epoch 3159/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.4437 - val_loss: -9.2707\n",
      "Epoch 3160/5000\n",
      "23/23 [==============================] - 5s 237ms/step - loss: -9.4451 - val_loss: -9.2719\n",
      "Epoch 3161/5000\n",
      "23/23 [==============================] - 6s 269ms/step - loss: -9.4670 - val_loss: -9.2756\n",
      "Epoch 3162/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.4359 - val_loss: -9.2785\n",
      "Epoch 3163/5000\n",
      "23/23 [==============================] - 4s 161ms/step - loss: -9.4694 - val_loss: -9.2834\n",
      "Epoch 3164/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.4657 - val_loss: -9.2862\n",
      "Epoch 3165/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5155 - val_loss: -9.2773\n",
      "Epoch 3166/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -9.4433 - val_loss: -9.2597\n",
      "Epoch 3167/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.4314 - val_loss: -9.2831\n",
      "Epoch 3168/5000\n",
      "23/23 [==============================] - 5s 241ms/step - loss: -9.4626 - val_loss: -9.2752\n",
      "Epoch 3169/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -9.5129 - val_loss: -9.2911\n",
      "Epoch 3170/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4478 - val_loss: -9.2764\n",
      "Epoch 3171/5000\n",
      "23/23 [==============================] - 4s 174ms/step - loss: -9.3780 - val_loss: -9.2627\n",
      "Epoch 3172/5000\n",
      "23/23 [==============================] - 5s 247ms/step - loss: -9.4583 - val_loss: -9.2814\n",
      "Epoch 3173/5000\n",
      "23/23 [==============================] - 6s 254ms/step - loss: -9.4537 - val_loss: -9.2673\n",
      "Epoch 3174/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.4274 - val_loss: -9.2828\n",
      "Epoch 3175/5000\n",
      "23/23 [==============================] - 3s 153ms/step - loss: -9.4594 - val_loss: -9.2883\n",
      "Epoch 3176/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.4718 - val_loss: -9.2819\n",
      "Epoch 3177/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -9.4678 - val_loss: -9.2773\n",
      "Epoch 3178/5000\n",
      "23/23 [==============================] - 5s 215ms/step - loss: -9.4851 - val_loss: -9.2859\n",
      "Epoch 3179/5000\n",
      "23/23 [==============================] - 5s 240ms/step - loss: -9.4893 - val_loss: -9.2838\n",
      "Epoch 3180/5000\n",
      "23/23 [==============================] - 3s 137ms/step - loss: -9.4598 - val_loss: -9.2794\n",
      "Epoch 3181/5000\n",
      "23/23 [==============================] - 5s 236ms/step - loss: -9.3984 - val_loss: -9.2815\n",
      "Epoch 3182/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.4734 - val_loss: -9.2669\n",
      "Epoch 3183/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -9.4839 - val_loss: -9.2758\n",
      "Epoch 3184/5000\n",
      "23/23 [==============================] - 3s 135ms/step - loss: -9.4350 - val_loss: -9.2859\n",
      "Epoch 3185/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -9.4383 - val_loss: -9.2721\n",
      "Epoch 3186/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.4675 - val_loss: -9.2830\n",
      "Epoch 3187/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.5103 - val_loss: -9.2851\n",
      "Epoch 3188/5000\n",
      "23/23 [==============================] - 4s 186ms/step - loss: -9.4765 - val_loss: -9.2730\n",
      "Epoch 3189/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5019 - val_loss: -9.2708\n",
      "Epoch 3190/5000\n",
      "23/23 [==============================] - 5s 247ms/step - loss: -9.4620 - val_loss: -9.2911\n",
      "Epoch 3191/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.4903 - val_loss: -9.2879\n",
      "Epoch 3192/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.4831 - val_loss: -9.2848\n",
      "Epoch 3193/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.4781 - val_loss: -9.2787\n",
      "Epoch 3194/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -9.4111 - val_loss: -9.2821\n",
      "Epoch 3195/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.4549 - val_loss: -9.2863\n",
      "Epoch 3196/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.4529 - val_loss: -9.2796\n",
      "Epoch 3197/5000\n",
      "23/23 [==============================] - 2s 112ms/step - loss: -9.4813 - val_loss: -9.2870\n",
      "Epoch 3198/5000\n",
      "23/23 [==============================] - 6s 255ms/step - loss: -9.4874 - val_loss: -9.2837\n",
      "Epoch 3199/5000\n",
      "23/23 [==============================] - 6s 254ms/step - loss: -9.4731 - val_loss: -9.2717\n",
      "Epoch 3200/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.3820 - val_loss: -9.2774\n",
      "Epoch 3201/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4399 - val_loss: -9.2879\n",
      "Epoch 3202/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.4279 - val_loss: -9.2777\n",
      "Epoch 3203/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5041 - val_loss: -9.2774\n",
      "Epoch 3204/5000\n",
      "23/23 [==============================] - 3s 147ms/step - loss: -9.3945 - val_loss: -9.2838\n",
      "Epoch 3205/5000\n",
      "23/23 [==============================] - 6s 258ms/step - loss: -9.4507 - val_loss: -9.2839\n",
      "Epoch 3206/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.4820 - val_loss: -9.2829\n",
      "Epoch 3207/5000\n",
      "23/23 [==============================] - 6s 261ms/step - loss: -9.4802 - val_loss: -9.2858\n",
      "Epoch 3208/5000\n",
      "23/23 [==============================] - 6s 255ms/step - loss: -9.4004 - val_loss: -9.2786\n",
      "Epoch 3209/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.4903 - val_loss: -9.2827\n",
      "Epoch 3210/5000\n",
      "23/23 [==============================] - 4s 174ms/step - loss: -9.4604 - val_loss: -9.2718\n",
      "Epoch 3211/5000\n",
      "23/23 [==============================] - 6s 251ms/step - loss: -9.4845 - val_loss: -9.2748\n",
      "Epoch 3212/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.4401 - val_loss: -9.2858\n",
      "Epoch 3213/5000\n",
      "23/23 [==============================] - 4s 179ms/step - loss: -9.5139 - val_loss: -9.2782\n",
      "Epoch 3214/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -9.4658 - val_loss: -9.2761\n",
      "Epoch 3215/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.4657 - val_loss: -9.2894\n",
      "Epoch 3216/5000\n",
      "23/23 [==============================] - 6s 257ms/step - loss: -9.4805 - val_loss: -9.2827\n",
      "Epoch 3217/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.4569 - val_loss: -9.2752\n",
      "Epoch 3218/5000\n",
      "23/23 [==============================] - 5s 219ms/step - loss: -9.4840 - val_loss: -9.2913\n",
      "Epoch 3219/5000\n",
      "23/23 [==============================] - 5s 207ms/step - loss: -9.4718 - val_loss: -9.2889\n",
      "Epoch 3220/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.4482 - val_loss: -9.2843\n",
      "Epoch 3221/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.4949 - val_loss: -9.2782\n",
      "Epoch 3222/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.4801 - val_loss: -9.2870\n",
      "Epoch 3223/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.4531 - val_loss: -9.2864\n",
      "Epoch 3224/5000\n",
      "23/23 [==============================] - 4s 173ms/step - loss: -9.4901 - val_loss: -9.2872\n",
      "Epoch 3225/5000\n",
      "23/23 [==============================] - 5s 222ms/step - loss: -9.4568 - val_loss: -9.2950\n",
      "Epoch 3226/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.4547 - val_loss: -9.2757\n",
      "Epoch 3227/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.4647 - val_loss: -9.2768\n",
      "Epoch 3228/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -9.4953 - val_loss: -9.2769\n",
      "Epoch 3229/5000\n",
      "23/23 [==============================] - 4s 195ms/step - loss: -9.4435 - val_loss: -9.2861\n",
      "Epoch 3230/5000\n",
      "23/23 [==============================] - 5s 248ms/step - loss: -9.4821 - val_loss: -9.2708\n",
      "Epoch 3231/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.4099 - val_loss: -9.2869\n",
      "Epoch 3232/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.4809 - val_loss: -9.2931\n",
      "Epoch 3233/5000\n",
      "23/23 [==============================] - 5s 241ms/step - loss: -9.4478 - val_loss: -9.2832\n",
      "Epoch 3234/5000\n",
      "23/23 [==============================] - 4s 180ms/step - loss: -9.4286 - val_loss: -9.2805\n",
      "Epoch 3235/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -9.4873 - val_loss: -9.2709\n",
      "Epoch 3236/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.5004 - val_loss: -9.2886\n",
      "Epoch 3237/5000\n",
      "23/23 [==============================] - 3s 140ms/step - loss: -9.4795 - val_loss: -9.2789\n",
      "Epoch 3238/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -9.4900 - val_loss: -9.2917\n",
      "Epoch 3239/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.4973 - val_loss: -9.2846\n",
      "Epoch 3240/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.4708 - val_loss: -9.2822\n",
      "Epoch 3241/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.4879 - val_loss: -9.2876\n",
      "Epoch 3242/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.4847 - val_loss: -9.2962\n",
      "Epoch 3243/5000\n",
      "23/23 [==============================] - 6s 265ms/step - loss: -9.5013 - val_loss: -9.2891\n",
      "Epoch 3244/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.4451 - val_loss: -9.2892\n",
      "Epoch 3245/5000\n",
      "23/23 [==============================] - 2s 104ms/step - loss: -9.4644 - val_loss: -9.2729\n",
      "Epoch 3246/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.5057 - val_loss: -9.2729\n",
      "Epoch 3247/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.4642 - val_loss: -9.2784\n",
      "Epoch 3248/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.4790 - val_loss: -9.2933\n",
      "Epoch 3249/5000\n",
      "23/23 [==============================] - 4s 189ms/step - loss: -9.4626 - val_loss: -9.2901\n",
      "Epoch 3250/5000\n",
      "23/23 [==============================] - 5s 204ms/step - loss: -9.5043 - val_loss: -9.2853\n",
      "Epoch 3251/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.4398 - val_loss: -9.2820\n",
      "Epoch 3252/5000\n",
      "23/23 [==============================] - 5s 249ms/step - loss: -9.4917 - val_loss: -9.2835\n",
      "Epoch 3253/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.5018 - val_loss: -9.2832\n",
      "Epoch 3254/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.4970 - val_loss: -9.2931\n",
      "Epoch 3255/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5144 - val_loss: -9.2981\n",
      "Epoch 3256/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -9.4803 - val_loss: -9.2749\n",
      "Epoch 3257/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.4921 - val_loss: -9.2730\n",
      "Epoch 3258/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.5008 - val_loss: -9.2910\n",
      "Epoch 3259/5000\n",
      "23/23 [==============================] - 3s 121ms/step - loss: -9.4452 - val_loss: -9.2858\n",
      "Epoch 3260/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.4957 - val_loss: -9.2797\n",
      "Epoch 3261/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.4726 - val_loss: -9.2844\n",
      "Epoch 3262/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.4909 - val_loss: -9.2941\n",
      "Epoch 3263/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -9.5279 - val_loss: -9.2916\n",
      "Epoch 3264/5000\n",
      "23/23 [==============================] - 3s 136ms/step - loss: -9.5218 - val_loss: -9.2921\n",
      "Epoch 3265/5000\n",
      "23/23 [==============================] - 4s 171ms/step - loss: -9.4992 - val_loss: -9.2884\n",
      "Epoch 3266/5000\n",
      "23/23 [==============================] - 3s 132ms/step - loss: -9.4888 - val_loss: -9.2799\n",
      "Epoch 3267/5000\n",
      "23/23 [==============================] - 5s 208ms/step - loss: -9.4809 - val_loss: -9.2932\n",
      "Epoch 3268/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.4815 - val_loss: -9.2828\n",
      "Epoch 3269/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.3888 - val_loss: -9.2896\n",
      "Epoch 3270/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.4977 - val_loss: -9.2840\n",
      "Epoch 3271/5000\n",
      "23/23 [==============================] - 2s 110ms/step - loss: -9.4913 - val_loss: -9.3053\n",
      "Epoch 3272/5000\n",
      "23/23 [==============================] - 6s 255ms/step - loss: -9.4824 - val_loss: -9.2819\n",
      "Epoch 3273/5000\n",
      "23/23 [==============================] - 6s 260ms/step - loss: -9.4486 - val_loss: -9.2824\n",
      "Epoch 3274/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4677 - val_loss: -9.2909\n",
      "Epoch 3275/5000\n",
      "23/23 [==============================] - 10s 473ms/step - loss: -9.4363 - val_loss: -9.2909\n",
      "Epoch 3276/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5142 - val_loss: -9.2863\n",
      "Epoch 3277/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.4426 - val_loss: -9.2885\n",
      "Epoch 3278/5000\n",
      "23/23 [==============================] - 5s 227ms/step - loss: -9.5291 - val_loss: -9.2863\n",
      "Epoch 3279/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.4914 - val_loss: -9.2928\n",
      "Epoch 3280/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -9.4733 - val_loss: -9.2780\n",
      "Epoch 3281/5000\n",
      "23/23 [==============================] - 6s 263ms/step - loss: -9.4420 - val_loss: -9.2808\n",
      "Epoch 3282/5000\n",
      "23/23 [==============================] - 5s 245ms/step - loss: -9.4990 - val_loss: -9.3022\n",
      "Epoch 3283/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5084 - val_loss: -9.2914\n",
      "Epoch 3284/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.5143 - val_loss: -9.2866\n",
      "Epoch 3285/5000\n",
      "23/23 [==============================] - 6s 252ms/step - loss: -9.4071 - val_loss: -9.2874\n",
      "Epoch 3286/5000\n",
      "23/23 [==============================] - 3s 135ms/step - loss: -9.5156 - val_loss: -9.2907\n",
      "Epoch 3287/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.4803 - val_loss: -9.2940\n",
      "Epoch 3288/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.4762 - val_loss: -9.2845\n",
      "Epoch 3289/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.4548 - val_loss: -9.2907\n",
      "Epoch 3290/5000\n",
      "23/23 [==============================] - 4s 172ms/step - loss: -9.4829 - val_loss: -9.2834\n",
      "Epoch 3291/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.4432 - val_loss: -9.2962\n",
      "Epoch 3292/5000\n",
      "23/23 [==============================] - 3s 120ms/step - loss: -9.4925 - val_loss: -9.2879\n",
      "Epoch 3293/5000\n",
      "23/23 [==============================] - 2s 109ms/step - loss: -9.4982 - val_loss: -9.2872\n",
      "Epoch 3294/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -9.4782 - val_loss: -9.2954\n",
      "Epoch 3295/5000\n",
      "23/23 [==============================] - 5s 220ms/step - loss: -9.4850 - val_loss: -9.3046\n",
      "Epoch 3296/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.4580 - val_loss: -9.2972\n",
      "Epoch 3297/5000\n",
      "23/23 [==============================] - 6s 255ms/step - loss: -9.5099 - val_loss: -9.3055\n",
      "Epoch 3298/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5070 - val_loss: -9.2784\n",
      "Epoch 3299/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4583 - val_loss: -9.3010\n",
      "Epoch 3300/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.4913 - val_loss: -9.2858\n",
      "Epoch 3301/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.4743 - val_loss: -9.2926\n",
      "Epoch 3302/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -9.4569 - val_loss: -9.2930\n",
      "Epoch 3303/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.4443 - val_loss: -9.2796\n",
      "Epoch 3304/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -9.4970 - val_loss: -9.2993\n",
      "Epoch 3305/5000\n",
      "23/23 [==============================] - 6s 250ms/step - loss: -9.4674 - val_loss: -9.2934\n",
      "Epoch 3306/5000\n",
      "23/23 [==============================] - 4s 200ms/step - loss: -9.5195 - val_loss: -9.2744\n",
      "Epoch 3307/5000\n",
      "23/23 [==============================] - 4s 188ms/step - loss: -9.4719 - val_loss: -9.2845\n",
      "Epoch 3308/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.4845 - val_loss: -9.2981\n",
      "Epoch 3309/5000\n",
      "23/23 [==============================] - 6s 262ms/step - loss: -9.4881 - val_loss: -9.2940\n",
      "Epoch 3310/5000\n",
      "23/23 [==============================] - 5s 240ms/step - loss: -9.4837 - val_loss: -9.2925\n",
      "Epoch 3311/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.5131 - val_loss: -9.2952\n",
      "Epoch 3312/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -9.4793 - val_loss: -9.2935\n",
      "Epoch 3313/5000\n",
      "23/23 [==============================] - 4s 167ms/step - loss: -9.4841 - val_loss: -9.2991\n",
      "Epoch 3314/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.4829 - val_loss: -9.2969\n",
      "Epoch 3315/5000\n",
      "23/23 [==============================] - 4s 199ms/step - loss: -9.4173 - val_loss: -9.3154\n",
      "Epoch 3316/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.4999 - val_loss: -9.2923\n",
      "Epoch 3317/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.5213 - val_loss: -9.2821\n",
      "Epoch 3318/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.4929 - val_loss: -9.2939\n",
      "Epoch 3319/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.5014 - val_loss: -9.3010\n",
      "Epoch 3320/5000\n",
      "23/23 [==============================] - 3s 131ms/step - loss: -9.4347 - val_loss: -9.2915\n",
      "Epoch 3321/5000\n",
      "23/23 [==============================] - 3s 148ms/step - loss: -9.4506 - val_loss: -9.2862\n",
      "Epoch 3322/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.5084 - val_loss: -9.2903\n",
      "Epoch 3323/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.4993 - val_loss: -9.2904\n",
      "Epoch 3324/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.5129 - val_loss: -9.2932\n",
      "Epoch 3325/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.4709 - val_loss: -9.3007\n",
      "Epoch 3326/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -9.4567 - val_loss: -9.3017\n",
      "Epoch 3327/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.4735 - val_loss: -9.2953\n",
      "Epoch 3328/5000\n",
      "23/23 [==============================] - 3s 143ms/step - loss: -9.4431 - val_loss: -9.2991\n",
      "Epoch 3329/5000\n",
      "23/23 [==============================] - 3s 145ms/step - loss: -9.5018 - val_loss: -9.2873\n",
      "Epoch 3330/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4900 - val_loss: -9.2989\n",
      "Epoch 3331/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.4834 - val_loss: -9.3026\n",
      "Epoch 3332/5000\n",
      "23/23 [==============================] - 5s 245ms/step - loss: -9.4989 - val_loss: -9.3005\n",
      "Epoch 3333/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.4960 - val_loss: -9.2950\n",
      "Epoch 3334/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.5250 - val_loss: -9.3034\n",
      "Epoch 3335/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.4961 - val_loss: -9.3005\n",
      "Epoch 3336/5000\n",
      "23/23 [==============================] - 4s 179ms/step - loss: -9.4932 - val_loss: -9.3016\n",
      "Epoch 3337/5000\n",
      "23/23 [==============================] - 5s 235ms/step - loss: -9.4895 - val_loss: -9.3029\n",
      "Epoch 3338/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.4379 - val_loss: -9.2979\n",
      "Epoch 3339/5000\n",
      "23/23 [==============================] - 2s 108ms/step - loss: -9.4509 - val_loss: -9.2944\n",
      "Epoch 3340/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.5387 - val_loss: -9.2965\n",
      "Epoch 3341/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -9.4611 - val_loss: -9.3030\n",
      "Epoch 3342/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.5212 - val_loss: -9.3112\n",
      "Epoch 3343/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.5276 - val_loss: -9.2987\n",
      "Epoch 3344/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.4845 - val_loss: -9.2922\n",
      "Epoch 3345/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.5126 - val_loss: -9.3020\n",
      "Epoch 3346/5000\n",
      "23/23 [==============================] - 5s 206ms/step - loss: -9.5072 - val_loss: -9.3062\n",
      "Epoch 3347/5000\n",
      "23/23 [==============================] - 4s 191ms/step - loss: -9.4653 - val_loss: -9.2882\n",
      "Epoch 3348/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -9.4548 - val_loss: -9.3094\n",
      "Epoch 3349/5000\n",
      "23/23 [==============================] - 2s 113ms/step - loss: -9.5435 - val_loss: -9.3009\n",
      "Epoch 3350/5000\n",
      "23/23 [==============================] - 3s 121ms/step - loss: -9.4381 - val_loss: -9.2916\n",
      "Epoch 3351/5000\n",
      "23/23 [==============================] - 3s 115ms/step - loss: -9.5012 - val_loss: -9.3045\n",
      "Epoch 3352/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5136 - val_loss: -9.2940\n",
      "Epoch 3353/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4908 - val_loss: -9.2972\n",
      "Epoch 3354/5000\n",
      "23/23 [==============================] - 3s 133ms/step - loss: -9.4723 - val_loss: -9.3019\n",
      "Epoch 3355/5000\n",
      "23/23 [==============================] - 5s 229ms/step - loss: -9.4890 - val_loss: -9.3046\n",
      "Epoch 3356/5000\n",
      "23/23 [==============================] - 4s 202ms/step - loss: -9.4291 - val_loss: -9.2986\n",
      "Epoch 3357/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.4668 - val_loss: -9.2984\n",
      "Epoch 3358/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.4935 - val_loss: -9.3044\n",
      "Epoch 3359/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -9.5053 - val_loss: -9.3026\n",
      "Epoch 3360/5000\n",
      "23/23 [==============================] - 2s 112ms/step - loss: -9.4797 - val_loss: -9.3052\n",
      "Epoch 3361/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.4872 - val_loss: -9.3034\n",
      "Epoch 3362/5000\n",
      "23/23 [==============================] - 5s 206ms/step - loss: -9.5101 - val_loss: -9.2978\n",
      "Epoch 3363/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.5126 - val_loss: -9.2974\n",
      "Epoch 3364/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -9.4745 - val_loss: -9.3022\n",
      "Epoch 3365/5000\n",
      "23/23 [==============================] - 6s 263ms/step - loss: -9.4772 - val_loss: -9.3063\n",
      "Epoch 3366/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.4796 - val_loss: -9.3003\n",
      "Epoch 3367/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.4534 - val_loss: -9.3007\n",
      "Epoch 3368/5000\n",
      "23/23 [==============================] - 3s 139ms/step - loss: -9.4739 - val_loss: -9.3026\n",
      "Epoch 3369/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.4908 - val_loss: -9.2941\n",
      "Epoch 3370/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.4686 - val_loss: -9.3066\n",
      "Epoch 3371/5000\n",
      "23/23 [==============================] - 5s 232ms/step - loss: -9.5215 - val_loss: -9.3008\n",
      "Epoch 3372/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -9.4972 - val_loss: -9.2952\n",
      "Epoch 3373/5000\n",
      "23/23 [==============================] - 6s 260ms/step - loss: -9.4723 - val_loss: -9.3155\n",
      "Epoch 3374/5000\n",
      "23/23 [==============================] - 3s 120ms/step - loss: -9.5045 - val_loss: -9.3034\n",
      "Epoch 3375/5000\n",
      "23/23 [==============================] - 3s 135ms/step - loss: -9.4608 - val_loss: -9.3098\n",
      "Epoch 3376/5000\n",
      "23/23 [==============================] - 5s 237ms/step - loss: -9.4797 - val_loss: -9.3041\n",
      "Epoch 3377/5000\n",
      "23/23 [==============================] - 5s 218ms/step - loss: -9.5011 - val_loss: -9.3021\n",
      "Epoch 3378/5000\n",
      "23/23 [==============================] - 3s 148ms/step - loss: -9.4907 - val_loss: -9.3031\n",
      "Epoch 3379/5000\n",
      "23/23 [==============================] - 4s 164ms/step - loss: -9.4767 - val_loss: -9.2899\n",
      "Epoch 3380/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.5081 - val_loss: -9.3048\n",
      "Epoch 3381/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.4796 - val_loss: -9.3084\n",
      "Epoch 3382/5000\n",
      "23/23 [==============================] - 6s 251ms/step - loss: -9.5123 - val_loss: -9.3026\n",
      "Epoch 3383/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5206 - val_loss: -9.3053\n",
      "Epoch 3384/5000\n",
      "23/23 [==============================] - 4s 187ms/step - loss: -9.4908 - val_loss: -9.2898\n",
      "Epoch 3385/5000\n",
      "23/23 [==============================] - 3s 138ms/step - loss: -9.5183 - val_loss: -9.2955\n",
      "Epoch 3386/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.4800 - val_loss: -9.3148\n",
      "Epoch 3387/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4608 - val_loss: -9.3112\n",
      "Epoch 3388/5000\n",
      "23/23 [==============================] - 4s 181ms/step - loss: -9.5375 - val_loss: -9.3016\n",
      "Epoch 3389/5000\n",
      "23/23 [==============================] - 6s 261ms/step - loss: -9.4192 - val_loss: -9.3171\n",
      "Epoch 3390/5000\n",
      "23/23 [==============================] - 2s 112ms/step - loss: -9.4903 - val_loss: -9.2984\n",
      "Epoch 3391/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.4921 - val_loss: -9.3032\n",
      "Epoch 3392/5000\n",
      "23/23 [==============================] - 4s 198ms/step - loss: -9.4677 - val_loss: -9.3029\n",
      "Epoch 3393/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.4985 - val_loss: -9.3001\n",
      "Epoch 3394/5000\n",
      "23/23 [==============================] - 3s 147ms/step - loss: -9.4971 - val_loss: -9.3023\n",
      "Epoch 3395/5000\n",
      "23/23 [==============================] - 5s 212ms/step - loss: -9.5246 - val_loss: -9.3018\n",
      "Epoch 3396/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -9.5009 - val_loss: -9.2955\n",
      "Epoch 3397/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.4552 - val_loss: -9.3166\n",
      "Epoch 3398/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5000 - val_loss: -9.3070\n",
      "Epoch 3399/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5189 - val_loss: -9.2983\n",
      "Epoch 3400/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.4972 - val_loss: -9.3097\n",
      "Epoch 3401/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.5290 - val_loss: -9.3066\n",
      "Epoch 3402/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.5090 - val_loss: -9.3024\n",
      "Epoch 3403/5000\n",
      "23/23 [==============================] - 3s 131ms/step - loss: -9.4914 - val_loss: -9.3085\n",
      "Epoch 3404/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5128 - val_loss: -9.2980\n",
      "Epoch 3405/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4716 - val_loss: -9.3130\n",
      "Epoch 3406/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.5016 - val_loss: -9.3121\n",
      "Epoch 3407/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5094 - val_loss: -9.2961\n",
      "Epoch 3408/5000\n",
      "23/23 [==============================] - 3s 156ms/step - loss: -9.5021 - val_loss: -9.3130\n",
      "Epoch 3409/5000\n",
      "23/23 [==============================] - 3s 118ms/step - loss: -9.4908 - val_loss: -9.2944\n",
      "Epoch 3410/5000\n",
      "23/23 [==============================] - 2s 110ms/step - loss: -9.5101 - val_loss: -9.2985\n",
      "Epoch 3411/5000\n",
      "23/23 [==============================] - 3s 117ms/step - loss: -9.4539 - val_loss: -9.3137\n",
      "Epoch 3412/5000\n",
      "23/23 [==============================] - 6s 259ms/step - loss: -9.4751 - val_loss: -9.3162\n",
      "Epoch 3413/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.4312 - val_loss: -9.3088\n",
      "Epoch 3414/5000\n",
      "23/23 [==============================] - 3s 140ms/step - loss: -9.5101 - val_loss: -9.3094\n",
      "Epoch 3415/5000\n",
      "23/23 [==============================] - 4s 176ms/step - loss: -9.5058 - val_loss: -9.3151\n",
      "Epoch 3416/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.4989 - val_loss: -9.2868\n",
      "Epoch 3417/5000\n",
      "23/23 [==============================] - 3s 132ms/step - loss: -9.5096 - val_loss: -9.3118\n",
      "Epoch 3418/5000\n",
      "23/23 [==============================] - 3s 117ms/step - loss: -9.4345 - val_loss: -9.3067\n",
      "Epoch 3419/5000\n",
      "23/23 [==============================] - 3s 119ms/step - loss: -9.5421 - val_loss: -9.3077\n",
      "Epoch 3420/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.5073 - val_loss: -9.3097\n",
      "Epoch 3421/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5190 - val_loss: -9.3094\n",
      "Epoch 3422/5000\n",
      "23/23 [==============================] - 4s 182ms/step - loss: -9.5077 - val_loss: -9.3166\n",
      "Epoch 3423/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.5291 - val_loss: -9.3165\n",
      "Epoch 3424/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5205 - val_loss: -9.3159\n",
      "Epoch 3425/5000\n",
      "23/23 [==============================] - 5s 245ms/step - loss: -9.4697 - val_loss: -9.3136\n",
      "Epoch 3426/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4316 - val_loss: -9.3072\n",
      "Epoch 3427/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.5061 - val_loss: -9.3006\n",
      "Epoch 3428/5000\n",
      "23/23 [==============================] - 3s 146ms/step - loss: -9.4966 - val_loss: -9.3189\n",
      "Epoch 3429/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -9.4864 - val_loss: -9.3107\n",
      "Epoch 3430/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -9.4999 - val_loss: -9.3084\n",
      "Epoch 3431/5000\n",
      "23/23 [==============================] - 2s 109ms/step - loss: -9.5505 - val_loss: -9.3091\n",
      "Epoch 3432/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.4775 - val_loss: -9.3179\n",
      "Epoch 3433/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5131 - val_loss: -9.3183\n",
      "Epoch 3434/5000\n",
      "23/23 [==============================] - 4s 185ms/step - loss: -9.4888 - val_loss: -9.3078\n",
      "Epoch 3435/5000\n",
      "23/23 [==============================] - 3s 132ms/step - loss: -9.4877 - val_loss: -9.3101\n",
      "Epoch 3436/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5205 - val_loss: -9.2984\n",
      "Epoch 3437/5000\n",
      "23/23 [==============================] - 4s 178ms/step - loss: -9.5067 - val_loss: -9.3031\n",
      "Epoch 3438/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.5101 - val_loss: -9.3057\n",
      "Epoch 3439/5000\n",
      "23/23 [==============================] - 5s 240ms/step - loss: -9.4916 - val_loss: -9.3125\n",
      "Epoch 3440/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.4578 - val_loss: -9.3142\n",
      "Epoch 3441/5000\n",
      "23/23 [==============================] - 5s 240ms/step - loss: -9.4937 - val_loss: -9.3120\n",
      "Epoch 3442/5000\n",
      "23/23 [==============================] - 3s 136ms/step - loss: -9.4590 - val_loss: -9.3106\n",
      "Epoch 3443/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.4913 - val_loss: -9.3057\n",
      "Epoch 3444/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4738 - val_loss: -9.3164\n",
      "Epoch 3445/5000\n",
      "23/23 [==============================] - 3s 140ms/step - loss: -9.4911 - val_loss: -9.3260\n",
      "Epoch 3446/5000\n",
      "23/23 [==============================] - 3s 119ms/step - loss: -9.5226 - val_loss: -9.3135\n",
      "Epoch 3447/5000\n",
      "23/23 [==============================] - 4s 201ms/step - loss: -9.5173 - val_loss: -9.3195\n",
      "Epoch 3448/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.4702 - val_loss: -9.3109\n",
      "Epoch 3449/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5185 - val_loss: -9.3185\n",
      "Epoch 3450/5000\n",
      "23/23 [==============================] - 5s 215ms/step - loss: -9.4736 - val_loss: -9.3140\n",
      "Epoch 3451/5000\n",
      "23/23 [==============================] - 5s 213ms/step - loss: -9.5000 - val_loss: -9.3019\n",
      "Epoch 3452/5000\n",
      "23/23 [==============================] - 5s 240ms/step - loss: -9.5085 - val_loss: -9.3195\n",
      "Epoch 3453/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -9.5297 - val_loss: -9.3041\n",
      "Epoch 3454/5000\n",
      "23/23 [==============================] - 6s 262ms/step - loss: -9.5180 - val_loss: -9.3129\n",
      "Epoch 3455/5000\n",
      "23/23 [==============================] - 3s 152ms/step - loss: -9.4705 - val_loss: -9.3176\n",
      "Epoch 3456/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.5388 - val_loss: -9.3112\n",
      "Epoch 3457/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.5312 - val_loss: -9.3094\n",
      "Epoch 3458/5000\n",
      "23/23 [==============================] - 4s 182ms/step - loss: -9.4902 - val_loss: -9.3093\n",
      "Epoch 3459/5000\n",
      "23/23 [==============================] - 2s 110ms/step - loss: -9.5253 - val_loss: -9.3178\n",
      "Epoch 3460/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -9.5204 - val_loss: -9.3197\n",
      "Epoch 3461/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5294 - val_loss: -9.3105\n",
      "Epoch 3462/5000\n",
      "23/23 [==============================] - 6s 265ms/step - loss: -9.4705 - val_loss: -9.3142\n",
      "Epoch 3463/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.5333 - val_loss: -9.3077\n",
      "Epoch 3464/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.5078 - val_loss: -9.3131\n",
      "Epoch 3465/5000\n",
      "23/23 [==============================] - 4s 191ms/step - loss: -9.4971 - val_loss: -9.3182\n",
      "Epoch 3466/5000\n",
      "23/23 [==============================] - 2s 104ms/step - loss: -9.4843 - val_loss: -9.3263\n",
      "Epoch 3467/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.5317 - val_loss: -9.3120\n",
      "Epoch 3468/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4743 - val_loss: -9.3216\n",
      "Epoch 3469/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.4953 - val_loss: -9.3299\n",
      "Epoch 3470/5000\n",
      "23/23 [==============================] - 3s 117ms/step - loss: -9.5159 - val_loss: -9.3194\n",
      "Epoch 3471/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.4966 - val_loss: -9.3093\n",
      "Epoch 3472/5000\n",
      "23/23 [==============================] - 3s 134ms/step - loss: -9.5058 - val_loss: -9.3231\n",
      "Epoch 3473/5000\n",
      "23/23 [==============================] - 3s 154ms/step - loss: -9.5254 - val_loss: -9.3156\n",
      "Epoch 3474/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.5079 - val_loss: -9.3180\n",
      "Epoch 3475/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -9.5027 - val_loss: -9.3279\n",
      "Epoch 3476/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.4925 - val_loss: -9.3210\n",
      "Epoch 3477/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.5335 - val_loss: -9.3172\n",
      "Epoch 3478/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.5117 - val_loss: -9.3180\n",
      "Epoch 3479/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.5116 - val_loss: -9.3070\n",
      "Epoch 3480/5000\n",
      "23/23 [==============================] - 5s 246ms/step - loss: -9.5070 - val_loss: -9.3169\n",
      "Epoch 3481/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.5056 - val_loss: -9.3084\n",
      "Epoch 3482/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5038 - val_loss: -9.3218\n",
      "Epoch 3483/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.5239 - val_loss: -9.3192\n",
      "Epoch 3484/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5324 - val_loss: -9.3152\n",
      "Epoch 3485/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -9.5089 - val_loss: -9.3277\n",
      "Epoch 3486/5000\n",
      "23/23 [==============================] - 5s 218ms/step - loss: -9.5055 - val_loss: -9.3253\n",
      "Epoch 3487/5000\n",
      "23/23 [==============================] - 5s 211ms/step - loss: -9.4877 - val_loss: -9.3201\n",
      "Epoch 3488/5000\n",
      "23/23 [==============================] - 3s 132ms/step - loss: -9.5211 - val_loss: -9.3152\n",
      "Epoch 3489/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.4891 - val_loss: -9.3133\n",
      "Epoch 3490/5000\n",
      "23/23 [==============================] - 3s 112ms/step - loss: -9.4988 - val_loss: -9.3199\n",
      "Epoch 3491/5000\n",
      "23/23 [==============================] - 5s 248ms/step - loss: -9.4736 - val_loss: -9.3139\n",
      "Epoch 3492/5000\n",
      "23/23 [==============================] - 5s 245ms/step - loss: -9.4950 - val_loss: -9.3146\n",
      "Epoch 3493/5000\n",
      "23/23 [==============================] - 4s 200ms/step - loss: -9.5414 - val_loss: -9.3134\n",
      "Epoch 3494/5000\n",
      "23/23 [==============================] - 5s 240ms/step - loss: -9.5181 - val_loss: -9.3219\n",
      "Epoch 3495/5000\n",
      "23/23 [==============================] - 5s 237ms/step - loss: -9.5323 - val_loss: -9.3054\n",
      "Epoch 3496/5000\n",
      "23/23 [==============================] - 6s 256ms/step - loss: -9.3848 - val_loss: -9.3144\n",
      "Epoch 3497/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.4888 - val_loss: -9.3199\n",
      "Epoch 3498/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5053 - val_loss: -9.3177\n",
      "Epoch 3499/5000\n",
      "23/23 [==============================] - 4s 200ms/step - loss: -9.5378 - val_loss: -9.3274\n",
      "Epoch 3500/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.5309 - val_loss: -9.3206\n",
      "Epoch 3501/5000\n",
      "23/23 [==============================] - 4s 172ms/step - loss: -9.2675 - val_loss: -9.3136\n",
      "Epoch 3502/5000\n",
      "23/23 [==============================] - 6s 252ms/step - loss: -9.5048 - val_loss: -9.3245\n",
      "Epoch 3503/5000\n",
      "23/23 [==============================] - 3s 120ms/step - loss: -9.5167 - val_loss: -9.3225\n",
      "Epoch 3504/5000\n",
      "23/23 [==============================] - 5s 246ms/step - loss: -9.5484 - val_loss: -9.3349\n",
      "Epoch 3505/5000\n",
      "23/23 [==============================] - 3s 158ms/step - loss: -9.4804 - val_loss: -9.3170\n",
      "Epoch 3506/5000\n",
      "23/23 [==============================] - 6s 263ms/step - loss: -9.5240 - val_loss: -9.3124\n",
      "Epoch 3507/5000\n",
      "23/23 [==============================] - 5s 208ms/step - loss: -9.4620 - val_loss: -9.3152\n",
      "Epoch 3508/5000\n",
      "23/23 [==============================] - 3s 136ms/step - loss: -9.4872 - val_loss: -9.3153\n",
      "Epoch 3509/5000\n",
      "23/23 [==============================] - 2s 110ms/step - loss: -9.4989 - val_loss: -9.3209\n",
      "Epoch 3510/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.5327 - val_loss: -9.3273\n",
      "Epoch 3511/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.5050 - val_loss: -9.3197\n",
      "Epoch 3512/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -9.5093 - val_loss: -9.3196\n",
      "Epoch 3513/5000\n",
      "23/23 [==============================] - 6s 259ms/step - loss: -9.5016 - val_loss: -9.3283\n",
      "Epoch 3514/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5074 - val_loss: -9.3192\n",
      "Epoch 3515/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5070 - val_loss: -9.3260\n",
      "Epoch 3516/5000\n",
      "23/23 [==============================] - 5s 247ms/step - loss: -9.5075 - val_loss: -9.3147\n",
      "Epoch 3517/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4963 - val_loss: -9.3206\n",
      "Epoch 3518/5000\n",
      "23/23 [==============================] - 3s 140ms/step - loss: -9.5006 - val_loss: -9.3221\n",
      "Epoch 3519/5000\n",
      "23/23 [==============================] - 4s 163ms/step - loss: -9.5051 - val_loss: -9.3222\n",
      "Epoch 3520/5000\n",
      "23/23 [==============================] - 2s 110ms/step - loss: -9.4944 - val_loss: -9.3127\n",
      "Epoch 3521/5000\n",
      "23/23 [==============================] - 5s 241ms/step - loss: -9.4924 - val_loss: -9.3169\n",
      "Epoch 3522/5000\n",
      "23/23 [==============================] - 6s 256ms/step - loss: -9.5126 - val_loss: -9.3319\n",
      "Epoch 3523/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.5096 - val_loss: -9.3245\n",
      "Epoch 3524/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.5185 - val_loss: -9.3223\n",
      "Epoch 3525/5000\n",
      "23/23 [==============================] - 6s 256ms/step - loss: -9.5023 - val_loss: -9.3292\n",
      "Epoch 3526/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.4797 - val_loss: -9.3215\n",
      "Epoch 3527/5000\n",
      "23/23 [==============================] - 4s 202ms/step - loss: -9.4941 - val_loss: -9.3304\n",
      "Epoch 3528/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5240 - val_loss: -9.3237\n",
      "Epoch 3529/5000\n",
      "23/23 [==============================] - 5s 210ms/step - loss: -9.5248 - val_loss: -9.3236\n",
      "Epoch 3530/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.4853 - val_loss: -9.3218\n",
      "Epoch 3531/5000\n",
      "23/23 [==============================] - 3s 155ms/step - loss: -9.5368 - val_loss: -9.3271\n",
      "Epoch 3532/5000\n",
      "23/23 [==============================] - 3s 149ms/step - loss: -9.5113 - val_loss: -9.3212\n",
      "Epoch 3533/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -9.5245 - val_loss: -9.3310\n",
      "Epoch 3534/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.5096 - val_loss: -9.3155\n",
      "Epoch 3535/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5176 - val_loss: -9.3192\n",
      "Epoch 3536/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.5446 - val_loss: -9.3138\n",
      "Epoch 3537/5000\n",
      "23/23 [==============================] - 3s 143ms/step - loss: -9.5279 - val_loss: -9.3316\n",
      "Epoch 3538/5000\n",
      "23/23 [==============================] - 5s 228ms/step - loss: -9.5045 - val_loss: -9.3116\n",
      "Epoch 3539/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4841 - val_loss: -9.3251\n",
      "Epoch 3540/5000\n",
      "23/23 [==============================] - 5s 208ms/step - loss: -9.5038 - val_loss: -9.3319\n",
      "Epoch 3541/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.5078 - val_loss: -9.3219\n",
      "Epoch 3542/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.5117 - val_loss: -9.3235\n",
      "Epoch 3543/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.4719 - val_loss: -9.3291\n",
      "Epoch 3544/5000\n",
      "23/23 [==============================] - 3s 113ms/step - loss: -9.4906 - val_loss: -9.3316\n",
      "Epoch 3545/5000\n",
      "23/23 [==============================] - 5s 230ms/step - loss: -9.5214 - val_loss: -9.3245\n",
      "Epoch 3546/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.4846 - val_loss: -9.3201\n",
      "Epoch 3547/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.4751 - val_loss: -9.3170\n",
      "Epoch 3548/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5239 - val_loss: -9.3270\n",
      "Epoch 3549/5000\n",
      "23/23 [==============================] - 4s 179ms/step - loss: -9.5433 - val_loss: -9.3255\n",
      "Epoch 3550/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.5527 - val_loss: -9.3267\n",
      "Epoch 3551/5000\n",
      "23/23 [==============================] - 4s 202ms/step - loss: -9.5090 - val_loss: -9.3258\n",
      "Epoch 3552/5000\n",
      "23/23 [==============================] - 5s 234ms/step - loss: -9.5287 - val_loss: -9.3197\n",
      "Epoch 3553/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.4612 - val_loss: -9.3285\n",
      "Epoch 3554/5000\n",
      "23/23 [==============================] - 3s 136ms/step - loss: -9.5002 - val_loss: -9.3331\n",
      "Epoch 3555/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.5138 - val_loss: -9.3273\n",
      "Epoch 3556/5000\n",
      "23/23 [==============================] - 5s 224ms/step - loss: -9.5275 - val_loss: -9.3181\n",
      "Epoch 3557/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.4991 - val_loss: -9.3084\n",
      "Epoch 3558/5000\n",
      "23/23 [==============================] - 2s 110ms/step - loss: -9.5226 - val_loss: -9.3226\n",
      "Epoch 3559/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -9.5324 - val_loss: -9.3245\n",
      "Epoch 3560/5000\n",
      "23/23 [==============================] - 5s 216ms/step - loss: -9.5262 - val_loss: -9.3257\n",
      "Epoch 3561/5000\n",
      "23/23 [==============================] - 6s 262ms/step - loss: -9.5100 - val_loss: -9.3400\n",
      "Epoch 3562/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -9.5424 - val_loss: -9.3189\n",
      "Epoch 3563/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5438 - val_loss: -9.3187\n",
      "Epoch 3564/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5104 - val_loss: -9.3296\n",
      "Epoch 3565/5000\n",
      "23/23 [==============================] - 5s 216ms/step - loss: -9.4979 - val_loss: -9.3316\n",
      "Epoch 3566/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.4830 - val_loss: -9.3353\n",
      "Epoch 3567/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4936 - val_loss: -9.3254\n",
      "Epoch 3568/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.5229 - val_loss: -9.3302\n",
      "Epoch 3569/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.5263 - val_loss: -9.3262\n",
      "Epoch 3570/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.5167 - val_loss: -9.3289\n",
      "Epoch 3571/5000\n",
      "23/23 [==============================] - 2s 113ms/step - loss: -9.4934 - val_loss: -9.3309\n",
      "Epoch 3572/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.4944 - val_loss: -9.3267\n",
      "Epoch 3573/5000\n",
      "23/23 [==============================] - 4s 202ms/step - loss: -9.5421 - val_loss: -9.3281\n",
      "Epoch 3574/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.5255 - val_loss: -9.3273\n",
      "Epoch 3575/5000\n",
      "23/23 [==============================] - 6s 265ms/step - loss: -9.5129 - val_loss: -9.3303\n",
      "Epoch 3576/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.4891 - val_loss: -9.3396\n",
      "Epoch 3577/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5447 - val_loss: -9.3225\n",
      "Epoch 3578/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.4851 - val_loss: -9.3353\n",
      "Epoch 3579/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.5582 - val_loss: -9.3363\n",
      "Epoch 3580/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.4980 - val_loss: -9.3235\n",
      "Epoch 3581/5000\n",
      "23/23 [==============================] - 5s 241ms/step - loss: -9.5101 - val_loss: -9.3288\n",
      "Epoch 3582/5000\n",
      "23/23 [==============================] - 5s 217ms/step - loss: -9.4792 - val_loss: -9.3232\n",
      "Epoch 3583/5000\n",
      "23/23 [==============================] - 6s 254ms/step - loss: -9.5073 - val_loss: -9.3316\n",
      "Epoch 3584/5000\n",
      "23/23 [==============================] - 4s 200ms/step - loss: -9.5474 - val_loss: -9.3317\n",
      "Epoch 3585/5000\n",
      "23/23 [==============================] - 6s 259ms/step - loss: -9.5120 - val_loss: -9.3341\n",
      "Epoch 3586/5000\n",
      "23/23 [==============================] - 4s 171ms/step - loss: -9.5213 - val_loss: -9.3224\n",
      "Epoch 3587/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5524 - val_loss: -9.3370\n",
      "Epoch 3588/5000\n",
      "23/23 [==============================] - 3s 120ms/step - loss: -9.4802 - val_loss: -9.3311\n",
      "Epoch 3589/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.5393 - val_loss: -9.3321\n",
      "Epoch 3590/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.4726 - val_loss: -9.3268\n",
      "Epoch 3591/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4985 - val_loss: -9.3285\n",
      "Epoch 3592/5000\n",
      "23/23 [==============================] - 4s 173ms/step - loss: -9.5113 - val_loss: -9.3191\n",
      "Epoch 3593/5000\n",
      "23/23 [==============================] - 5s 245ms/step - loss: -9.4906 - val_loss: -9.3324\n",
      "Epoch 3594/5000\n",
      "23/23 [==============================] - 5s 245ms/step - loss: -9.4950 - val_loss: -9.3321\n",
      "Epoch 3595/5000\n",
      "23/23 [==============================] - 3s 132ms/step - loss: -9.4925 - val_loss: -9.3444\n",
      "Epoch 3596/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.5381 - val_loss: -9.3309\n",
      "Epoch 3597/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.4932 - val_loss: -9.3318\n",
      "Epoch 3598/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.5423 - val_loss: -9.3306\n",
      "Epoch 3599/5000\n",
      "23/23 [==============================] - 4s 177ms/step - loss: -9.4760 - val_loss: -9.3343\n",
      "Epoch 3600/5000\n",
      "23/23 [==============================] - 4s 201ms/step - loss: -9.4442 - val_loss: -9.3299\n",
      "Epoch 3601/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.5215 - val_loss: -9.3281\n",
      "Epoch 3602/5000\n",
      "23/23 [==============================] - 4s 164ms/step - loss: -9.5077 - val_loss: -9.3330\n",
      "Epoch 3603/5000\n",
      "23/23 [==============================] - 3s 139ms/step - loss: -9.5140 - val_loss: -9.3390\n",
      "Epoch 3604/5000\n",
      "23/23 [==============================] - 6s 257ms/step - loss: -9.5104 - val_loss: -9.3305\n",
      "Epoch 3605/5000\n",
      "23/23 [==============================] - 4s 203ms/step - loss: -9.5308 - val_loss: -9.3366\n",
      "Epoch 3606/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5171 - val_loss: -9.3259\n",
      "Epoch 3607/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5269 - val_loss: -9.3296\n",
      "Epoch 3608/5000\n",
      "23/23 [==============================] - 3s 135ms/step - loss: -9.5264 - val_loss: -9.3350\n",
      "Epoch 3609/5000\n",
      "23/23 [==============================] - 2s 113ms/step - loss: -9.4762 - val_loss: -9.3372\n",
      "Epoch 3610/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.5277 - val_loss: -9.3374\n",
      "Epoch 3611/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5041 - val_loss: -9.3323\n",
      "Epoch 3612/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.5451 - val_loss: -9.3329\n",
      "Epoch 3613/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.4979 - val_loss: -9.3376\n",
      "Epoch 3614/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5084 - val_loss: -9.3318\n",
      "Epoch 3615/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.5161 - val_loss: -9.3318\n",
      "Epoch 3616/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.5093 - val_loss: -9.3367\n",
      "Epoch 3617/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.5418 - val_loss: -9.3297\n",
      "Epoch 3618/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.4926 - val_loss: -9.3341\n",
      "Epoch 3619/5000\n",
      "23/23 [==============================] - 3s 117ms/step - loss: -9.5259 - val_loss: -9.3340\n",
      "Epoch 3620/5000\n",
      "23/23 [==============================] - 3s 131ms/step - loss: -9.5370 - val_loss: -9.3294\n",
      "Epoch 3621/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5007 - val_loss: -9.3270\n",
      "Epoch 3622/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5372 - val_loss: -9.3379\n",
      "Epoch 3623/5000\n",
      "23/23 [==============================] - 5s 245ms/step - loss: -9.5297 - val_loss: -9.3314\n",
      "Epoch 3624/5000\n",
      "23/23 [==============================] - 3s 118ms/step - loss: -9.5214 - val_loss: -9.3386\n",
      "Epoch 3625/5000\n",
      "23/23 [==============================] - 6s 253ms/step - loss: -9.5397 - val_loss: -9.3459\n",
      "Epoch 3626/5000\n",
      "23/23 [==============================] - 5s 246ms/step - loss: -9.5066 - val_loss: -9.3242\n",
      "Epoch 3627/5000\n",
      "23/23 [==============================] - 6s 255ms/step - loss: -9.5584 - val_loss: -9.3385\n",
      "Epoch 3628/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.5451 - val_loss: -9.3305\n",
      "Epoch 3629/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5383 - val_loss: -9.3423\n",
      "Epoch 3630/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.5474 - val_loss: -9.3378\n",
      "Epoch 3631/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5346 - val_loss: -9.3289\n",
      "Epoch 3632/5000\n",
      "23/23 [==============================] - 5s 249ms/step - loss: -9.5050 - val_loss: -9.3287\n",
      "Epoch 3633/5000\n",
      "23/23 [==============================] - 5s 208ms/step - loss: -9.5109 - val_loss: -9.3412\n",
      "Epoch 3634/5000\n",
      "23/23 [==============================] - 4s 171ms/step - loss: -9.5190 - val_loss: -9.3365\n",
      "Epoch 3635/5000\n",
      "23/23 [==============================] - 6s 254ms/step - loss: -9.5245 - val_loss: -9.3400\n",
      "Epoch 3636/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.5229 - val_loss: -9.3380\n",
      "Epoch 3637/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5186 - val_loss: -9.3402\n",
      "Epoch 3638/5000\n",
      "23/23 [==============================] - 3s 114ms/step - loss: -9.5223 - val_loss: -9.3431\n",
      "Epoch 3639/5000\n",
      "23/23 [==============================] - 5s 204ms/step - loss: -9.5370 - val_loss: -9.3409\n",
      "Epoch 3640/5000\n",
      "23/23 [==============================] - 5s 245ms/step - loss: -9.5154 - val_loss: -9.3321\n",
      "Epoch 3641/5000\n",
      "23/23 [==============================] - 5s 241ms/step - loss: -9.5334 - val_loss: -9.3328\n",
      "Epoch 3642/5000\n",
      "23/23 [==============================] - 3s 143ms/step - loss: -9.5405 - val_loss: -9.3361\n",
      "Epoch 3643/5000\n",
      "23/23 [==============================] - 3s 152ms/step - loss: -9.4268 - val_loss: -9.3396\n",
      "Epoch 3644/5000\n",
      "23/23 [==============================] - 5s 241ms/step - loss: -9.5257 - val_loss: -9.3384\n",
      "Epoch 3645/5000\n",
      "23/23 [==============================] - 6s 261ms/step - loss: -9.4895 - val_loss: -9.3288\n",
      "Epoch 3646/5000\n",
      "23/23 [==============================] - 5s 218ms/step - loss: -9.5344 - val_loss: -9.3330\n",
      "Epoch 3647/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.5320 - val_loss: -9.3423\n",
      "Epoch 3648/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -9.5380 - val_loss: -9.3358\n",
      "Epoch 3649/5000\n",
      "23/23 [==============================] - 5s 219ms/step - loss: -9.5317 - val_loss: -9.3446\n",
      "Epoch 3650/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5181 - val_loss: -9.3401\n",
      "Epoch 3651/5000\n",
      "23/23 [==============================] - 4s 159ms/step - loss: -9.5405 - val_loss: -9.3384\n",
      "Epoch 3652/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.5593 - val_loss: -9.3356\n",
      "Epoch 3653/5000\n",
      "23/23 [==============================] - 3s 115ms/step - loss: -9.5421 - val_loss: -9.3382\n",
      "Epoch 3654/5000\n",
      "23/23 [==============================] - 4s 169ms/step - loss: -9.5324 - val_loss: -9.3386\n",
      "Epoch 3655/5000\n",
      "23/23 [==============================] - 4s 180ms/step - loss: -9.5336 - val_loss: -9.3337\n",
      "Epoch 3656/5000\n",
      "23/23 [==============================] - 5s 223ms/step - loss: -9.5800 - val_loss: -9.3507\n",
      "Epoch 3657/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -9.5101 - val_loss: -9.3377\n",
      "Epoch 3658/5000\n",
      "23/23 [==============================] - 3s 117ms/step - loss: -9.5148 - val_loss: -9.3275\n",
      "Epoch 3659/5000\n",
      "23/23 [==============================] - 4s 172ms/step - loss: -9.5622 - val_loss: -9.3304\n",
      "Epoch 3660/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.4695 - val_loss: -9.3356\n",
      "Epoch 3661/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5339 - val_loss: -9.3398\n",
      "Epoch 3662/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -9.5516 - val_loss: -9.3425\n",
      "Epoch 3663/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5354 - val_loss: -9.3426\n",
      "Epoch 3664/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5365 - val_loss: -9.3399\n",
      "Epoch 3665/5000\n",
      "23/23 [==============================] - 6s 251ms/step - loss: -9.5510 - val_loss: -9.3287\n",
      "Epoch 3666/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.5493 - val_loss: -9.3376\n",
      "Epoch 3667/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.4533 - val_loss: -9.3484\n",
      "Epoch 3668/5000\n",
      "23/23 [==============================] - 3s 117ms/step - loss: -9.5306 - val_loss: -9.3385\n",
      "Epoch 3669/5000\n",
      "23/23 [==============================] - 6s 268ms/step - loss: -9.5281 - val_loss: -9.3483\n",
      "Epoch 3670/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5045 - val_loss: -9.3430\n",
      "Epoch 3671/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -9.5340 - val_loss: -9.3404\n",
      "Epoch 3672/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.5233 - val_loss: -9.3391\n",
      "Epoch 3673/5000\n",
      "23/23 [==============================] - 5s 235ms/step - loss: -9.5516 - val_loss: -9.3392\n",
      "Epoch 3674/5000\n",
      "23/23 [==============================] - 3s 146ms/step - loss: -9.4938 - val_loss: -9.3216\n",
      "Epoch 3675/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.5120 - val_loss: -9.3364\n",
      "Epoch 3676/5000\n",
      "23/23 [==============================] - 3s 132ms/step - loss: -9.5453 - val_loss: -9.3475\n",
      "Epoch 3677/5000\n",
      "23/23 [==============================] - 4s 203ms/step - loss: -9.5086 - val_loss: -9.3343\n",
      "Epoch 3678/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.5214 - val_loss: -9.3442\n",
      "Epoch 3679/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.5079 - val_loss: -9.3361\n",
      "Epoch 3680/5000\n",
      "23/23 [==============================] - 2s 108ms/step - loss: -9.5332 - val_loss: -9.3370\n",
      "Epoch 3681/5000\n",
      "23/23 [==============================] - 5s 209ms/step - loss: -9.5022 - val_loss: -9.3429\n",
      "Epoch 3682/5000\n",
      "23/23 [==============================] - 5s 248ms/step - loss: -9.4985 - val_loss: -9.3410\n",
      "Epoch 3683/5000\n",
      "23/23 [==============================] - 5s 233ms/step - loss: -9.5269 - val_loss: -9.3408\n",
      "Epoch 3684/5000\n",
      "23/23 [==============================] - 2s 108ms/step - loss: -9.5210 - val_loss: -9.3456\n",
      "Epoch 3685/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -9.5461 - val_loss: -9.3410\n",
      "Epoch 3686/5000\n",
      "23/23 [==============================] - 3s 133ms/step - loss: -9.5218 - val_loss: -9.3320\n",
      "Epoch 3687/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -9.5465 - val_loss: -9.3385\n",
      "Epoch 3688/5000\n",
      "23/23 [==============================] - 4s 181ms/step - loss: -9.5444 - val_loss: -9.3457\n",
      "Epoch 3689/5000\n",
      "23/23 [==============================] - 3s 114ms/step - loss: -9.4793 - val_loss: -9.3424\n",
      "Epoch 3690/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.5479 - val_loss: -9.3390\n",
      "Epoch 3691/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5340 - val_loss: -9.3392\n",
      "Epoch 3692/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.5019 - val_loss: -9.3442\n",
      "Epoch 3693/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -9.5253 - val_loss: -9.3407\n",
      "Epoch 3694/5000\n",
      "23/23 [==============================] - 6s 258ms/step - loss: -9.5339 - val_loss: -9.3389\n",
      "Epoch 3695/5000\n",
      "23/23 [==============================] - 5s 209ms/step - loss: -9.5432 - val_loss: -9.3431\n",
      "Epoch 3696/5000\n",
      "23/23 [==============================] - 6s 259ms/step - loss: -9.5355 - val_loss: -9.3371\n",
      "Epoch 3697/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.5458 - val_loss: -9.3394\n",
      "Epoch 3698/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5391 - val_loss: -9.3448\n",
      "Epoch 3699/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -9.4663 - val_loss: -9.3437\n",
      "Epoch 3700/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5306 - val_loss: -9.3455\n",
      "Epoch 3701/5000\n",
      "23/23 [==============================] - 5s 232ms/step - loss: -9.5075 - val_loss: -9.3471\n",
      "Epoch 3702/5000\n",
      "23/23 [==============================] - 4s 187ms/step - loss: -9.5427 - val_loss: -9.3463\n",
      "Epoch 3703/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.5242 - val_loss: -9.3438\n",
      "Epoch 3704/5000\n",
      "23/23 [==============================] - 5s 247ms/step - loss: -9.5248 - val_loss: -9.3404\n",
      "Epoch 3705/5000\n",
      "23/23 [==============================] - 6s 254ms/step - loss: -9.5382 - val_loss: -9.3477\n",
      "Epoch 3706/5000\n",
      "23/23 [==============================] - 6s 258ms/step - loss: -9.5207 - val_loss: -9.3354\n",
      "Epoch 3707/5000\n",
      "23/23 [==============================] - 4s 165ms/step - loss: -9.5242 - val_loss: -9.3351\n",
      "Epoch 3708/5000\n",
      "23/23 [==============================] - 3s 116ms/step - loss: -9.5509 - val_loss: -9.3421\n",
      "Epoch 3709/5000\n",
      "23/23 [==============================] - 3s 134ms/step - loss: -9.5397 - val_loss: -9.3520\n",
      "Epoch 3710/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5308 - val_loss: -9.3417\n",
      "Epoch 3711/5000\n",
      "23/23 [==============================] - 6s 260ms/step - loss: -9.5295 - val_loss: -9.3436\n",
      "Epoch 3712/5000\n",
      "23/23 [==============================] - 4s 178ms/step - loss: -9.5241 - val_loss: -9.3362\n",
      "Epoch 3713/5000\n",
      "23/23 [==============================] - 5s 249ms/step - loss: -9.5175 - val_loss: -9.3455\n",
      "Epoch 3714/5000\n",
      "23/23 [==============================] - 6s 256ms/step - loss: -9.4813 - val_loss: -9.3385\n",
      "Epoch 3715/5000\n",
      "23/23 [==============================] - 5s 210ms/step - loss: -9.4689 - val_loss: -9.3477\n",
      "Epoch 3716/5000\n",
      "23/23 [==============================] - 3s 146ms/step - loss: -9.5249 - val_loss: -9.3299\n",
      "Epoch 3717/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5150 - val_loss: -9.3402\n",
      "Epoch 3718/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.5201 - val_loss: -9.3485\n",
      "Epoch 3719/5000\n",
      "23/23 [==============================] - 4s 183ms/step - loss: -9.5551 - val_loss: -9.3412\n",
      "Epoch 3720/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.5156 - val_loss: -9.3411\n",
      "Epoch 3721/5000\n",
      "23/23 [==============================] - 3s 142ms/step - loss: -9.5564 - val_loss: -9.3449\n",
      "Epoch 3722/5000\n",
      "23/23 [==============================] - 4s 160ms/step - loss: -9.5058 - val_loss: -9.3473\n",
      "Epoch 3723/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.5395 - val_loss: -9.3444\n",
      "Epoch 3724/5000\n",
      "23/23 [==============================] - 2s 104ms/step - loss: -9.5675 - val_loss: -9.3468\n",
      "Epoch 3725/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5623 - val_loss: -9.3476\n",
      "Epoch 3726/5000\n",
      "23/23 [==============================] - 4s 184ms/step - loss: -9.5347 - val_loss: -9.3508\n",
      "Epoch 3727/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.4721 - val_loss: -9.3447\n",
      "Epoch 3728/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.5272 - val_loss: -9.3523\n",
      "Epoch 3729/5000\n",
      "23/23 [==============================] - 3s 120ms/step - loss: -9.4827 - val_loss: -9.3441\n",
      "Epoch 3730/5000\n",
      "23/23 [==============================] - 6s 255ms/step - loss: -9.5304 - val_loss: -9.3455\n",
      "Epoch 3731/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5459 - val_loss: -9.3511\n",
      "Epoch 3732/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.4996 - val_loss: -9.3421\n",
      "Epoch 3733/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.5205 - val_loss: -9.3508\n",
      "Epoch 3734/5000\n",
      "23/23 [==============================] - 4s 178ms/step - loss: -9.5627 - val_loss: -9.3460\n",
      "Epoch 3735/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.5423 - val_loss: -9.3411\n",
      "Epoch 3736/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4981 - val_loss: -9.3430\n",
      "Epoch 3737/5000\n",
      "23/23 [==============================] - 6s 259ms/step - loss: -9.5732 - val_loss: -9.3447\n",
      "Epoch 3738/5000\n",
      "23/23 [==============================] - 3s 157ms/step - loss: -9.5411 - val_loss: -9.3534\n",
      "Epoch 3739/5000\n",
      "23/23 [==============================] - 4s 172ms/step - loss: -9.5461 - val_loss: -9.3441\n",
      "Epoch 3740/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.4829 - val_loss: -9.3477\n",
      "Epoch 3741/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.5189 - val_loss: -9.3488\n",
      "Epoch 3742/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.5226 - val_loss: -9.3404\n",
      "Epoch 3743/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5080 - val_loss: -9.3497\n",
      "Epoch 3744/5000\n",
      "23/23 [==============================] - 4s 169ms/step - loss: -9.5286 - val_loss: -9.3439\n",
      "Epoch 3745/5000\n",
      "23/23 [==============================] - 6s 256ms/step - loss: -9.5475 - val_loss: -9.3411\n",
      "Epoch 3746/5000\n",
      "23/23 [==============================] - 5s 245ms/step - loss: -9.5534 - val_loss: -9.3325\n",
      "Epoch 3747/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5089 - val_loss: -9.3482\n",
      "Epoch 3748/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5000 - val_loss: -9.3500\n",
      "Epoch 3749/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5447 - val_loss: -9.3461\n",
      "Epoch 3750/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.5073 - val_loss: -9.3467\n",
      "Epoch 3751/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.4693 - val_loss: -9.3454\n",
      "Epoch 3752/5000\n",
      "23/23 [==============================] - 6s 264ms/step - loss: -9.5052 - val_loss: -9.3432\n",
      "Epoch 3753/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5611 - val_loss: -9.3515\n",
      "Epoch 3754/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.5466 - val_loss: -9.3467\n",
      "Epoch 3755/5000\n",
      "23/23 [==============================] - 5s 240ms/step - loss: -9.5383 - val_loss: -9.3526\n",
      "Epoch 3756/5000\n",
      "23/23 [==============================] - 3s 120ms/step - loss: -9.4905 - val_loss: -9.3512\n",
      "Epoch 3757/5000\n",
      "23/23 [==============================] - 3s 116ms/step - loss: -9.5335 - val_loss: -9.3398\n",
      "Epoch 3758/5000\n",
      "23/23 [==============================] - 3s 119ms/step - loss: -9.5304 - val_loss: -9.3444\n",
      "Epoch 3759/5000\n",
      "23/23 [==============================] - 4s 163ms/step - loss: -9.5222 - val_loss: -9.3582\n",
      "Epoch 3760/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.5004 - val_loss: -9.3424\n",
      "Epoch 3761/5000\n",
      "23/23 [==============================] - 4s 203ms/step - loss: -9.5664 - val_loss: -9.3441\n",
      "Epoch 3762/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.5404 - val_loss: -9.3499\n",
      "Epoch 3763/5000\n",
      "23/23 [==============================] - 3s 144ms/step - loss: -9.5348 - val_loss: -9.3504\n",
      "Epoch 3764/5000\n",
      "23/23 [==============================] - 6s 260ms/step - loss: -9.5197 - val_loss: -9.3537\n",
      "Epoch 3765/5000\n",
      "23/23 [==============================] - 3s 144ms/step - loss: -9.5273 - val_loss: -9.3549\n",
      "Epoch 3766/5000\n",
      "23/23 [==============================] - 3s 121ms/step - loss: -9.5396 - val_loss: -9.3494\n",
      "Epoch 3767/5000\n",
      "23/23 [==============================] - 3s 145ms/step - loss: -9.5307 - val_loss: -9.3545\n",
      "Epoch 3768/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.5657 - val_loss: -9.3539\n",
      "Epoch 3769/5000\n",
      "23/23 [==============================] - 5s 246ms/step - loss: -9.5562 - val_loss: -9.3468\n",
      "Epoch 3770/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.5418 - val_loss: -9.3543\n",
      "Epoch 3771/5000\n",
      "23/23 [==============================] - 4s 200ms/step - loss: -9.5558 - val_loss: -9.3528\n",
      "Epoch 3772/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -9.5654 - val_loss: -9.3440\n",
      "Epoch 3773/5000\n",
      "23/23 [==============================] - 4s 189ms/step - loss: -9.4979 - val_loss: -9.3474\n",
      "Epoch 3774/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.5526 - val_loss: -9.3566\n",
      "Epoch 3775/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5116 - val_loss: -9.3390\n",
      "Epoch 3776/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.5412 - val_loss: -9.3478\n",
      "Epoch 3777/5000\n",
      "23/23 [==============================] - 2s 110ms/step - loss: -9.5294 - val_loss: -9.3470\n",
      "Epoch 3778/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5344 - val_loss: -9.3600\n",
      "Epoch 3779/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -9.5311 - val_loss: -9.3550\n",
      "Epoch 3780/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.5429 - val_loss: -9.3576\n",
      "Epoch 3781/5000\n",
      "23/23 [==============================] - 5s 215ms/step - loss: -9.5355 - val_loss: -9.3569\n",
      "Epoch 3782/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.5294 - val_loss: -9.3479\n",
      "Epoch 3783/5000\n",
      "23/23 [==============================] - 6s 251ms/step - loss: -9.5390 - val_loss: -9.3548\n",
      "Epoch 3784/5000\n",
      "23/23 [==============================] - 6s 251ms/step - loss: -9.5459 - val_loss: -9.3487\n",
      "Epoch 3785/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.5170 - val_loss: -9.3436\n",
      "Epoch 3786/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.4935 - val_loss: -9.3517\n",
      "Epoch 3787/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5223 - val_loss: -9.3566\n",
      "Epoch 3788/5000\n",
      "23/23 [==============================] - 4s 199ms/step - loss: -9.5546 - val_loss: -9.3533\n",
      "Epoch 3789/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -9.5298 - val_loss: -9.3433\n",
      "Epoch 3790/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.5381 - val_loss: -9.3553\n",
      "Epoch 3791/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.5509 - val_loss: -9.3534\n",
      "Epoch 3792/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5345 - val_loss: -9.3498\n",
      "Epoch 3793/5000\n",
      "23/23 [==============================] - 4s 176ms/step - loss: -9.5146 - val_loss: -9.3663\n",
      "Epoch 3794/5000\n",
      "23/23 [==============================] - 3s 135ms/step - loss: -9.5354 - val_loss: -9.3482\n",
      "Epoch 3795/5000\n",
      "23/23 [==============================] - 4s 192ms/step - loss: -9.5298 - val_loss: -9.3469\n",
      "Epoch 3796/5000\n",
      "23/23 [==============================] - 3s 136ms/step - loss: -9.5178 - val_loss: -9.3555\n",
      "Epoch 3797/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.5694 - val_loss: -9.3523\n",
      "Epoch 3798/5000\n",
      "23/23 [==============================] - 6s 253ms/step - loss: -9.4733 - val_loss: -9.3509\n",
      "Epoch 3799/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.5437 - val_loss: -9.3558\n",
      "Epoch 3800/5000\n",
      "23/23 [==============================] - 4s 179ms/step - loss: -9.5754 - val_loss: -9.3532\n",
      "Epoch 3801/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5405 - val_loss: -9.3539\n",
      "Epoch 3802/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.5539 - val_loss: -9.3488\n",
      "Epoch 3803/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5264 - val_loss: -9.3565\n",
      "Epoch 3804/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -9.5457 - val_loss: -9.3521\n",
      "Epoch 3805/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5258 - val_loss: -9.3489\n",
      "Epoch 3806/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.5247 - val_loss: -9.3504\n",
      "Epoch 3807/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.5245 - val_loss: -9.3531\n",
      "Epoch 3808/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5273 - val_loss: -9.3540\n",
      "Epoch 3809/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.5500 - val_loss: -9.3555\n",
      "Epoch 3810/5000\n",
      "23/23 [==============================] - 4s 197ms/step - loss: -9.5290 - val_loss: -9.3552\n",
      "Epoch 3811/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.5644 - val_loss: -9.3540\n",
      "Epoch 3812/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.4874 - val_loss: -9.3459\n",
      "Epoch 3813/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5302 - val_loss: -9.3530\n",
      "Epoch 3814/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.5495 - val_loss: -9.3477\n",
      "Epoch 3815/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5054 - val_loss: -9.3505\n",
      "Epoch 3816/5000\n",
      "23/23 [==============================] - 6s 265ms/step - loss: -9.5518 - val_loss: -9.3553\n",
      "Epoch 3817/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.4903 - val_loss: -9.3541\n",
      "Epoch 3818/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.5668 - val_loss: -9.3573\n",
      "Epoch 3819/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.5358 - val_loss: -9.3594\n",
      "Epoch 3820/5000\n",
      "23/23 [==============================] - 6s 262ms/step - loss: -9.5153 - val_loss: -9.3579\n",
      "Epoch 3821/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5306 - val_loss: -9.3595\n",
      "Epoch 3822/5000\n",
      "23/23 [==============================] - 4s 163ms/step - loss: -9.5126 - val_loss: -9.3566\n",
      "Epoch 3823/5000\n",
      "23/23 [==============================] - 5s 249ms/step - loss: -9.5226 - val_loss: -9.3502\n",
      "Epoch 3824/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.5623 - val_loss: -9.3550\n",
      "Epoch 3825/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.5445 - val_loss: -9.3626\n",
      "Epoch 3826/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.5349 - val_loss: -9.3591\n",
      "Epoch 3827/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.5543 - val_loss: -9.3536\n",
      "Epoch 3828/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.5623 - val_loss: -9.3463\n",
      "Epoch 3829/5000\n",
      "23/23 [==============================] - 3s 119ms/step - loss: -9.5381 - val_loss: -9.3560\n",
      "Epoch 3830/5000\n",
      "23/23 [==============================] - 5s 247ms/step - loss: -9.5277 - val_loss: -9.3605\n",
      "Epoch 3831/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.4793 - val_loss: -9.3493\n",
      "Epoch 3832/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -9.5298 - val_loss: -9.3612\n",
      "Epoch 3833/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5436 - val_loss: -9.3560\n",
      "Epoch 3834/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5416 - val_loss: -9.3550\n",
      "Epoch 3835/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.5375 - val_loss: -9.3548\n",
      "Epoch 3836/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.5379 - val_loss: -9.3584\n",
      "Epoch 3837/5000\n",
      "23/23 [==============================] - 4s 173ms/step - loss: -9.4818 - val_loss: -9.3649\n",
      "Epoch 3838/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.5468 - val_loss: -9.3600\n",
      "Epoch 3839/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5495 - val_loss: -9.3558\n",
      "Epoch 3840/5000\n",
      "23/23 [==============================] - 5s 246ms/step - loss: -9.5416 - val_loss: -9.3605\n",
      "Epoch 3841/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.5406 - val_loss: -9.3609\n",
      "Epoch 3842/5000\n",
      "23/23 [==============================] - 3s 135ms/step - loss: -9.5617 - val_loss: -9.3563\n",
      "Epoch 3843/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.5310 - val_loss: -9.3604\n",
      "Epoch 3844/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -9.5232 - val_loss: -9.3652\n",
      "Epoch 3845/5000\n",
      "23/23 [==============================] - 3s 131ms/step - loss: -9.5658 - val_loss: -9.3576\n",
      "Epoch 3846/5000\n",
      "23/23 [==============================] - 3s 136ms/step - loss: -9.5305 - val_loss: -9.3481\n",
      "Epoch 3847/5000\n",
      "23/23 [==============================] - 3s 143ms/step - loss: -9.5288 - val_loss: -9.3651\n",
      "Epoch 3848/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5199 - val_loss: -9.3542\n",
      "Epoch 3849/5000\n",
      "23/23 [==============================] - 5s 220ms/step - loss: -9.5364 - val_loss: -9.3614\n",
      "Epoch 3850/5000\n",
      "23/23 [==============================] - 6s 258ms/step - loss: -9.5672 - val_loss: -9.3528\n",
      "Epoch 3851/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.5120 - val_loss: -9.3527\n",
      "Epoch 3852/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.5394 - val_loss: -9.3613\n",
      "Epoch 3853/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5243 - val_loss: -9.3575\n",
      "Epoch 3854/5000\n",
      "23/23 [==============================] - 3s 116ms/step - loss: -9.5542 - val_loss: -9.3579\n",
      "Epoch 3855/5000\n",
      "23/23 [==============================] - 5s 207ms/step - loss: -9.5310 - val_loss: -9.3628\n",
      "Epoch 3856/5000\n",
      "23/23 [==============================] - 4s 189ms/step - loss: -9.5712 - val_loss: -9.3531\n",
      "Epoch 3857/5000\n",
      "23/23 [==============================] - 5s 217ms/step - loss: -9.5311 - val_loss: -9.3595\n",
      "Epoch 3858/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.4543 - val_loss: -9.3553\n",
      "Epoch 3859/5000\n",
      "23/23 [==============================] - 5s 215ms/step - loss: -9.5518 - val_loss: -9.3552\n",
      "Epoch 3860/5000\n",
      "23/23 [==============================] - 3s 149ms/step - loss: -9.5481 - val_loss: -9.3546\n",
      "Epoch 3861/5000\n",
      "23/23 [==============================] - 6s 253ms/step - loss: -9.5358 - val_loss: -9.3636\n",
      "Epoch 3862/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.5533 - val_loss: -9.3698\n",
      "Epoch 3863/5000\n",
      "23/23 [==============================] - 5s 211ms/step - loss: -9.5209 - val_loss: -9.3575\n",
      "Epoch 3864/5000\n",
      "23/23 [==============================] - 4s 170ms/step - loss: -9.5364 - val_loss: -9.3584\n",
      "Epoch 3865/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.5370 - val_loss: -9.3683\n",
      "Epoch 3866/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5593 - val_loss: -9.3586\n",
      "Epoch 3867/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5581 - val_loss: -9.3596\n",
      "Epoch 3868/5000\n",
      "23/23 [==============================] - 6s 257ms/step - loss: -9.5600 - val_loss: -9.3515\n",
      "Epoch 3869/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.4901 - val_loss: -9.3661\n",
      "Epoch 3870/5000\n",
      "23/23 [==============================] - 6s 257ms/step - loss: -9.5405 - val_loss: -9.3619\n",
      "Epoch 3871/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.5451 - val_loss: -9.3614\n",
      "Epoch 3872/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -9.5303 - val_loss: -9.3588\n",
      "Epoch 3873/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5738 - val_loss: -9.3673\n",
      "Epoch 3874/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.5699 - val_loss: -9.3651\n",
      "Epoch 3875/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.5455 - val_loss: -9.3634\n",
      "Epoch 3876/5000\n",
      "23/23 [==============================] - 6s 265ms/step - loss: -9.5724 - val_loss: -9.3568\n",
      "Epoch 3877/5000\n",
      "23/23 [==============================] - 6s 255ms/step - loss: -9.4848 - val_loss: -9.3624\n",
      "Epoch 3878/5000\n",
      "23/23 [==============================] - 5s 241ms/step - loss: -9.5653 - val_loss: -9.3690\n",
      "Epoch 3879/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5778 - val_loss: -9.3701\n",
      "Epoch 3880/5000\n",
      "23/23 [==============================] - 4s 180ms/step - loss: -9.5477 - val_loss: -9.3652\n",
      "Epoch 3881/5000\n",
      "23/23 [==============================] - 5s 212ms/step - loss: -9.5309 - val_loss: -9.3697\n",
      "Epoch 3882/5000\n",
      "23/23 [==============================] - 6s 269ms/step - loss: -9.5374 - val_loss: -9.3620\n",
      "Epoch 3883/5000\n",
      "23/23 [==============================] - 3s 143ms/step - loss: -9.5459 - val_loss: -9.3509\n",
      "Epoch 3884/5000\n",
      "23/23 [==============================] - 3s 141ms/step - loss: -9.5546 - val_loss: -9.3482\n",
      "Epoch 3885/5000\n",
      "23/23 [==============================] - 10s 476ms/step - loss: -9.5131 - val_loss: -9.3597\n",
      "Epoch 3886/5000\n",
      "23/23 [==============================] - 3s 118ms/step - loss: -9.5665 - val_loss: -9.3635\n",
      "Epoch 3887/5000\n",
      "23/23 [==============================] - 2s 104ms/step - loss: -9.5421 - val_loss: -9.3613\n",
      "Epoch 3888/5000\n",
      "23/23 [==============================] - 6s 253ms/step - loss: -9.5625 - val_loss: -9.3442\n",
      "Epoch 3889/5000\n",
      "23/23 [==============================] - 4s 163ms/step - loss: -9.5437 - val_loss: -9.3633\n",
      "Epoch 3890/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5326 - val_loss: -9.3691\n",
      "Epoch 3891/5000\n",
      "23/23 [==============================] - 6s 262ms/step - loss: -9.4560 - val_loss: -9.3675\n",
      "Epoch 3892/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5519 - val_loss: -9.3571\n",
      "Epoch 3893/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.5769 - val_loss: -9.3551\n",
      "Epoch 3894/5000\n",
      "23/23 [==============================] - 3s 139ms/step - loss: -9.5690 - val_loss: -9.3612\n",
      "Epoch 3895/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.5449 - val_loss: -9.3631\n",
      "Epoch 3896/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -9.5595 - val_loss: -9.3586\n",
      "Epoch 3897/5000\n",
      "23/23 [==============================] - 6s 261ms/step - loss: -9.5284 - val_loss: -9.3555\n",
      "Epoch 3898/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.5639 - val_loss: -9.3610\n",
      "Epoch 3899/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -9.5287 - val_loss: -9.3655\n",
      "Epoch 3900/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5526 - val_loss: -9.3534\n",
      "Epoch 3901/5000\n",
      "23/23 [==============================] - 3s 132ms/step - loss: -9.5350 - val_loss: -9.3565\n",
      "Epoch 3902/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.5778 - val_loss: -9.3616\n",
      "Epoch 3903/5000\n",
      "23/23 [==============================] - 6s 250ms/step - loss: -9.5375 - val_loss: -9.3644\n",
      "Epoch 3904/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -9.5687 - val_loss: -9.3574\n",
      "Epoch 3905/5000\n",
      "23/23 [==============================] - 5s 246ms/step - loss: -9.5746 - val_loss: -9.3715\n",
      "Epoch 3906/5000\n",
      "23/23 [==============================] - 5s 239ms/step - loss: -9.5586 - val_loss: -9.3721\n",
      "Epoch 3907/5000\n",
      "23/23 [==============================] - 2s 108ms/step - loss: -9.5441 - val_loss: -9.3615\n",
      "Epoch 3908/5000\n",
      "23/23 [==============================] - 3s 119ms/step - loss: -9.5738 - val_loss: -9.3595\n",
      "Epoch 3909/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.5361 - val_loss: -9.3650\n",
      "Epoch 3910/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -9.5306 - val_loss: -9.3589\n",
      "Epoch 3911/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.5648 - val_loss: -9.3496\n",
      "Epoch 3912/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.5334 - val_loss: -9.3660\n",
      "Epoch 3913/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5388 - val_loss: -9.3588\n",
      "Epoch 3914/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5329 - val_loss: -9.3646\n",
      "Epoch 3915/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.5537 - val_loss: -9.3672\n",
      "Epoch 3916/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.5482 - val_loss: -9.3622\n",
      "Epoch 3917/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.5592 - val_loss: -9.3640\n",
      "Epoch 3918/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.5575 - val_loss: -9.3517\n",
      "Epoch 3919/5000\n",
      "23/23 [==============================] - 2s 108ms/step - loss: -9.5570 - val_loss: -9.3684\n",
      "Epoch 3920/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.5394 - val_loss: -9.3717\n",
      "Epoch 3921/5000\n",
      "23/23 [==============================] - 6s 281ms/step - loss: -9.5472 - val_loss: -9.3653\n",
      "Epoch 3922/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5512 - val_loss: -9.3565\n",
      "Epoch 3923/5000\n",
      "23/23 [==============================] - 6s 254ms/step - loss: -9.5865 - val_loss: -9.3689\n",
      "Epoch 3924/5000\n",
      "23/23 [==============================] - 6s 253ms/step - loss: -9.5486 - val_loss: -9.3570\n",
      "Epoch 3925/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.5481 - val_loss: -9.3636\n",
      "Epoch 3926/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.5438 - val_loss: -9.3636\n",
      "Epoch 3927/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5460 - val_loss: -9.3640\n",
      "Epoch 3928/5000\n",
      "23/23 [==============================] - 6s 263ms/step - loss: -9.5748 - val_loss: -9.3629\n",
      "Epoch 3929/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.5441 - val_loss: -9.3593\n",
      "Epoch 3930/5000\n",
      "23/23 [==============================] - 3s 147ms/step - loss: -9.5548 - val_loss: -9.3703\n",
      "Epoch 3931/5000\n",
      "23/23 [==============================] - 3s 114ms/step - loss: -9.5413 - val_loss: -9.3675\n",
      "Epoch 3932/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.5469 - val_loss: -9.3685\n",
      "Epoch 3933/5000\n",
      "23/23 [==============================] - 2s 108ms/step - loss: -9.5478 - val_loss: -9.3680\n",
      "Epoch 3934/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -9.5350 - val_loss: -9.3711\n",
      "Epoch 3935/5000\n",
      "23/23 [==============================] - 5s 224ms/step - loss: -9.4952 - val_loss: -9.3653\n",
      "Epoch 3936/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5470 - val_loss: -9.3571\n",
      "Epoch 3937/5000\n",
      "23/23 [==============================] - 5s 245ms/step - loss: -9.5695 - val_loss: -9.3758\n",
      "Epoch 3938/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.5156 - val_loss: -9.3724\n",
      "Epoch 3939/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.5383 - val_loss: -9.3694\n",
      "Epoch 3940/5000\n",
      "23/23 [==============================] - 2s 113ms/step - loss: -9.5610 - val_loss: -9.3764\n",
      "Epoch 3941/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -9.5545 - val_loss: -9.3689\n",
      "Epoch 3942/5000\n",
      "23/23 [==============================] - 6s 256ms/step - loss: -9.5569 - val_loss: -9.3681\n",
      "Epoch 3943/5000\n",
      "23/23 [==============================] - 5s 206ms/step - loss: -9.5684 - val_loss: -9.3673\n",
      "Epoch 3944/5000\n",
      "23/23 [==============================] - 4s 171ms/step - loss: -9.5593 - val_loss: -9.3657\n",
      "Epoch 3945/5000\n",
      "23/23 [==============================] - 3s 146ms/step - loss: -9.5541 - val_loss: -9.3652\n",
      "Epoch 3946/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.5463 - val_loss: -9.3606\n",
      "Epoch 3947/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5509 - val_loss: -9.3666\n",
      "Epoch 3948/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.5457 - val_loss: -9.3660\n",
      "Epoch 3949/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.5422 - val_loss: -9.3645\n",
      "Epoch 3950/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5876 - val_loss: -9.3678\n",
      "Epoch 3951/5000\n",
      "23/23 [==============================] - 3s 156ms/step - loss: -9.5745 - val_loss: -9.3724\n",
      "Epoch 3952/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.5921 - val_loss: -9.3651\n",
      "Epoch 3953/5000\n",
      "23/23 [==============================] - 4s 160ms/step - loss: -9.5550 - val_loss: -9.3686\n",
      "Epoch 3954/5000\n",
      "23/23 [==============================] - 3s 116ms/step - loss: -9.5523 - val_loss: -9.3635\n",
      "Epoch 3955/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.5635 - val_loss: -9.3595\n",
      "Epoch 3956/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.5688 - val_loss: -9.3672\n",
      "Epoch 3957/5000\n",
      "23/23 [==============================] - 5s 247ms/step - loss: -9.5480 - val_loss: -9.3723\n",
      "Epoch 3958/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.5630 - val_loss: -9.3689\n",
      "Epoch 3959/5000\n",
      "23/23 [==============================] - 6s 263ms/step - loss: -9.5997 - val_loss: -9.3665\n",
      "Epoch 3960/5000\n",
      "23/23 [==============================] - 5s 247ms/step - loss: -9.5798 - val_loss: -9.3649\n",
      "Epoch 3961/5000\n",
      "23/23 [==============================] - 3s 118ms/step - loss: -9.5476 - val_loss: -9.3779\n",
      "Epoch 3962/5000\n",
      "23/23 [==============================] - 3s 133ms/step - loss: -9.5359 - val_loss: -9.3706\n",
      "Epoch 3963/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -9.5754 - val_loss: -9.3641\n",
      "Epoch 3964/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5441 - val_loss: -9.3672\n",
      "Epoch 3965/5000\n",
      "23/23 [==============================] - 4s 171ms/step - loss: -9.5622 - val_loss: -9.3680\n",
      "Epoch 3966/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.5636 - val_loss: -9.3702\n",
      "Epoch 3967/5000\n",
      "23/23 [==============================] - 5s 208ms/step - loss: -9.5353 - val_loss: -9.3693\n",
      "Epoch 3968/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.4976 - val_loss: -9.3730\n",
      "Epoch 3969/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.5503 - val_loss: -9.3649\n",
      "Epoch 3970/5000\n",
      "23/23 [==============================] - 6s 250ms/step - loss: -9.5846 - val_loss: -9.3743\n",
      "Epoch 3971/5000\n",
      "23/23 [==============================] - 5s 233ms/step - loss: -9.5553 - val_loss: -9.3657\n",
      "Epoch 3972/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.5924 - val_loss: -9.3674\n",
      "Epoch 3973/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.5456 - val_loss: -9.3710\n",
      "Epoch 3974/5000\n",
      "23/23 [==============================] - 3s 140ms/step - loss: -9.5674 - val_loss: -9.3666\n",
      "Epoch 3975/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5662 - val_loss: -9.3701\n",
      "Epoch 3976/5000\n",
      "23/23 [==============================] - 3s 149ms/step - loss: -9.5434 - val_loss: -9.3726\n",
      "Epoch 3977/5000\n",
      "23/23 [==============================] - 6s 253ms/step - loss: -9.5270 - val_loss: -9.3752\n",
      "Epoch 3978/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.5597 - val_loss: -9.3673\n",
      "Epoch 3979/5000\n",
      "23/23 [==============================] - 4s 185ms/step - loss: -9.5617 - val_loss: -9.3705\n",
      "Epoch 3980/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.5558 - val_loss: -9.3662\n",
      "Epoch 3981/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.5771 - val_loss: -9.3727\n",
      "Epoch 3982/5000\n",
      "23/23 [==============================] - 5s 240ms/step - loss: -9.5659 - val_loss: -9.3690\n",
      "Epoch 3983/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5646 - val_loss: -9.3728\n",
      "Epoch 3984/5000\n",
      "23/23 [==============================] - 6s 266ms/step - loss: -9.5820 - val_loss: -9.3690\n",
      "Epoch 3985/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.5520 - val_loss: -9.3738\n",
      "Epoch 3986/5000\n",
      "23/23 [==============================] - 3s 154ms/step - loss: -9.5818 - val_loss: -9.3808\n",
      "Epoch 3987/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5804 - val_loss: -9.3752\n",
      "Epoch 3988/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5594 - val_loss: -9.3709\n",
      "Epoch 3989/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5603 - val_loss: -9.3721\n",
      "Epoch 3990/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5303 - val_loss: -9.3752\n",
      "Epoch 3991/5000\n",
      "23/23 [==============================] - 5s 233ms/step - loss: -9.5559 - val_loss: -9.3609\n",
      "Epoch 3992/5000\n",
      "23/23 [==============================] - 6s 256ms/step - loss: -9.5489 - val_loss: -9.3621\n",
      "Epoch 3993/5000\n",
      "23/23 [==============================] - 5s 220ms/step - loss: -9.5775 - val_loss: -9.3714\n",
      "Epoch 3994/5000\n",
      "23/23 [==============================] - 3s 121ms/step - loss: -9.5772 - val_loss: -9.3694\n",
      "Epoch 3995/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5594 - val_loss: -9.3611\n",
      "Epoch 3996/5000\n",
      "23/23 [==============================] - 5s 228ms/step - loss: -9.5755 - val_loss: -9.3692\n",
      "Epoch 3997/5000\n",
      "23/23 [==============================] - 3s 114ms/step - loss: -9.5500 - val_loss: -9.3767\n",
      "Epoch 3998/5000\n",
      "23/23 [==============================] - 5s 227ms/step - loss: -9.5709 - val_loss: -9.3622\n",
      "Epoch 3999/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5204 - val_loss: -9.3648\n",
      "Epoch 4000/5000\n",
      "23/23 [==============================] - 3s 120ms/step - loss: -9.5431 - val_loss: -9.3698\n",
      "Epoch 4001/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.5639 - val_loss: -9.3765\n",
      "Epoch 4002/5000\n",
      "23/23 [==============================] - 4s 167ms/step - loss: -9.5579 - val_loss: -9.3735\n",
      "Epoch 4003/5000\n",
      "23/23 [==============================] - 2s 112ms/step - loss: -9.5969 - val_loss: -9.3671\n",
      "Epoch 4004/5000\n",
      "23/23 [==============================] - 6s 261ms/step - loss: -9.5703 - val_loss: -9.3669\n",
      "Epoch 4005/5000\n",
      "23/23 [==============================] - 3s 132ms/step - loss: -9.5421 - val_loss: -9.3659\n",
      "Epoch 4006/5000\n",
      "23/23 [==============================] - 2s 104ms/step - loss: -9.5828 - val_loss: -9.3704\n",
      "Epoch 4007/5000\n",
      "23/23 [==============================] - 4s 191ms/step - loss: -9.5339 - val_loss: -9.3720\n",
      "Epoch 4008/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5371 - val_loss: -9.3728\n",
      "Epoch 4009/5000\n",
      "23/23 [==============================] - 5s 208ms/step - loss: -9.5708 - val_loss: -9.3784\n",
      "Epoch 4010/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.4883 - val_loss: -9.3653\n",
      "Epoch 4011/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5280 - val_loss: -9.3776\n",
      "Epoch 4012/5000\n",
      "23/23 [==============================] - 5s 233ms/step - loss: -9.5412 - val_loss: -9.3692\n",
      "Epoch 4013/5000\n",
      "23/23 [==============================] - 5s 223ms/step - loss: -9.5689 - val_loss: -9.3701\n",
      "Epoch 4014/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5621 - val_loss: -9.3654\n",
      "Epoch 4015/5000\n",
      "23/23 [==============================] - 4s 202ms/step - loss: -9.5368 - val_loss: -9.3759\n",
      "Epoch 4016/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5526 - val_loss: -9.3717\n",
      "Epoch 4017/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.5360 - val_loss: -9.3617\n",
      "Epoch 4018/5000\n",
      "23/23 [==============================] - 4s 177ms/step - loss: -9.5689 - val_loss: -9.3690\n",
      "Epoch 4019/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5363 - val_loss: -9.3728\n",
      "Epoch 4020/5000\n",
      "23/23 [==============================] - 5s 231ms/step - loss: -9.5843 - val_loss: -9.3679\n",
      "Epoch 4021/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.5334 - val_loss: -9.3706\n",
      "Epoch 4022/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.5545 - val_loss: -9.3710\n",
      "Epoch 4023/5000\n",
      "23/23 [==============================] - 5s 232ms/step - loss: -9.5877 - val_loss: -9.3779\n",
      "Epoch 4024/5000\n",
      "23/23 [==============================] - 6s 254ms/step - loss: -9.5529 - val_loss: -9.3748\n",
      "Epoch 4025/5000\n",
      "23/23 [==============================] - 6s 259ms/step - loss: -9.5413 - val_loss: -9.3708\n",
      "Epoch 4026/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5618 - val_loss: -9.3733\n",
      "Epoch 4027/5000\n",
      "23/23 [==============================] - 5s 231ms/step - loss: -9.5803 - val_loss: -9.3701\n",
      "Epoch 4028/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.5495 - val_loss: -9.3744\n",
      "Epoch 4029/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.5472 - val_loss: -9.3697\n",
      "Epoch 4030/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.5402 - val_loss: -9.3765\n",
      "Epoch 4031/5000\n",
      "23/23 [==============================] - 4s 190ms/step - loss: -9.5635 - val_loss: -9.3726\n",
      "Epoch 4032/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.5728 - val_loss: -9.3744\n",
      "Epoch 4033/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.5791 - val_loss: -9.3691\n",
      "Epoch 4034/5000\n",
      "23/23 [==============================] - 3s 157ms/step - loss: -9.5944 - val_loss: -9.3792\n",
      "Epoch 4035/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5420 - val_loss: -9.3686\n",
      "Epoch 4036/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.5557 - val_loss: -9.3725\n",
      "Epoch 4037/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5566 - val_loss: -9.3714\n",
      "Epoch 4038/5000\n",
      "23/23 [==============================] - 2s 112ms/step - loss: -9.5057 - val_loss: -9.3696\n",
      "Epoch 4039/5000\n",
      "23/23 [==============================] - 5s 205ms/step - loss: -9.5507 - val_loss: -9.3653\n",
      "Epoch 4040/5000\n",
      "23/23 [==============================] - 4s 201ms/step - loss: -9.5655 - val_loss: -9.3818\n",
      "Epoch 4041/5000\n",
      "23/23 [==============================] - 4s 168ms/step - loss: -9.5721 - val_loss: -9.3720\n",
      "Epoch 4042/5000\n",
      "23/23 [==============================] - 4s 167ms/step - loss: -9.5713 - val_loss: -9.3709\n",
      "Epoch 4043/5000\n",
      "23/23 [==============================] - 3s 136ms/step - loss: -9.5536 - val_loss: -9.3730\n",
      "Epoch 4044/5000\n",
      "23/23 [==============================] - 5s 238ms/step - loss: -9.5586 - val_loss: -9.3820\n",
      "Epoch 4045/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5920 - val_loss: -9.3801\n",
      "Epoch 4046/5000\n",
      "23/23 [==============================] - 5s 240ms/step - loss: -9.5751 - val_loss: -9.3765\n",
      "Epoch 4047/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.5625 - val_loss: -9.3686\n",
      "Epoch 4048/5000\n",
      "23/23 [==============================] - 3s 133ms/step - loss: -9.5215 - val_loss: -9.3821\n",
      "Epoch 4049/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.5463 - val_loss: -9.3785\n",
      "Epoch 4050/5000\n",
      "23/23 [==============================] - 4s 169ms/step - loss: -9.5712 - val_loss: -9.3765\n",
      "Epoch 4051/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5520 - val_loss: -9.3683\n",
      "Epoch 4052/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5521 - val_loss: -9.3804\n",
      "Epoch 4053/5000\n",
      "23/23 [==============================] - 3s 140ms/step - loss: -9.5696 - val_loss: -9.3855\n",
      "Epoch 4054/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.5441 - val_loss: -9.3796\n",
      "Epoch 4055/5000\n",
      "23/23 [==============================] - 4s 180ms/step - loss: -9.5559 - val_loss: -9.3780\n",
      "Epoch 4056/5000\n",
      "23/23 [==============================] - 3s 148ms/step - loss: -9.5747 - val_loss: -9.3780\n",
      "Epoch 4057/5000\n",
      "23/23 [==============================] - 2s 104ms/step - loss: -9.5841 - val_loss: -9.3820\n",
      "Epoch 4058/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5718 - val_loss: -9.3798\n",
      "Epoch 4059/5000\n",
      "23/23 [==============================] - 5s 247ms/step - loss: -9.5546 - val_loss: -9.3788\n",
      "Epoch 4060/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5463 - val_loss: -9.3761\n",
      "Epoch 4061/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.5830 - val_loss: -9.3740\n",
      "Epoch 4062/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.5418 - val_loss: -9.3777\n",
      "Epoch 4063/5000\n",
      "23/23 [==============================] - 5s 204ms/step - loss: -9.5646 - val_loss: -9.3804\n",
      "Epoch 4064/5000\n",
      "23/23 [==============================] - 5s 237ms/step - loss: -9.5382 - val_loss: -9.3739\n",
      "Epoch 4065/5000\n",
      "23/23 [==============================] - 5s 246ms/step - loss: -9.5480 - val_loss: -9.3780\n",
      "Epoch 4066/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5789 - val_loss: -9.3750\n",
      "Epoch 4067/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.5600 - val_loss: -9.3755\n",
      "Epoch 4068/5000\n",
      "23/23 [==============================] - 4s 169ms/step - loss: -9.5723 - val_loss: -9.3733\n",
      "Epoch 4069/5000\n",
      "23/23 [==============================] - 5s 231ms/step - loss: -9.5690 - val_loss: -9.3782\n",
      "Epoch 4070/5000\n",
      "23/23 [==============================] - 5s 249ms/step - loss: -9.5742 - val_loss: -9.3756\n",
      "Epoch 4071/5000\n",
      "23/23 [==============================] - 2s 113ms/step - loss: -9.5256 - val_loss: -9.3757\n",
      "Epoch 4072/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.5388 - val_loss: -9.3823\n",
      "Epoch 4073/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5671 - val_loss: -9.3795\n",
      "Epoch 4074/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5221 - val_loss: -9.3795\n",
      "Epoch 4075/5000\n",
      "23/23 [==============================] - 3s 139ms/step - loss: -9.5477 - val_loss: -9.3819\n",
      "Epoch 4076/5000\n",
      "23/23 [==============================] - 3s 134ms/step - loss: -9.5680 - val_loss: -9.3760\n",
      "Epoch 4077/5000\n",
      "23/23 [==============================] - 5s 240ms/step - loss: -9.6047 - val_loss: -9.3721\n",
      "Epoch 4078/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5774 - val_loss: -9.3777\n",
      "Epoch 4079/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5713 - val_loss: -9.3723\n",
      "Epoch 4080/5000\n",
      "23/23 [==============================] - 5s 240ms/step - loss: -9.5700 - val_loss: -9.3726\n",
      "Epoch 4081/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.5575 - val_loss: -9.3804\n",
      "Epoch 4082/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -9.5416 - val_loss: -9.3839\n",
      "Epoch 4083/5000\n",
      "23/23 [==============================] - 4s 166ms/step - loss: -9.5412 - val_loss: -9.3789\n",
      "Epoch 4084/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.5740 - val_loss: -9.3823\n",
      "Epoch 4085/5000\n",
      "23/23 [==============================] - 3s 114ms/step - loss: -9.5831 - val_loss: -9.3791\n",
      "Epoch 4086/5000\n",
      "23/23 [==============================] - 4s 166ms/step - loss: -9.5587 - val_loss: -9.3747\n",
      "Epoch 4087/5000\n",
      "23/23 [==============================] - 4s 168ms/step - loss: -9.5621 - val_loss: -9.3775\n",
      "Epoch 4088/5000\n",
      "23/23 [==============================] - 5s 222ms/step - loss: -9.5363 - val_loss: -9.3742\n",
      "Epoch 4089/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5968 - val_loss: -9.3779\n",
      "Epoch 4090/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.5687 - val_loss: -9.3801\n",
      "Epoch 4091/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.5035 - val_loss: -9.3788\n",
      "Epoch 4092/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5557 - val_loss: -9.3740\n",
      "Epoch 4093/5000\n",
      "23/23 [==============================] - 4s 177ms/step - loss: -9.5728 - val_loss: -9.3862\n",
      "Epoch 4094/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -9.5694 - val_loss: -9.3770\n",
      "Epoch 4095/5000\n",
      "23/23 [==============================] - 3s 115ms/step - loss: -9.5743 - val_loss: -9.3830\n",
      "Epoch 4096/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.5692 - val_loss: -9.3733\n",
      "Epoch 4097/5000\n",
      "23/23 [==============================] - 3s 114ms/step - loss: -9.5448 - val_loss: -9.3853\n",
      "Epoch 4098/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5671 - val_loss: -9.3853\n",
      "Epoch 4099/5000\n",
      "23/23 [==============================] - 5s 205ms/step - loss: -9.5778 - val_loss: -9.3829\n",
      "Epoch 4100/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.5775 - val_loss: -9.3772\n",
      "Epoch 4101/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.5667 - val_loss: -9.3813\n",
      "Epoch 4102/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.5435 - val_loss: -9.3813\n",
      "Epoch 4103/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5393 - val_loss: -9.3805\n",
      "Epoch 4104/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.5960 - val_loss: -9.3750\n",
      "Epoch 4105/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.5786 - val_loss: -9.3818\n",
      "Epoch 4106/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.5584 - val_loss: -9.3863\n",
      "Epoch 4107/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.5616 - val_loss: -9.3814\n",
      "Epoch 4108/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.5377 - val_loss: -9.3773\n",
      "Epoch 4109/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.5594 - val_loss: -9.3755\n",
      "Epoch 4110/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.6002 - val_loss: -9.3863\n",
      "Epoch 4111/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -9.5709 - val_loss: -9.3804\n",
      "Epoch 4112/5000\n",
      "23/23 [==============================] - 3s 115ms/step - loss: -9.5378 - val_loss: -9.3781\n",
      "Epoch 4113/5000\n",
      "23/23 [==============================] - 5s 240ms/step - loss: -9.5676 - val_loss: -9.3788\n",
      "Epoch 4114/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -9.5943 - val_loss: -9.3786\n",
      "Epoch 4115/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.5578 - val_loss: -9.3797\n",
      "Epoch 4116/5000\n",
      "23/23 [==============================] - 4s 170ms/step - loss: -9.5743 - val_loss: -9.3750\n",
      "Epoch 4117/5000\n",
      "23/23 [==============================] - 3s 117ms/step - loss: -9.5514 - val_loss: -9.3852\n",
      "Epoch 4118/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.5393 - val_loss: -9.3655\n",
      "Epoch 4119/5000\n",
      "23/23 [==============================] - 4s 179ms/step - loss: -9.5482 - val_loss: -9.3863\n",
      "Epoch 4120/5000\n",
      "23/23 [==============================] - 3s 158ms/step - loss: -9.5492 - val_loss: -9.3707\n",
      "Epoch 4121/5000\n",
      "23/23 [==============================] - 4s 176ms/step - loss: -9.5748 - val_loss: -9.3791\n",
      "Epoch 4122/5000\n",
      "23/23 [==============================] - 5s 246ms/step - loss: -9.5908 - val_loss: -9.3730\n",
      "Epoch 4123/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -9.5715 - val_loss: -9.3852\n",
      "Epoch 4124/5000\n",
      "23/23 [==============================] - 2s 109ms/step - loss: -9.5609 - val_loss: -9.3788\n",
      "Epoch 4125/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5602 - val_loss: -9.3846\n",
      "Epoch 4126/5000\n",
      "23/23 [==============================] - 3s 138ms/step - loss: -9.5784 - val_loss: -9.3876\n",
      "Epoch 4127/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.5642 - val_loss: -9.3862\n",
      "Epoch 4128/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5448 - val_loss: -9.3849\n",
      "Epoch 4129/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5831 - val_loss: -9.3768\n",
      "Epoch 4130/5000\n",
      "23/23 [==============================] - 4s 166ms/step - loss: -9.5441 - val_loss: -9.3915\n",
      "Epoch 4131/5000\n",
      "23/23 [==============================] - 5s 215ms/step - loss: -9.6008 - val_loss: -9.3867\n",
      "Epoch 4132/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.5425 - val_loss: -9.3797\n",
      "Epoch 4133/5000\n",
      "23/23 [==============================] - 5s 221ms/step - loss: -9.5780 - val_loss: -9.3906\n",
      "Epoch 4134/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.5844 - val_loss: -9.3924\n",
      "Epoch 4135/5000\n",
      "23/23 [==============================] - 5s 245ms/step - loss: -9.5826 - val_loss: -9.3853\n",
      "Epoch 4136/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -9.5641 - val_loss: -9.3854\n",
      "Epoch 4137/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.5658 - val_loss: -9.3731\n",
      "Epoch 4138/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5845 - val_loss: -9.3898\n",
      "Epoch 4139/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.5393 - val_loss: -9.3760\n",
      "Epoch 4140/5000\n",
      "23/23 [==============================] - 3s 146ms/step - loss: -9.5968 - val_loss: -9.3862\n",
      "Epoch 4141/5000\n",
      "23/23 [==============================] - 2s 109ms/step - loss: -9.5718 - val_loss: -9.3864\n",
      "Epoch 4142/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5829 - val_loss: -9.3824\n",
      "Epoch 4143/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -9.5897 - val_loss: -9.3863\n",
      "Epoch 4144/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.5569 - val_loss: -9.3854\n",
      "Epoch 4145/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -9.5809 - val_loss: -9.3893\n",
      "Epoch 4146/5000\n",
      "23/23 [==============================] - 3s 120ms/step - loss: -9.5602 - val_loss: -9.3858\n",
      "Epoch 4147/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.5590 - val_loss: -9.3864\n",
      "Epoch 4148/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.5760 - val_loss: -9.3829\n",
      "Epoch 4149/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.5813 - val_loss: -9.3916\n",
      "Epoch 4150/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.5576 - val_loss: -9.3883\n",
      "Epoch 4151/5000\n",
      "23/23 [==============================] - 2s 112ms/step - loss: -9.5617 - val_loss: -9.3869\n",
      "Epoch 4152/5000\n",
      "23/23 [==============================] - 3s 134ms/step - loss: -9.5321 - val_loss: -9.3809\n",
      "Epoch 4153/5000\n",
      "23/23 [==============================] - 3s 134ms/step - loss: -9.5748 - val_loss: -9.3874\n",
      "Epoch 4154/5000\n",
      "23/23 [==============================] - 5s 246ms/step - loss: -9.5272 - val_loss: -9.3861\n",
      "Epoch 4155/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.5497 - val_loss: -9.3834\n",
      "Epoch 4156/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -9.5954 - val_loss: -9.3860\n",
      "Epoch 4157/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.5703 - val_loss: -9.3902\n",
      "Epoch 4158/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.5661 - val_loss: -9.3911\n",
      "Epoch 4159/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5794 - val_loss: -9.3817\n",
      "Epoch 4160/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -9.5399 - val_loss: -9.3884\n",
      "Epoch 4161/5000\n",
      "23/23 [==============================] - 2s 110ms/step - loss: -9.5846 - val_loss: -9.3826\n",
      "Epoch 4162/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6008 - val_loss: -9.3908\n",
      "Epoch 4163/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.5856 - val_loss: -9.3838\n",
      "Epoch 4164/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -9.5938 - val_loss: -9.3854\n",
      "Epoch 4165/5000\n",
      "23/23 [==============================] - 3s 155ms/step - loss: -9.5501 - val_loss: -9.3789\n",
      "Epoch 4166/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.5831 - val_loss: -9.3707\n",
      "Epoch 4167/5000\n",
      "23/23 [==============================] - 4s 161ms/step - loss: -9.5853 - val_loss: -9.3897\n",
      "Epoch 4168/5000\n",
      "23/23 [==============================] - 4s 192ms/step - loss: -9.5564 - val_loss: -9.3866\n",
      "Epoch 4169/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.5824 - val_loss: -9.3879\n",
      "Epoch 4170/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.5807 - val_loss: -9.3851\n",
      "Epoch 4171/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5885 - val_loss: -9.3843\n",
      "Epoch 4172/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5885 - val_loss: -9.3864\n",
      "Epoch 4173/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5990 - val_loss: -9.3881\n",
      "Epoch 4174/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -9.5771 - val_loss: -9.3864\n",
      "Epoch 4175/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5844 - val_loss: -9.3844\n",
      "Epoch 4176/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.5791 - val_loss: -9.3896\n",
      "Epoch 4177/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5805 - val_loss: -9.3832\n",
      "Epoch 4178/5000\n",
      "23/23 [==============================] - 3s 148ms/step - loss: -9.5816 - val_loss: -9.3850\n",
      "Epoch 4179/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.5802 - val_loss: -9.3942\n",
      "Epoch 4180/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.5690 - val_loss: -9.3908\n",
      "Epoch 4181/5000\n",
      "23/23 [==============================] - 3s 120ms/step - loss: -9.5669 - val_loss: -9.3920\n",
      "Epoch 4182/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.6006 - val_loss: -9.3880\n",
      "Epoch 4183/5000\n",
      "23/23 [==============================] - 3s 121ms/step - loss: -9.4933 - val_loss: -9.3903\n",
      "Epoch 4184/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5675 - val_loss: -9.3816\n",
      "Epoch 4185/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.5753 - val_loss: -9.3836\n",
      "Epoch 4186/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5645 - val_loss: -9.3777\n",
      "Epoch 4187/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5892 - val_loss: -9.3941\n",
      "Epoch 4188/5000\n",
      "23/23 [==============================] - 2s 113ms/step - loss: -9.5900 - val_loss: -9.3873\n",
      "Epoch 4189/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5737 - val_loss: -9.3908\n",
      "Epoch 4190/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5895 - val_loss: -9.3872\n",
      "Epoch 4191/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.5529 - val_loss: -9.3767\n",
      "Epoch 4192/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.5600 - val_loss: -9.3852\n",
      "Epoch 4193/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.5868 - val_loss: -9.3881\n",
      "Epoch 4194/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5380 - val_loss: -9.3924\n",
      "Epoch 4195/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5696 - val_loss: -9.3853\n",
      "Epoch 4196/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5665 - val_loss: -9.3871\n",
      "Epoch 4197/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.6079 - val_loss: -9.3886\n",
      "Epoch 4198/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.5987 - val_loss: -9.3871\n",
      "Epoch 4199/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5926 - val_loss: -9.3920\n",
      "Epoch 4200/5000\n",
      "23/23 [==============================] - 5s 245ms/step - loss: -9.5784 - val_loss: -9.3938\n",
      "Epoch 4201/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.5506 - val_loss: -9.3875\n",
      "Epoch 4202/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6068 - val_loss: -9.3894\n",
      "Epoch 4203/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -9.5782 - val_loss: -9.3853\n",
      "Epoch 4204/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.6015 - val_loss: -9.3891\n",
      "Epoch 4205/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.5569 - val_loss: -9.3805\n",
      "Epoch 4206/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -9.5724 - val_loss: -9.3928\n",
      "Epoch 4207/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.5689 - val_loss: -9.3953\n",
      "Epoch 4208/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.5849 - val_loss: -9.3914\n",
      "Epoch 4209/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.5878 - val_loss: -9.3854\n",
      "Epoch 4210/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -9.6022 - val_loss: -9.3834\n",
      "Epoch 4211/5000\n",
      "23/23 [==============================] - 4s 162ms/step - loss: -9.5662 - val_loss: -9.3902\n",
      "Epoch 4212/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -9.5768 - val_loss: -9.3959\n",
      "Epoch 4213/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5860 - val_loss: -9.3923\n",
      "Epoch 4214/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.5898 - val_loss: -9.3940\n",
      "Epoch 4215/5000\n",
      "23/23 [==============================] - 2s 110ms/step - loss: -9.5562 - val_loss: -9.3796\n",
      "Epoch 4216/5000\n",
      "23/23 [==============================] - 5s 232ms/step - loss: -9.5866 - val_loss: -9.3945\n",
      "Epoch 4217/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.6035 - val_loss: -9.3878\n",
      "Epoch 4218/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.5823 - val_loss: -9.3943\n",
      "Epoch 4219/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.5747 - val_loss: -9.3876\n",
      "Epoch 4220/5000\n",
      "23/23 [==============================] - 3s 114ms/step - loss: -9.5855 - val_loss: -9.3949\n",
      "Epoch 4221/5000\n",
      "23/23 [==============================] - 3s 142ms/step - loss: -9.5713 - val_loss: -9.3844\n",
      "Epoch 4222/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5834 - val_loss: -9.3908\n",
      "Epoch 4223/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5637 - val_loss: -9.3827\n",
      "Epoch 4224/5000\n",
      "23/23 [==============================] - 5s 249ms/step - loss: -9.5607 - val_loss: -9.3947\n",
      "Epoch 4225/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -9.5646 - val_loss: -9.3975\n",
      "Epoch 4226/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.6075 - val_loss: -9.3905\n",
      "Epoch 4227/5000\n",
      "23/23 [==============================] - 4s 161ms/step - loss: -9.5480 - val_loss: -9.3828\n",
      "Epoch 4228/5000\n",
      "23/23 [==============================] - 5s 212ms/step - loss: -9.5740 - val_loss: -9.3881\n",
      "Epoch 4229/5000\n",
      "23/23 [==============================] - 4s 199ms/step - loss: -9.5679 - val_loss: -9.3973\n",
      "Epoch 4230/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -9.5138 - val_loss: -9.3907\n",
      "Epoch 4231/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5288 - val_loss: -9.3944\n",
      "Epoch 4232/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5721 - val_loss: -9.3927\n",
      "Epoch 4233/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6009 - val_loss: -9.3915\n",
      "Epoch 4234/5000\n",
      "23/23 [==============================] - 3s 136ms/step - loss: -9.5815 - val_loss: -9.3918\n",
      "Epoch 4235/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.6006 - val_loss: -9.3951\n",
      "Epoch 4236/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -9.6019 - val_loss: -9.3918\n",
      "Epoch 4237/5000\n",
      "23/23 [==============================] - 5s 223ms/step - loss: -9.5748 - val_loss: -9.3975\n",
      "Epoch 4238/5000\n",
      "23/23 [==============================] - 5s 235ms/step - loss: -9.5914 - val_loss: -9.3930\n",
      "Epoch 4239/5000\n",
      "23/23 [==============================] - 5s 225ms/step - loss: -9.5652 - val_loss: -9.3943\n",
      "Epoch 4240/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.6011 - val_loss: -9.3906\n",
      "Epoch 4241/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.5870 - val_loss: -9.3915\n",
      "Epoch 4242/5000\n",
      "23/23 [==============================] - 5s 206ms/step - loss: -9.5693 - val_loss: -9.3955\n",
      "Epoch 4243/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -9.5753 - val_loss: -9.3911\n",
      "Epoch 4244/5000\n",
      "23/23 [==============================] - 4s 184ms/step - loss: -9.5335 - val_loss: -9.3901\n",
      "Epoch 4245/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -9.5744 - val_loss: -9.3938\n",
      "Epoch 4246/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5961 - val_loss: -9.3946\n",
      "Epoch 4247/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5842 - val_loss: -9.3890\n",
      "Epoch 4248/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.5716 - val_loss: -9.3879\n",
      "Epoch 4249/5000\n",
      "23/23 [==============================] - 4s 192ms/step - loss: -9.5786 - val_loss: -9.3930\n",
      "Epoch 4250/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.5890 - val_loss: -9.3882\n",
      "Epoch 4251/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -9.5758 - val_loss: -9.3886\n",
      "Epoch 4252/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -9.5788 - val_loss: -9.3955\n",
      "Epoch 4253/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -9.6159 - val_loss: -9.3933\n",
      "Epoch 4254/5000\n",
      "23/23 [==============================] - 6s 252ms/step - loss: -9.5934 - val_loss: -9.3870\n",
      "Epoch 4255/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -9.5699 - val_loss: -9.3931\n",
      "Epoch 4256/5000\n",
      "23/23 [==============================] - 2s 108ms/step - loss: -9.5821 - val_loss: -9.3940\n",
      "Epoch 4257/5000\n",
      "23/23 [==============================] - 6s 264ms/step - loss: -9.5829 - val_loss: -9.3988\n",
      "Epoch 4258/5000\n",
      "23/23 [==============================] - 6s 253ms/step - loss: -9.5728 - val_loss: -9.4003\n",
      "Epoch 4259/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.5851 - val_loss: -9.3979\n",
      "Epoch 4260/5000\n",
      "23/23 [==============================] - 6s 281ms/step - loss: -9.5751 - val_loss: -9.3925\n",
      "Epoch 4261/5000\n",
      "23/23 [==============================] - 3s 118ms/step - loss: -9.5528 - val_loss: -9.3984\n",
      "Epoch 4262/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -9.6173 - val_loss: -9.3975\n",
      "Epoch 4263/5000\n",
      "23/23 [==============================] - 3s 148ms/step - loss: -9.5992 - val_loss: -9.3889\n",
      "Epoch 4264/5000\n",
      "23/23 [==============================] - 4s 184ms/step - loss: -9.5828 - val_loss: -9.3914\n",
      "Epoch 4265/5000\n",
      "23/23 [==============================] - 4s 169ms/step - loss: -9.5945 - val_loss: -9.3922\n",
      "Epoch 4266/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -9.5686 - val_loss: -9.3914\n",
      "Epoch 4267/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.5831 - val_loss: -9.3914\n",
      "Epoch 4268/5000\n",
      "23/23 [==============================] - 3s 136ms/step - loss: -9.5551 - val_loss: -9.3980\n",
      "Epoch 4269/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.5903 - val_loss: -9.3892\n",
      "Epoch 4270/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.5355 - val_loss: -9.3957\n",
      "Epoch 4271/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5660 - val_loss: -9.3899\n",
      "Epoch 4272/5000\n",
      "23/23 [==============================] - 4s 190ms/step - loss: -9.5740 - val_loss: -9.3894\n",
      "Epoch 4273/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5938 - val_loss: -9.3890\n",
      "Epoch 4274/5000\n",
      "23/23 [==============================] - 4s 159ms/step - loss: -9.6018 - val_loss: -9.3936\n",
      "Epoch 4275/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5901 - val_loss: -9.3969\n",
      "Epoch 4276/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -9.5584 - val_loss: -9.3918\n",
      "Epoch 4277/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -9.5751 - val_loss: -9.3989\n",
      "Epoch 4278/5000\n",
      "23/23 [==============================] - 3s 117ms/step - loss: -9.5931 - val_loss: -9.4028\n",
      "Epoch 4279/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -9.5698 - val_loss: -9.3979\n",
      "Epoch 4280/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6001 - val_loss: -9.3941\n",
      "Epoch 4281/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5741 - val_loss: -9.3895\n",
      "Epoch 4282/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5612 - val_loss: -9.3966\n",
      "Epoch 4283/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6016 - val_loss: -9.4011\n",
      "Epoch 4284/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5696 - val_loss: -9.3954\n",
      "Epoch 4285/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5971 - val_loss: -9.3997\n",
      "Epoch 4286/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.6053 - val_loss: -9.3987\n",
      "Epoch 4287/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -9.6082 - val_loss: -9.3954\n",
      "Epoch 4288/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -9.5897 - val_loss: -9.3968\n",
      "Epoch 4289/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.6136 - val_loss: -9.3976\n",
      "Epoch 4290/5000\n",
      "23/23 [==============================] - 6s 256ms/step - loss: -9.5740 - val_loss: -9.4051\n",
      "Epoch 4291/5000\n",
      "23/23 [==============================] - 6s 270ms/step - loss: -9.6067 - val_loss: -9.3972\n",
      "Epoch 4292/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5707 - val_loss: -9.4001\n",
      "Epoch 4293/5000\n",
      "23/23 [==============================] - 2s 109ms/step - loss: -9.5855 - val_loss: -9.3943\n",
      "Epoch 4294/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5922 - val_loss: -9.3978\n",
      "Epoch 4295/5000\n",
      "23/23 [==============================] - 2s 109ms/step - loss: -9.5743 - val_loss: -9.3997\n",
      "Epoch 4296/5000\n",
      "23/23 [==============================] - 6s 253ms/step - loss: -9.5602 - val_loss: -9.3925\n",
      "Epoch 4297/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6066 - val_loss: -9.3965\n",
      "Epoch 4298/5000\n",
      "23/23 [==============================] - 3s 114ms/step - loss: -9.6034 - val_loss: -9.3914\n",
      "Epoch 4299/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.5748 - val_loss: -9.3987\n",
      "Epoch 4300/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5657 - val_loss: -9.3970\n",
      "Epoch 4301/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.6027 - val_loss: -9.3959\n",
      "Epoch 4302/5000\n",
      "23/23 [==============================] - 4s 171ms/step - loss: -9.5926 - val_loss: -9.3991\n",
      "Epoch 4303/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.6099 - val_loss: -9.3958\n",
      "Epoch 4304/5000\n",
      "23/23 [==============================] - 5s 241ms/step - loss: -9.6052 - val_loss: -9.3967\n",
      "Epoch 4305/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.5781 - val_loss: -9.3952\n",
      "Epoch 4306/5000\n",
      "23/23 [==============================] - 3s 143ms/step - loss: -9.5928 - val_loss: -9.3940\n",
      "Epoch 4307/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6031 - val_loss: -9.3977\n",
      "Epoch 4308/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.5657 - val_loss: -9.3979\n",
      "Epoch 4309/5000\n",
      "23/23 [==============================] - 4s 160ms/step - loss: -9.6160 - val_loss: -9.3910\n",
      "Epoch 4310/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.5577 - val_loss: -9.3923\n",
      "Epoch 4311/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5709 - val_loss: -9.4057\n",
      "Epoch 4312/5000\n",
      "23/23 [==============================] - 3s 120ms/step - loss: -9.5990 - val_loss: -9.3996\n",
      "Epoch 4313/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.5593 - val_loss: -9.3923\n",
      "Epoch 4314/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5679 - val_loss: -9.4005\n",
      "Epoch 4315/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.5825 - val_loss: -9.3969\n",
      "Epoch 4316/5000\n",
      "23/23 [==============================] - 3s 134ms/step - loss: -9.5811 - val_loss: -9.3930\n",
      "Epoch 4317/5000\n",
      "23/23 [==============================] - 5s 245ms/step - loss: -9.6091 - val_loss: -9.4032\n",
      "Epoch 4318/5000\n",
      "23/23 [==============================] - 3s 138ms/step - loss: -9.5644 - val_loss: -9.3938\n",
      "Epoch 4319/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.5816 - val_loss: -9.3964\n",
      "Epoch 4320/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.5833 - val_loss: -9.3906\n",
      "Epoch 4321/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.6123 - val_loss: -9.3958\n",
      "Epoch 4322/5000\n",
      "23/23 [==============================] - 3s 116ms/step - loss: -9.6067 - val_loss: -9.3958\n",
      "Epoch 4323/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.5631 - val_loss: -9.3929\n",
      "Epoch 4324/5000\n",
      "23/23 [==============================] - 4s 177ms/step - loss: -9.4984 - val_loss: -9.3987\n",
      "Epoch 4325/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -9.5942 - val_loss: -9.3964\n",
      "Epoch 4326/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.5786 - val_loss: -9.3927\n",
      "Epoch 4327/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.6017 - val_loss: -9.4006\n",
      "Epoch 4328/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.5810 - val_loss: -9.3955\n",
      "Epoch 4329/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.6017 - val_loss: -9.4012\n",
      "Epoch 4330/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.5749 - val_loss: -9.4000\n",
      "Epoch 4331/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5938 - val_loss: -9.4002\n",
      "Epoch 4332/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.5682 - val_loss: -9.3986\n",
      "Epoch 4333/5000\n",
      "23/23 [==============================] - 3s 137ms/step - loss: -9.6010 - val_loss: -9.3995\n",
      "Epoch 4334/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.5754 - val_loss: -9.4023\n",
      "Epoch 4335/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.5993 - val_loss: -9.4021\n",
      "Epoch 4336/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.5855 - val_loss: -9.4007\n",
      "Epoch 4337/5000\n",
      "23/23 [==============================] - 5s 214ms/step - loss: -9.5925 - val_loss: -9.4041\n",
      "Epoch 4338/5000\n",
      "23/23 [==============================] - 5s 245ms/step - loss: -9.5638 - val_loss: -9.4060\n",
      "Epoch 4339/5000\n",
      "23/23 [==============================] - 5s 245ms/step - loss: -9.5770 - val_loss: -9.3977\n",
      "Epoch 4340/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.5783 - val_loss: -9.3975\n",
      "Epoch 4341/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5669 - val_loss: -9.3959\n",
      "Epoch 4342/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5881 - val_loss: -9.4025\n",
      "Epoch 4343/5000\n",
      "23/23 [==============================] - 5s 217ms/step - loss: -9.5731 - val_loss: -9.3998\n",
      "Epoch 4344/5000\n",
      "23/23 [==============================] - 6s 260ms/step - loss: -9.5865 - val_loss: -9.3997\n",
      "Epoch 4345/5000\n",
      "23/23 [==============================] - 4s 171ms/step - loss: -9.5884 - val_loss: -9.4015\n",
      "Epoch 4346/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.5697 - val_loss: -9.4097\n",
      "Epoch 4347/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.5927 - val_loss: -9.3911\n",
      "Epoch 4348/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.5853 - val_loss: -9.3992\n",
      "Epoch 4349/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.6038 - val_loss: -9.4028\n",
      "Epoch 4350/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6044 - val_loss: -9.4052\n",
      "Epoch 4351/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6029 - val_loss: -9.4001\n",
      "Epoch 4352/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.6013 - val_loss: -9.4030\n",
      "Epoch 4353/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5982 - val_loss: -9.3996\n",
      "Epoch 4354/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.5887 - val_loss: -9.4007\n",
      "Epoch 4355/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5871 - val_loss: -9.4000\n",
      "Epoch 4356/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.5792 - val_loss: -9.4136\n",
      "Epoch 4357/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5990 - val_loss: -9.3986\n",
      "Epoch 4358/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5893 - val_loss: -9.4009\n",
      "Epoch 4359/5000\n",
      "23/23 [==============================] - 2s 113ms/step - loss: -9.5343 - val_loss: -9.4008\n",
      "Epoch 4360/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.5873 - val_loss: -9.4003\n",
      "Epoch 4361/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5826 - val_loss: -9.4054\n",
      "Epoch 4362/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -9.5864 - val_loss: -9.4009\n",
      "Epoch 4363/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5971 - val_loss: -9.4010\n",
      "Epoch 4364/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.6154 - val_loss: -9.4023\n",
      "Epoch 4365/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5374 - val_loss: -9.4047\n",
      "Epoch 4366/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -9.5845 - val_loss: -9.4017\n",
      "Epoch 4367/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.5992 - val_loss: -9.4045\n",
      "Epoch 4368/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6099 - val_loss: -9.3985\n",
      "Epoch 4369/5000\n",
      "23/23 [==============================] - 6s 249ms/step - loss: -9.5976 - val_loss: -9.3994\n",
      "Epoch 4370/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5698 - val_loss: -9.4012\n",
      "Epoch 4371/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.5577 - val_loss: -9.4011\n",
      "Epoch 4372/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.5826 - val_loss: -9.4041\n",
      "Epoch 4373/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.5706 - val_loss: -9.3922\n",
      "Epoch 4374/5000\n",
      "23/23 [==============================] - 3s 151ms/step - loss: -9.5915 - val_loss: -9.4029\n",
      "Epoch 4375/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5995 - val_loss: -9.4035\n",
      "Epoch 4376/5000\n",
      "23/23 [==============================] - 3s 115ms/step - loss: -9.5661 - val_loss: -9.4037\n",
      "Epoch 4377/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5849 - val_loss: -9.3972\n",
      "Epoch 4378/5000\n",
      "23/23 [==============================] - 2s 113ms/step - loss: -9.5738 - val_loss: -9.4039\n",
      "Epoch 4379/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.5948 - val_loss: -9.4006\n",
      "Epoch 4380/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.5997 - val_loss: -9.3998\n",
      "Epoch 4381/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5791 - val_loss: -9.3958\n",
      "Epoch 4382/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.5853 - val_loss: -9.4059\n",
      "Epoch 4383/5000\n",
      "23/23 [==============================] - 6s 272ms/step - loss: -9.6239 - val_loss: -9.4031\n",
      "Epoch 4384/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.5985 - val_loss: -9.4044\n",
      "Epoch 4385/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.5909 - val_loss: -9.4042\n",
      "Epoch 4386/5000\n",
      "23/23 [==============================] - 4s 178ms/step - loss: -9.5949 - val_loss: -9.4092\n",
      "Epoch 4387/5000\n",
      "23/23 [==============================] - 4s 187ms/step - loss: -9.5363 - val_loss: -9.3892\n",
      "Epoch 4388/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.5874 - val_loss: -9.4077\n",
      "Epoch 4389/5000\n",
      "23/23 [==============================] - 4s 198ms/step - loss: -9.6069 - val_loss: -9.3977\n",
      "Epoch 4390/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.5777 - val_loss: -9.4014\n",
      "Epoch 4391/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.5946 - val_loss: -9.4049\n",
      "Epoch 4392/5000\n",
      "23/23 [==============================] - 3s 133ms/step - loss: -9.6075 - val_loss: -9.4027\n",
      "Epoch 4393/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.6093 - val_loss: -9.4041\n",
      "Epoch 4394/5000\n",
      "23/23 [==============================] - 3s 115ms/step - loss: -9.6002 - val_loss: -9.4016\n",
      "Epoch 4395/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6156 - val_loss: -9.4009\n",
      "Epoch 4396/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.5658 - val_loss: -9.4035\n",
      "Epoch 4397/5000\n",
      "23/23 [==============================] - 3s 152ms/step - loss: -9.5830 - val_loss: -9.4059\n",
      "Epoch 4398/5000\n",
      "23/23 [==============================] - 2s 109ms/step - loss: -9.6081 - val_loss: -9.4042\n",
      "Epoch 4399/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.5749 - val_loss: -9.4100\n",
      "Epoch 4400/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.5823 - val_loss: -9.4095\n",
      "Epoch 4401/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.5975 - val_loss: -9.3989\n",
      "Epoch 4402/5000\n",
      "23/23 [==============================] - 3s 117ms/step - loss: -9.5823 - val_loss: -9.4033\n",
      "Epoch 4403/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.6090 - val_loss: -9.3998\n",
      "Epoch 4404/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5976 - val_loss: -9.4108\n",
      "Epoch 4405/5000\n",
      "23/23 [==============================] - 2s 109ms/step - loss: -9.5841 - val_loss: -9.4018\n",
      "Epoch 4406/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5931 - val_loss: -9.4037\n",
      "Epoch 4407/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.5781 - val_loss: -9.4104\n",
      "Epoch 4408/5000\n",
      "23/23 [==============================] - 5s 245ms/step - loss: -9.6082 - val_loss: -9.3986\n",
      "Epoch 4409/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.6097 - val_loss: -9.4015\n",
      "Epoch 4410/5000\n",
      "23/23 [==============================] - 5s 248ms/step - loss: -9.5911 - val_loss: -9.4004\n",
      "Epoch 4411/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -9.6202 - val_loss: -9.4091\n",
      "Epoch 4412/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.6113 - val_loss: -9.3998\n",
      "Epoch 4413/5000\n",
      "23/23 [==============================] - 2s 86ms/step - loss: -9.6058 - val_loss: -9.4060\n",
      "Epoch 4414/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.5382 - val_loss: -9.4091\n",
      "Epoch 4415/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -9.6018 - val_loss: -9.4093\n",
      "Epoch 4416/5000\n",
      "23/23 [==============================] - 3s 118ms/step - loss: -9.5848 - val_loss: -9.4014\n",
      "Epoch 4417/5000\n",
      "23/23 [==============================] - 3s 135ms/step - loss: -9.5911 - val_loss: -9.3977\n",
      "Epoch 4418/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.6030 - val_loss: -9.4064\n",
      "Epoch 4419/5000\n",
      "23/23 [==============================] - 3s 138ms/step - loss: -9.5654 - val_loss: -9.4015\n",
      "Epoch 4420/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6005 - val_loss: -9.4040\n",
      "Epoch 4421/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.6039 - val_loss: -9.4012\n",
      "Epoch 4422/5000\n",
      "23/23 [==============================] - 3s 119ms/step - loss: -9.5913 - val_loss: -9.4002\n",
      "Epoch 4423/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.5808 - val_loss: -9.4047\n",
      "Epoch 4424/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5726 - val_loss: -9.4043\n",
      "Epoch 4425/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.6049 - val_loss: -9.4053\n",
      "Epoch 4426/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6086 - val_loss: -9.4068\n",
      "Epoch 4427/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5604 - val_loss: -9.4102\n",
      "Epoch 4428/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5843 - val_loss: -9.3978\n",
      "Epoch 4429/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -9.5990 - val_loss: -9.3987\n",
      "Epoch 4430/5000\n",
      "23/23 [==============================] - 5s 239ms/step - loss: -9.5724 - val_loss: -9.4109\n",
      "Epoch 4431/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5878 - val_loss: -9.4100\n",
      "Epoch 4432/5000\n",
      "23/23 [==============================] - 2s 84ms/step - loss: -9.5791 - val_loss: -9.3960\n",
      "Epoch 4433/5000\n",
      "23/23 [==============================] - 3s 113ms/step - loss: -9.5847 - val_loss: -9.4052\n",
      "Epoch 4434/5000\n",
      "23/23 [==============================] - 4s 167ms/step - loss: -9.5622 - val_loss: -9.4076\n",
      "Epoch 4435/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5944 - val_loss: -9.4022\n",
      "Epoch 4436/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.6068 - val_loss: -9.4027\n",
      "Epoch 4437/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5871 - val_loss: -9.3992\n",
      "Epoch 4438/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.6253 - val_loss: -9.4068\n",
      "Epoch 4439/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5882 - val_loss: -9.4112\n",
      "Epoch 4440/5000\n",
      "23/23 [==============================] - 5s 247ms/step - loss: -9.6211 - val_loss: -9.4152\n",
      "Epoch 4441/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.5796 - val_loss: -9.4048\n",
      "Epoch 4442/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.5472 - val_loss: -9.4110\n",
      "Epoch 4443/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.5941 - val_loss: -9.4033\n",
      "Epoch 4444/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.5991 - val_loss: -9.4018\n",
      "Epoch 4445/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5691 - val_loss: -9.4045\n",
      "Epoch 4446/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5808 - val_loss: -9.4043\n",
      "Epoch 4447/5000\n",
      "23/23 [==============================] - 2s 83ms/step - loss: -9.5862 - val_loss: -9.4078\n",
      "Epoch 4448/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.5946 - val_loss: -9.4103\n",
      "Epoch 4449/5000\n",
      "23/23 [==============================] - 3s 117ms/step - loss: -9.5886 - val_loss: -9.4039\n",
      "Epoch 4450/5000\n",
      "23/23 [==============================] - 3s 113ms/step - loss: -9.6067 - val_loss: -9.4121\n",
      "Epoch 4451/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.5984 - val_loss: -9.4036\n",
      "Epoch 4452/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.6004 - val_loss: -9.4146\n",
      "Epoch 4453/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.6054 - val_loss: -9.4091\n",
      "Epoch 4454/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5731 - val_loss: -9.4062\n",
      "Epoch 4455/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5889 - val_loss: -9.4112\n",
      "Epoch 4456/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5993 - val_loss: -9.4039\n",
      "Epoch 4457/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.5868 - val_loss: -9.4082\n",
      "Epoch 4458/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5383 - val_loss: -9.4073\n",
      "Epoch 4459/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5945 - val_loss: -9.4077\n",
      "Epoch 4460/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.6081 - val_loss: -9.4049\n",
      "Epoch 4461/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.6029 - val_loss: -9.4072\n",
      "Epoch 4462/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.5917 - val_loss: -9.4044\n",
      "Epoch 4463/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.5773 - val_loss: -9.4099\n",
      "Epoch 4464/5000\n",
      "23/23 [==============================] - 4s 173ms/step - loss: -9.5950 - val_loss: -9.4196\n",
      "Epoch 4465/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.5840 - val_loss: -9.4122\n",
      "Epoch 4466/5000\n",
      "23/23 [==============================] - 3s 120ms/step - loss: -9.5643 - val_loss: -9.4149\n",
      "Epoch 4467/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.5862 - val_loss: -9.4103\n",
      "Epoch 4468/5000\n",
      "23/23 [==============================] - 5s 242ms/step - loss: -9.6085 - val_loss: -9.4120\n",
      "Epoch 4469/5000\n",
      "23/23 [==============================] - 4s 183ms/step - loss: -9.5887 - val_loss: -9.4080\n",
      "Epoch 4470/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.5296 - val_loss: -9.4121\n",
      "Epoch 4471/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.5836 - val_loss: -9.4128\n",
      "Epoch 4472/5000\n",
      "23/23 [==============================] - 2s 104ms/step - loss: -9.5893 - val_loss: -9.4068\n",
      "Epoch 4473/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.6124 - val_loss: -9.4138\n",
      "Epoch 4474/5000\n",
      "23/23 [==============================] - 3s 118ms/step - loss: -9.5884 - val_loss: -9.4059\n",
      "Epoch 4475/5000\n",
      "23/23 [==============================] - 3s 151ms/step - loss: -9.6158 - val_loss: -9.4059\n",
      "Epoch 4476/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.5832 - val_loss: -9.4140\n",
      "Epoch 4477/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5959 - val_loss: -9.4033\n",
      "Epoch 4478/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -9.5965 - val_loss: -9.4079\n",
      "Epoch 4479/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5940 - val_loss: -9.4077\n",
      "Epoch 4480/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5708 - val_loss: -9.4107\n",
      "Epoch 4481/5000\n",
      "23/23 [==============================] - 3s 113ms/step - loss: -9.6274 - val_loss: -9.4144\n",
      "Epoch 4482/5000\n",
      "23/23 [==============================] - 5s 229ms/step - loss: -9.5767 - val_loss: -9.4135\n",
      "Epoch 4483/5000\n",
      "23/23 [==============================] - 4s 174ms/step - loss: -9.6020 - val_loss: -9.4101\n",
      "Epoch 4484/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -9.6095 - val_loss: -9.4142\n",
      "Epoch 4485/5000\n",
      "23/23 [==============================] - 2s 112ms/step - loss: -9.5948 - val_loss: -9.4116\n",
      "Epoch 4486/5000\n",
      "23/23 [==============================] - 4s 187ms/step - loss: -9.5931 - val_loss: -9.4101\n",
      "Epoch 4487/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.5843 - val_loss: -9.4082\n",
      "Epoch 4488/5000\n",
      "23/23 [==============================] - 5s 241ms/step - loss: -9.5949 - val_loss: -9.4090\n",
      "Epoch 4489/5000\n",
      "23/23 [==============================] - 2s 104ms/step - loss: -9.5511 - val_loss: -9.4092\n",
      "Epoch 4490/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -9.5906 - val_loss: -9.4049\n",
      "Epoch 4491/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.6008 - val_loss: -9.4099\n",
      "Epoch 4492/5000\n",
      "23/23 [==============================] - 4s 172ms/step - loss: -9.5944 - val_loss: -9.4067\n",
      "Epoch 4493/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6166 - val_loss: -9.4101\n",
      "Epoch 4494/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.6236 - val_loss: -9.4119\n",
      "Epoch 4495/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.5926 - val_loss: -9.4055\n",
      "Epoch 4496/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5993 - val_loss: -9.4096\n",
      "Epoch 4497/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.6050 - val_loss: -9.4137\n",
      "Epoch 4498/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5999 - val_loss: -9.4092\n",
      "Epoch 4499/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.6088 - val_loss: -9.4153\n",
      "Epoch 4500/5000\n",
      "23/23 [==============================] - 3s 131ms/step - loss: -9.5912 - val_loss: -9.4092\n",
      "Epoch 4501/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.6049 - val_loss: -9.4068\n",
      "Epoch 4502/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5843 - val_loss: -9.4131\n",
      "Epoch 4503/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.5994 - val_loss: -9.4100\n",
      "Epoch 4504/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.5995 - val_loss: -9.4065\n",
      "Epoch 4505/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.6058 - val_loss: -9.4078\n",
      "Epoch 4506/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5762 - val_loss: -9.4124\n",
      "Epoch 4507/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.6132 - val_loss: -9.4120\n",
      "Epoch 4508/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.6127 - val_loss: -9.4063\n",
      "Epoch 4509/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.5920 - val_loss: -9.4119\n",
      "Epoch 4510/5000\n",
      "23/23 [==============================] - 2s 104ms/step - loss: -9.5944 - val_loss: -9.4149\n",
      "Epoch 4511/5000\n",
      "23/23 [==============================] - 3s 132ms/step - loss: -9.5993 - val_loss: -9.4149\n",
      "Epoch 4512/5000\n",
      "23/23 [==============================] - 2s 112ms/step - loss: -9.6112 - val_loss: -9.4046\n",
      "Epoch 4513/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.6216 - val_loss: -9.4045\n",
      "Epoch 4514/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -9.5691 - val_loss: -9.4120\n",
      "Epoch 4515/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5918 - val_loss: -9.4126\n",
      "Epoch 4516/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.6076 - val_loss: -9.4049\n",
      "Epoch 4517/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5940 - val_loss: -9.4145\n",
      "Epoch 4518/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -9.6103 - val_loss: -9.4045\n",
      "Epoch 4519/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.6110 - val_loss: -9.4084\n",
      "Epoch 4520/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -9.6045 - val_loss: -9.4182\n",
      "Epoch 4521/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.6315 - val_loss: -9.4107\n",
      "Epoch 4522/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.5968 - val_loss: -9.4091\n",
      "Epoch 4523/5000\n",
      "23/23 [==============================] - 3s 132ms/step - loss: -9.6243 - val_loss: -9.4123\n",
      "Epoch 4524/5000\n",
      "23/23 [==============================] - 2s 110ms/step - loss: -9.6061 - val_loss: -9.4157\n",
      "Epoch 4525/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.5933 - val_loss: -9.4111\n",
      "Epoch 4526/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -9.6073 - val_loss: -9.4070\n",
      "Epoch 4527/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.5906 - val_loss: -9.4131\n",
      "Epoch 4528/5000\n",
      "23/23 [==============================] - 3s 118ms/step - loss: -9.6023 - val_loss: -9.4111\n",
      "Epoch 4529/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6160 - val_loss: -9.4122\n",
      "Epoch 4530/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -9.6069 - val_loss: -9.4044\n",
      "Epoch 4531/5000\n",
      "23/23 [==============================] - 4s 160ms/step - loss: -9.6087 - val_loss: -9.4091\n",
      "Epoch 4532/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -9.5864 - val_loss: -9.4126\n",
      "Epoch 4533/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -9.5893 - val_loss: -9.4140\n",
      "Epoch 4534/5000\n",
      "23/23 [==============================] - 5s 247ms/step - loss: -9.5747 - val_loss: -9.4126\n",
      "Epoch 4535/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.5737 - val_loss: -9.4199\n",
      "Epoch 4536/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -9.6120 - val_loss: -9.4149\n",
      "Epoch 4537/5000\n",
      "23/23 [==============================] - 4s 186ms/step - loss: -9.6142 - val_loss: -9.4139\n",
      "Epoch 4538/5000\n",
      "23/23 [==============================] - 2s 109ms/step - loss: -9.5966 - val_loss: -9.4009\n",
      "Epoch 4539/5000\n",
      "23/23 [==============================] - 3s 134ms/step - loss: -9.6074 - val_loss: -9.4135\n",
      "Epoch 4540/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.5851 - val_loss: -9.4138\n",
      "Epoch 4541/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.5775 - val_loss: -9.4064\n",
      "Epoch 4542/5000\n",
      "23/23 [==============================] - 3s 117ms/step - loss: -9.5941 - val_loss: -9.4174\n",
      "Epoch 4543/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6046 - val_loss: -9.4091\n",
      "Epoch 4544/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.5915 - val_loss: -9.4099\n",
      "Epoch 4545/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.5926 - val_loss: -9.4117\n",
      "Epoch 4546/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.5927 - val_loss: -9.4093\n",
      "Epoch 4547/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.6032 - val_loss: -9.4098\n",
      "Epoch 4548/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -9.5949 - val_loss: -9.4183\n",
      "Epoch 4549/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5776 - val_loss: -9.4128\n",
      "Epoch 4550/5000\n",
      "23/23 [==============================] - 3s 114ms/step - loss: -9.6099 - val_loss: -9.4106\n",
      "Epoch 4551/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6278 - val_loss: -9.4160\n",
      "Epoch 4552/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6167 - val_loss: -9.4147\n",
      "Epoch 4553/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.6083 - val_loss: -9.4104\n",
      "Epoch 4554/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6150 - val_loss: -9.4113\n",
      "Epoch 4555/5000\n",
      "23/23 [==============================] - 2s 109ms/step - loss: -9.6091 - val_loss: -9.4153\n",
      "Epoch 4556/5000\n",
      "23/23 [==============================] - 5s 240ms/step - loss: -9.6061 - val_loss: -9.4112\n",
      "Epoch 4557/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.6162 - val_loss: -9.4122\n",
      "Epoch 4558/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.6141 - val_loss: -9.4146\n",
      "Epoch 4559/5000\n",
      "23/23 [==============================] - 5s 240ms/step - loss: -9.5985 - val_loss: -9.4117\n",
      "Epoch 4560/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -9.5854 - val_loss: -9.4190\n",
      "Epoch 4561/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.6002 - val_loss: -9.4128\n",
      "Epoch 4562/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5968 - val_loss: -9.4173\n",
      "Epoch 4563/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.6133 - val_loss: -9.4097\n",
      "Epoch 4564/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.6287 - val_loss: -9.4151\n",
      "Epoch 4565/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5919 - val_loss: -9.4098\n",
      "Epoch 4566/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.6035 - val_loss: -9.4194\n",
      "Epoch 4567/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.6120 - val_loss: -9.4164\n",
      "Epoch 4568/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6183 - val_loss: -9.4115\n",
      "Epoch 4569/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.6058 - val_loss: -9.4167\n",
      "Epoch 4570/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6159 - val_loss: -9.4140\n",
      "Epoch 4571/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -9.5608 - val_loss: -9.4159\n",
      "Epoch 4572/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.6181 - val_loss: -9.4099\n",
      "Epoch 4573/5000\n",
      "23/23 [==============================] - 3s 146ms/step - loss: -9.5965 - val_loss: -9.4163\n",
      "Epoch 4574/5000\n",
      "23/23 [==============================] - 3s 153ms/step - loss: -9.6094 - val_loss: -9.4112\n",
      "Epoch 4575/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.6225 - val_loss: -9.4142\n",
      "Epoch 4576/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5888 - val_loss: -9.4155\n",
      "Epoch 4577/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.6015 - val_loss: -9.4217\n",
      "Epoch 4578/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.6032 - val_loss: -9.4118\n",
      "Epoch 4579/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.5941 - val_loss: -9.4173\n",
      "Epoch 4580/5000\n",
      "23/23 [==============================] - 2s 104ms/step - loss: -9.5926 - val_loss: -9.4070\n",
      "Epoch 4581/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.6141 - val_loss: -9.4085\n",
      "Epoch 4582/5000\n",
      "23/23 [==============================] - 2s 92ms/step - loss: -9.6107 - val_loss: -9.4156\n",
      "Epoch 4583/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.5303 - val_loss: -9.4148\n",
      "Epoch 4584/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -9.6084 - val_loss: -9.4136\n",
      "Epoch 4585/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -9.5997 - val_loss: -9.4145\n",
      "Epoch 4586/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6168 - val_loss: -9.4204\n",
      "Epoch 4587/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -9.6182 - val_loss: -9.4225\n",
      "Epoch 4588/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -9.6215 - val_loss: -9.4136\n",
      "Epoch 4589/5000\n",
      "23/23 [==============================] - 2s 91ms/step - loss: -9.6033 - val_loss: -9.4101\n",
      "Epoch 4590/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5996 - val_loss: -9.4161\n",
      "Epoch 4591/5000\n",
      "23/23 [==============================] - 3s 114ms/step - loss: -9.6105 - val_loss: -9.4124\n",
      "Epoch 4592/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -9.6194 - val_loss: -9.4171\n",
      "Epoch 4593/5000\n",
      "23/23 [==============================] - 3s 119ms/step - loss: -9.6128 - val_loss: -9.4161\n",
      "Epoch 4594/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.5984 - val_loss: -9.4156\n",
      "Epoch 4595/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -9.6208 - val_loss: -9.4194\n",
      "Epoch 4596/5000\n",
      "23/23 [==============================] - 3s 113ms/step - loss: -9.6067 - val_loss: -9.4177\n",
      "Epoch 4597/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6072 - val_loss: -9.4155\n",
      "Epoch 4598/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.6158 - val_loss: -9.4192\n",
      "Epoch 4599/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5800 - val_loss: -9.4133\n",
      "Epoch 4600/5000\n",
      "23/23 [==============================] - 3s 131ms/step - loss: -9.6051 - val_loss: -9.4077\n",
      "Epoch 4601/5000\n",
      "23/23 [==============================] - 2s 112ms/step - loss: -9.5971 - val_loss: -9.4190\n",
      "Epoch 4602/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.6153 - val_loss: -9.4138\n",
      "Epoch 4603/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.6140 - val_loss: -9.4057\n",
      "Epoch 4604/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.6315 - val_loss: -9.4177\n",
      "Epoch 4605/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -9.6173 - val_loss: -9.4188\n",
      "Epoch 4606/5000\n",
      "23/23 [==============================] - 3s 131ms/step - loss: -9.6049 - val_loss: -9.4193\n",
      "Epoch 4607/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -9.5881 - val_loss: -9.4182\n",
      "Epoch 4608/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -9.6084 - val_loss: -9.4136\n",
      "Epoch 4609/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.6230 - val_loss: -9.4192\n",
      "Epoch 4610/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -9.5885 - val_loss: -9.4137\n",
      "Epoch 4611/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6096 - val_loss: -9.4202\n",
      "Epoch 4612/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -9.5934 - val_loss: -9.4189\n",
      "Epoch 4613/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.5995 - val_loss: -9.4158\n",
      "Epoch 4614/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5798 - val_loss: -9.4168\n",
      "Epoch 4615/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -9.6004 - val_loss: -9.4115\n",
      "Epoch 4616/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.6082 - val_loss: -9.4166\n",
      "Epoch 4617/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.5948 - val_loss: -9.4130\n",
      "Epoch 4618/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5954 - val_loss: -9.4158\n",
      "Epoch 4619/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.6138 - val_loss: -9.4165\n",
      "Epoch 4620/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.6068 - val_loss: -9.4205\n",
      "Epoch 4621/5000\n",
      "23/23 [==============================] - 2s 89ms/step - loss: -9.6138 - val_loss: -9.4203\n",
      "Epoch 4622/5000\n",
      "23/23 [==============================] - 3s 155ms/step - loss: -9.6086 - val_loss: -9.4181\n",
      "Epoch 4623/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.6251 - val_loss: -9.4149\n",
      "Epoch 4624/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -9.6113 - val_loss: -9.4138\n",
      "Epoch 4625/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5622 - val_loss: -9.4225\n",
      "Epoch 4626/5000\n",
      "23/23 [==============================] - 5s 244ms/step - loss: -9.5828 - val_loss: -9.4231\n",
      "Epoch 4627/5000\n",
      "23/23 [==============================] - 2s 109ms/step - loss: -9.5932 - val_loss: -9.4269\n",
      "Epoch 4628/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -9.6021 - val_loss: -9.4135\n",
      "Epoch 4629/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5811 - val_loss: -9.4177\n",
      "Epoch 4630/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.6017 - val_loss: -9.4206\n",
      "Epoch 4631/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -9.6230 - val_loss: -9.4160\n",
      "Epoch 4632/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -9.6044 - val_loss: -9.4219\n",
      "Epoch 4633/5000\n",
      "23/23 [==============================] - 3s 121ms/step - loss: -9.5461 - val_loss: -9.4215\n",
      "Epoch 4634/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.5907 - val_loss: -9.4227\n",
      "Epoch 4635/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.6063 - val_loss: -9.4228\n",
      "Epoch 4636/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.6114 - val_loss: -9.4177\n",
      "Epoch 4637/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6233 - val_loss: -9.4148\n",
      "Epoch 4638/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6102 - val_loss: -9.4148\n",
      "Epoch 4639/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.6004 - val_loss: -9.4160\n",
      "Epoch 4640/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.6061 - val_loss: -9.4176\n",
      "Epoch 4641/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.6190 - val_loss: -9.4176\n",
      "Epoch 4642/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6247 - val_loss: -9.4125\n",
      "Epoch 4643/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.5842 - val_loss: -9.4127\n",
      "Epoch 4644/5000\n",
      "23/23 [==============================] - 5s 241ms/step - loss: -9.6291 - val_loss: -9.4172\n",
      "Epoch 4645/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -9.6260 - val_loss: -9.4223\n",
      "Epoch 4646/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.5849 - val_loss: -9.4164\n",
      "Epoch 4647/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.6271 - val_loss: -9.4180\n",
      "Epoch 4648/5000\n",
      "23/23 [==============================] - 3s 120ms/step - loss: -9.6188 - val_loss: -9.4194\n",
      "Epoch 4649/5000\n",
      "23/23 [==============================] - 5s 211ms/step - loss: -9.6032 - val_loss: -9.4216\n",
      "Epoch 4650/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.6176 - val_loss: -9.4247\n",
      "Epoch 4651/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -9.5816 - val_loss: -9.4255\n",
      "Epoch 4652/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6094 - val_loss: -9.4163\n",
      "Epoch 4653/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6212 - val_loss: -9.4109\n",
      "Epoch 4654/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.6102 - val_loss: -9.4193\n",
      "Epoch 4655/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -9.6298 - val_loss: -9.4174\n",
      "Epoch 4656/5000\n",
      "23/23 [==============================] - 3s 151ms/step - loss: -9.5934 - val_loss: -9.4198\n",
      "Epoch 4657/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6163 - val_loss: -9.4235\n",
      "Epoch 4658/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6048 - val_loss: -9.4202\n",
      "Epoch 4659/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6067 - val_loss: -9.4212\n",
      "Epoch 4660/5000\n",
      "23/23 [==============================] - 2s 108ms/step - loss: -9.6143 - val_loss: -9.4219\n",
      "Epoch 4661/5000\n",
      "23/23 [==============================] - 6s 273ms/step - loss: -9.5849 - val_loss: -9.4263\n",
      "Epoch 4662/5000\n",
      "23/23 [==============================] - 3s 133ms/step - loss: -9.5956 - val_loss: -9.4197\n",
      "Epoch 4663/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.5941 - val_loss: -9.4206\n",
      "Epoch 4664/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -9.5994 - val_loss: -9.4263\n",
      "Epoch 4665/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.6063 - val_loss: -9.4224\n",
      "Epoch 4666/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.6118 - val_loss: -9.4202\n",
      "Epoch 4667/5000\n",
      "23/23 [==============================] - 3s 118ms/step - loss: -9.5989 - val_loss: -9.4202\n",
      "Epoch 4668/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.6119 - val_loss: -9.4245\n",
      "Epoch 4669/5000\n",
      "23/23 [==============================] - 3s 119ms/step - loss: -9.6050 - val_loss: -9.4264\n",
      "Epoch 4670/5000\n",
      "23/23 [==============================] - 2s 90ms/step - loss: -9.6238 - val_loss: -9.4207\n",
      "Epoch 4671/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.6132 - val_loss: -9.4238\n",
      "Epoch 4672/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.6278 - val_loss: -9.4265\n",
      "Epoch 4673/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.6309 - val_loss: -9.4137\n",
      "Epoch 4674/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -9.6121 - val_loss: -9.4219\n",
      "Epoch 4675/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6355 - val_loss: -9.4223\n",
      "Epoch 4676/5000\n",
      "23/23 [==============================] - 3s 135ms/step - loss: -9.6132 - val_loss: -9.4209\n",
      "Epoch 4677/5000\n",
      "23/23 [==============================] - 3s 114ms/step - loss: -9.6226 - val_loss: -9.4196\n",
      "Epoch 4678/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6148 - val_loss: -9.4236\n",
      "Epoch 4679/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.5935 - val_loss: -9.4214\n",
      "Epoch 4680/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -9.6234 - val_loss: -9.4192\n",
      "Epoch 4681/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -9.5911 - val_loss: -9.4106\n",
      "Epoch 4682/5000\n",
      "23/23 [==============================] - 3s 148ms/step - loss: -9.5962 - val_loss: -9.4229\n",
      "Epoch 4683/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6078 - val_loss: -9.4272\n",
      "Epoch 4684/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.6223 - val_loss: -9.4220\n",
      "Epoch 4685/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.6043 - val_loss: -9.4223\n",
      "Epoch 4686/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -9.6133 - val_loss: -9.4208\n",
      "Epoch 4687/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6170 - val_loss: -9.4220\n",
      "Epoch 4688/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.5867 - val_loss: -9.4212\n",
      "Epoch 4689/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.6126 - val_loss: -9.4216\n",
      "Epoch 4690/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.6175 - val_loss: -9.4191\n",
      "Epoch 4691/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.6062 - val_loss: -9.4208\n",
      "Epoch 4692/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.6187 - val_loss: -9.4219\n",
      "Epoch 4693/5000\n",
      "23/23 [==============================] - 2s 93ms/step - loss: -9.6100 - val_loss: -9.4206\n",
      "Epoch 4694/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6247 - val_loss: -9.4301\n",
      "Epoch 4695/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6140 - val_loss: -9.4233\n",
      "Epoch 4696/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5971 - val_loss: -9.4237\n",
      "Epoch 4697/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.6065 - val_loss: -9.4194\n",
      "Epoch 4698/5000\n",
      "23/23 [==============================] - 2s 87ms/step - loss: -9.5875 - val_loss: -9.4233\n",
      "Epoch 4699/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -9.5905 - val_loss: -9.4233\n",
      "Epoch 4700/5000\n",
      "23/23 [==============================] - 2s 85ms/step - loss: -9.6232 - val_loss: -9.4216\n",
      "Epoch 4701/5000\n",
      "23/23 [==============================] - 5s 247ms/step - loss: -9.5996 - val_loss: -9.4227\n",
      "Epoch 4702/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.6377 - val_loss: -9.4212\n",
      "Epoch 4703/5000\n",
      "23/23 [==============================] - 3s 155ms/step - loss: -9.5696 - val_loss: -9.4238\n",
      "Epoch 4704/5000\n",
      "23/23 [==============================] - 5s 204ms/step - loss: -9.6029 - val_loss: -9.4168\n",
      "Epoch 4705/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.6099 - val_loss: -9.4284\n",
      "Epoch 4706/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.6264 - val_loss: -9.4225\n",
      "Epoch 4707/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6266 - val_loss: -9.4239\n",
      "Epoch 4708/5000\n",
      "23/23 [==============================] - 5s 243ms/step - loss: -9.6353 - val_loss: -9.4265\n",
      "Epoch 4709/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6259 - val_loss: -9.4280\n",
      "Epoch 4710/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6086 - val_loss: -9.4227\n",
      "Epoch 4711/5000\n",
      "23/23 [==============================] - 3s 133ms/step - loss: -9.6298 - val_loss: -9.4209\n",
      "Epoch 4712/5000\n",
      "23/23 [==============================] - 2s 97ms/step - loss: -9.6087 - val_loss: -9.4256\n",
      "Epoch 4713/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -9.6227 - val_loss: -9.4247\n",
      "Epoch 4714/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -9.6083 - val_loss: -9.4210\n",
      "Epoch 4715/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.6296 - val_loss: -9.4235\n",
      "Epoch 4716/5000\n",
      "23/23 [==============================] - 3s 114ms/step - loss: -9.6216 - val_loss: -9.4178\n",
      "Epoch 4717/5000\n",
      "23/23 [==============================] - 2s 88ms/step - loss: -9.6056 - val_loss: -9.4222\n",
      "Epoch 4718/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6324 - val_loss: -9.4181\n",
      "Epoch 4719/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6017 - val_loss: -9.4229\n",
      "Epoch 4720/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.6266 - val_loss: -9.4229\n",
      "Epoch 4721/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -9.6107 - val_loss: -9.4252\n",
      "Epoch 4722/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -9.6235 - val_loss: -9.4251\n",
      "Epoch 4723/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.5955 - val_loss: -9.4287\n",
      "Epoch 4724/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.6221 - val_loss: -9.4274\n",
      "Epoch 4725/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.6046 - val_loss: -9.4209\n",
      "Epoch 4726/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.6469 - val_loss: -9.4223\n",
      "Epoch 4727/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.6199 - val_loss: -9.4279\n",
      "Epoch 4728/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6219 - val_loss: -9.4230\n",
      "Epoch 4729/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -9.5826 - val_loss: -9.4221\n",
      "Epoch 4730/5000\n",
      "23/23 [==============================] - 2s 104ms/step - loss: -9.5932 - val_loss: -9.4247\n",
      "Epoch 4731/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.5783 - val_loss: -9.4213\n",
      "Epoch 4732/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -9.6027 - val_loss: -9.4211\n",
      "Epoch 4733/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.5992 - val_loss: -9.4290\n",
      "Epoch 4734/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -9.6045 - val_loss: -9.4266\n",
      "Epoch 4735/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.6298 - val_loss: -9.4255\n",
      "Epoch 4736/5000\n",
      "23/23 [==============================] - 3s 121ms/step - loss: -9.6118 - val_loss: -9.4272\n",
      "Epoch 4737/5000\n",
      "23/23 [==============================] - 3s 134ms/step - loss: -9.6120 - val_loss: -9.4228\n",
      "Epoch 4738/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -9.6100 - val_loss: -9.4255\n",
      "Epoch 4739/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.6247 - val_loss: -9.4266\n",
      "Epoch 4740/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6066 - val_loss: -9.4263\n",
      "Epoch 4741/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6339 - val_loss: -9.4240\n",
      "Epoch 4742/5000\n",
      "23/23 [==============================] - 2s 112ms/step - loss: -9.6027 - val_loss: -9.4232\n",
      "Epoch 4743/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6052 - val_loss: -9.4194\n",
      "Epoch 4744/5000\n",
      "23/23 [==============================] - 2s 109ms/step - loss: -9.6246 - val_loss: -9.4242\n",
      "Epoch 4745/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.6401 - val_loss: -9.4250\n",
      "Epoch 4746/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6079 - val_loss: -9.4239\n",
      "Epoch 4747/5000\n",
      "23/23 [==============================] - 3s 115ms/step - loss: -9.6307 - val_loss: -9.4223\n",
      "Epoch 4748/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.6165 - val_loss: -9.4218\n",
      "Epoch 4749/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.6081 - val_loss: -9.4249\n",
      "Epoch 4750/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.6083 - val_loss: -9.4212\n",
      "Epoch 4751/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6149 - val_loss: -9.4285\n",
      "Epoch 4752/5000\n",
      "23/23 [==============================] - 2s 110ms/step - loss: -9.6062 - val_loss: -9.4224\n",
      "Epoch 4753/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6112 - val_loss: -9.4286\n",
      "Epoch 4754/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.6324 - val_loss: -9.4248\n",
      "Epoch 4755/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.6104 - val_loss: -9.4228\n",
      "Epoch 4756/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.6093 - val_loss: -9.4270\n",
      "Epoch 4757/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.6142 - val_loss: -9.4209\n",
      "Epoch 4758/5000\n",
      "23/23 [==============================] - 2s 110ms/step - loss: -9.6112 - val_loss: -9.4195\n",
      "Epoch 4759/5000\n",
      "23/23 [==============================] - 2s 112ms/step - loss: -9.5897 - val_loss: -9.4209\n",
      "Epoch 4760/5000\n",
      "23/23 [==============================] - 2s 110ms/step - loss: -9.6287 - val_loss: -9.4219\n",
      "Epoch 4761/5000\n",
      "23/23 [==============================] - 3s 116ms/step - loss: -9.6156 - val_loss: -9.4241\n",
      "Epoch 4762/5000\n",
      "23/23 [==============================] - 3s 114ms/step - loss: -9.6222 - val_loss: -9.4294\n",
      "Epoch 4763/5000\n",
      "23/23 [==============================] - 3s 121ms/step - loss: -9.5734 - val_loss: -9.4262\n",
      "Epoch 4764/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.6363 - val_loss: -9.4233\n",
      "Epoch 4765/5000\n",
      "23/23 [==============================] - 2s 112ms/step - loss: -9.6144 - val_loss: -9.4284\n",
      "Epoch 4766/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.6102 - val_loss: -9.4235\n",
      "Epoch 4767/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.5970 - val_loss: -9.4277\n",
      "Epoch 4768/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6071 - val_loss: -9.4247\n",
      "Epoch 4769/5000\n",
      "23/23 [==============================] - 3s 121ms/step - loss: -9.6216 - val_loss: -9.4255\n",
      "Epoch 4770/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.6124 - val_loss: -9.4279\n",
      "Epoch 4771/5000\n",
      "23/23 [==============================] - 2s 113ms/step - loss: -9.6123 - val_loss: -9.4293\n",
      "Epoch 4772/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -9.6135 - val_loss: -9.4276\n",
      "Epoch 4773/5000\n",
      "23/23 [==============================] - 2s 108ms/step - loss: -9.6147 - val_loss: -9.4225\n",
      "Epoch 4774/5000\n",
      "23/23 [==============================] - 3s 118ms/step - loss: -9.5812 - val_loss: -9.4295\n",
      "Epoch 4775/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.6118 - val_loss: -9.4274\n",
      "Epoch 4776/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6398 - val_loss: -9.4278\n",
      "Epoch 4777/5000\n",
      "23/23 [==============================] - 3s 120ms/step - loss: -9.6044 - val_loss: -9.4282\n",
      "Epoch 4778/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -9.6224 - val_loss: -9.4232\n",
      "Epoch 4779/5000\n",
      "23/23 [==============================] - 3s 117ms/step - loss: -9.6196 - val_loss: -9.4355\n",
      "Epoch 4780/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -9.6185 - val_loss: -9.4256\n",
      "Epoch 4781/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.6238 - val_loss: -9.4194\n",
      "Epoch 4782/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6153 - val_loss: -9.4315\n",
      "Epoch 4783/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5977 - val_loss: -9.4256\n",
      "Epoch 4784/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -9.6148 - val_loss: -9.4237\n",
      "Epoch 4785/5000\n",
      "23/23 [==============================] - 2s 108ms/step - loss: -9.6185 - val_loss: -9.4279\n",
      "Epoch 4786/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.6118 - val_loss: -9.4284\n",
      "Epoch 4787/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.6092 - val_loss: -9.4281\n",
      "Epoch 4788/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -9.5699 - val_loss: -9.4232\n",
      "Epoch 4789/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.6294 - val_loss: -9.4297\n",
      "Epoch 4790/5000\n",
      "23/23 [==============================] - 2s 112ms/step - loss: -9.6382 - val_loss: -9.4229\n",
      "Epoch 4791/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.6404 - val_loss: -9.4288\n",
      "Epoch 4792/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.6196 - val_loss: -9.4287\n",
      "Epoch 4793/5000\n",
      "23/23 [==============================] - 2s 113ms/step - loss: -9.6164 - val_loss: -9.4254\n",
      "Epoch 4794/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.6123 - val_loss: -9.4330\n",
      "Epoch 4795/5000\n",
      "23/23 [==============================] - 2s 113ms/step - loss: -9.5909 - val_loss: -9.4221\n",
      "Epoch 4796/5000\n",
      "23/23 [==============================] - 3s 131ms/step - loss: -9.5881 - val_loss: -9.4289\n",
      "Epoch 4797/5000\n",
      "23/23 [==============================] - 2s 108ms/step - loss: -9.6131 - val_loss: -9.4286\n",
      "Epoch 4798/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6065 - val_loss: -9.4287\n",
      "Epoch 4799/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.6386 - val_loss: -9.4290\n",
      "Epoch 4800/5000\n",
      "23/23 [==============================] - 3s 132ms/step - loss: -9.6119 - val_loss: -9.4313\n",
      "Epoch 4801/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.6320 - val_loss: -9.4288\n",
      "Epoch 4802/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.6208 - val_loss: -9.4317\n",
      "Epoch 4803/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6236 - val_loss: -9.4291\n",
      "Epoch 4804/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6239 - val_loss: -9.4282\n",
      "Epoch 4805/5000\n",
      "23/23 [==============================] - 3s 131ms/step - loss: -9.6213 - val_loss: -9.4276\n",
      "Epoch 4806/5000\n",
      "23/23 [==============================] - 2s 110ms/step - loss: -9.5839 - val_loss: -9.4316\n",
      "Epoch 4807/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.6194 - val_loss: -9.4317\n",
      "Epoch 4808/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.6151 - val_loss: -9.4252\n",
      "Epoch 4809/5000\n",
      "23/23 [==============================] - 2s 108ms/step - loss: -9.6137 - val_loss: -9.4229\n",
      "Epoch 4810/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.6155 - val_loss: -9.4307\n",
      "Epoch 4811/5000\n",
      "23/23 [==============================] - 3s 115ms/step - loss: -9.5776 - val_loss: -9.4273\n",
      "Epoch 4812/5000\n",
      "23/23 [==============================] - 3s 118ms/step - loss: -9.6063 - val_loss: -9.4340\n",
      "Epoch 4813/5000\n",
      "23/23 [==============================] - 2s 108ms/step - loss: -9.6001 - val_loss: -9.4307\n",
      "Epoch 4814/5000\n",
      "23/23 [==============================] - 2s 108ms/step - loss: -9.5884 - val_loss: -9.4307\n",
      "Epoch 4815/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5838 - val_loss: -9.4290\n",
      "Epoch 4816/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -9.6020 - val_loss: -9.4326\n",
      "Epoch 4817/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.6213 - val_loss: -9.4303\n",
      "Epoch 4818/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6280 - val_loss: -9.4286\n",
      "Epoch 4819/5000\n",
      "23/23 [==============================] - 3s 114ms/step - loss: -9.6335 - val_loss: -9.4238\n",
      "Epoch 4820/5000\n",
      "23/23 [==============================] - 2s 110ms/step - loss: -9.6049 - val_loss: -9.4256\n",
      "Epoch 4821/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.6098 - val_loss: -9.4316\n",
      "Epoch 4822/5000\n",
      "23/23 [==============================] - 3s 117ms/step - loss: -9.6247 - val_loss: -9.4295\n",
      "Epoch 4823/5000\n",
      "23/23 [==============================] - 2s 113ms/step - loss: -9.6219 - val_loss: -9.4224\n",
      "Epoch 4824/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.6181 - val_loss: -9.4283\n",
      "Epoch 4825/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.6185 - val_loss: -9.4260\n",
      "Epoch 4826/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6213 - val_loss: -9.4328\n",
      "Epoch 4827/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.6012 - val_loss: -9.4281\n",
      "Epoch 4828/5000\n",
      "23/23 [==============================] - 5s 240ms/step - loss: -9.5984 - val_loss: -9.4311\n",
      "Epoch 4829/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6190 - val_loss: -9.4323\n",
      "Epoch 4830/5000\n",
      "23/23 [==============================] - 3s 133ms/step - loss: -9.6144 - val_loss: -9.4357\n",
      "Epoch 4831/5000\n",
      "23/23 [==============================] - 3s 115ms/step - loss: -9.6237 - val_loss: -9.4295\n",
      "Epoch 4832/5000\n",
      "23/23 [==============================] - 5s 245ms/step - loss: -9.6025 - val_loss: -9.4324\n",
      "Epoch 4833/5000\n",
      "23/23 [==============================] - 2s 104ms/step - loss: -9.6305 - val_loss: -9.4316\n",
      "Epoch 4834/5000\n",
      "23/23 [==============================] - 3s 113ms/step - loss: -9.6319 - val_loss: -9.4319\n",
      "Epoch 4835/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.6137 - val_loss: -9.4271\n",
      "Epoch 4836/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.6205 - val_loss: -9.4288\n",
      "Epoch 4837/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6263 - val_loss: -9.4343\n",
      "Epoch 4838/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.6399 - val_loss: -9.4278\n",
      "Epoch 4839/5000\n",
      "23/23 [==============================] - 2s 108ms/step - loss: -9.6190 - val_loss: -9.4281\n",
      "Epoch 4840/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6360 - val_loss: -9.4273\n",
      "Epoch 4841/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.6069 - val_loss: -9.4291\n",
      "Epoch 4842/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.6075 - val_loss: -9.4252\n",
      "Epoch 4843/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.5923 - val_loss: -9.4274\n",
      "Epoch 4844/5000\n",
      "23/23 [==============================] - 3s 114ms/step - loss: -9.6295 - val_loss: -9.4337\n",
      "Epoch 4845/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.6239 - val_loss: -9.4281\n",
      "Epoch 4846/5000\n",
      "23/23 [==============================] - 3s 120ms/step - loss: -9.6195 - val_loss: -9.4381\n",
      "Epoch 4847/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -9.6038 - val_loss: -9.4305\n",
      "Epoch 4848/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -9.6270 - val_loss: -9.4296\n",
      "Epoch 4849/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.5944 - val_loss: -9.4310\n",
      "Epoch 4850/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.6047 - val_loss: -9.4314\n",
      "Epoch 4851/5000\n",
      "23/23 [==============================] - 2s 110ms/step - loss: -9.6148 - val_loss: -9.4333\n",
      "Epoch 4852/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.6316 - val_loss: -9.4282\n",
      "Epoch 4853/5000\n",
      "23/23 [==============================] - 2s 110ms/step - loss: -9.5984 - val_loss: -9.4327\n",
      "Epoch 4854/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.6340 - val_loss: -9.4310\n",
      "Epoch 4855/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.6266 - val_loss: -9.4302\n",
      "Epoch 4856/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.6366 - val_loss: -9.4305\n",
      "Epoch 4857/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -9.6210 - val_loss: -9.4277\n",
      "Epoch 4858/5000\n",
      "23/23 [==============================] - 2s 112ms/step - loss: -9.6093 - val_loss: -9.4328\n",
      "Epoch 4859/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6071 - val_loss: -9.4285\n",
      "Epoch 4860/5000\n",
      "23/23 [==============================] - 3s 116ms/step - loss: -9.6107 - val_loss: -9.4317\n",
      "Epoch 4861/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.6321 - val_loss: -9.4314\n",
      "Epoch 4862/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6145 - val_loss: -9.4365\n",
      "Epoch 4863/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -9.6254 - val_loss: -9.4300\n",
      "Epoch 4864/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6309 - val_loss: -9.4288\n",
      "Epoch 4865/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.6409 - val_loss: -9.4308\n",
      "Epoch 4866/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.6206 - val_loss: -9.4336\n",
      "Epoch 4867/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6227 - val_loss: -9.4335\n",
      "Epoch 4868/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6262 - val_loss: -9.4272\n",
      "Epoch 4869/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -9.6342 - val_loss: -9.4334\n",
      "Epoch 4870/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.5761 - val_loss: -9.4296\n",
      "Epoch 4871/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6099 - val_loss: -9.4303\n",
      "Epoch 4872/5000\n",
      "23/23 [==============================] - 2s 99ms/step - loss: -9.6272 - val_loss: -9.4325\n",
      "Epoch 4873/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.6233 - val_loss: -9.4395\n",
      "Epoch 4874/5000\n",
      "23/23 [==============================] - 3s 114ms/step - loss: -9.6137 - val_loss: -9.4344\n",
      "Epoch 4875/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.5706 - val_loss: -9.4352\n",
      "Epoch 4876/5000\n",
      "23/23 [==============================] - 3s 120ms/step - loss: -9.6172 - val_loss: -9.4285\n",
      "Epoch 4877/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -9.6347 - val_loss: -9.4297\n",
      "Epoch 4878/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.6351 - val_loss: -9.4382\n",
      "Epoch 4879/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -9.6131 - val_loss: -9.4385\n",
      "Epoch 4880/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.6318 - val_loss: -9.4327\n",
      "Epoch 4881/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -9.6246 - val_loss: -9.4291\n",
      "Epoch 4882/5000\n",
      "23/23 [==============================] - 2s 94ms/step - loss: -9.6169 - val_loss: -9.4368\n",
      "Epoch 4883/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.6231 - val_loss: -9.4405\n",
      "Epoch 4884/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.6008 - val_loss: -9.4300\n",
      "Epoch 4885/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.6251 - val_loss: -9.4293\n",
      "Epoch 4886/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.6170 - val_loss: -9.4296\n",
      "Epoch 4887/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.6204 - val_loss: -9.4333\n",
      "Epoch 4888/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -9.6247 - val_loss: -9.4374\n",
      "Epoch 4889/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.6340 - val_loss: -9.4344\n",
      "Epoch 4890/5000\n",
      "23/23 [==============================] - 2s 113ms/step - loss: -9.6356 - val_loss: -9.4342\n",
      "Epoch 4891/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.5812 - val_loss: -9.4359\n",
      "Epoch 4892/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.6112 - val_loss: -9.4320\n",
      "Epoch 4893/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6000 - val_loss: -9.4350\n",
      "Epoch 4894/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.6265 - val_loss: -9.4300\n",
      "Epoch 4895/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.6311 - val_loss: -9.4334\n",
      "Epoch 4896/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -9.6416 - val_loss: -9.4369\n",
      "Epoch 4897/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6317 - val_loss: -9.4335\n",
      "Epoch 4898/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.6131 - val_loss: -9.4259\n",
      "Epoch 4899/5000\n",
      "23/23 [==============================] - 2s 113ms/step - loss: -9.6409 - val_loss: -9.4307\n",
      "Epoch 4900/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.5859 - val_loss: -9.4266\n",
      "Epoch 4901/5000\n",
      "23/23 [==============================] - 2s 96ms/step - loss: -9.6171 - val_loss: -9.4244\n",
      "Epoch 4902/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -9.6312 - val_loss: -9.4227\n",
      "Epoch 4903/5000\n",
      "23/23 [==============================] - 2s 101ms/step - loss: -9.6194 - val_loss: -9.4341\n",
      "Epoch 4904/5000\n",
      "23/23 [==============================] - 2s 110ms/step - loss: -9.6187 - val_loss: -9.4367\n",
      "Epoch 4905/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.5874 - val_loss: -9.4294\n",
      "Epoch 4906/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -9.6387 - val_loss: -9.4303\n",
      "Epoch 4907/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.6321 - val_loss: -9.4334\n",
      "Epoch 4908/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -9.5969 - val_loss: -9.4354\n",
      "Epoch 4909/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.6471 - val_loss: -9.4319\n",
      "Epoch 4910/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.6041 - val_loss: -9.4342\n",
      "Epoch 4911/5000\n",
      "23/23 [==============================] - 3s 132ms/step - loss: -9.6193 - val_loss: -9.4339\n",
      "Epoch 4912/5000\n",
      "23/23 [==============================] - 5s 245ms/step - loss: -9.6326 - val_loss: -9.4280\n",
      "Epoch 4913/5000\n",
      "23/23 [==============================] - 2s 112ms/step - loss: -9.6278 - val_loss: -9.4354\n",
      "Epoch 4914/5000\n",
      "23/23 [==============================] - 3s 118ms/step - loss: -9.6296 - val_loss: -9.4352\n",
      "Epoch 4915/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.6150 - val_loss: -9.4278\n",
      "Epoch 4916/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -9.6284 - val_loss: -9.4314\n",
      "Epoch 4917/5000\n",
      "23/23 [==============================] - 2s 110ms/step - loss: -9.6353 - val_loss: -9.4338\n",
      "Epoch 4918/5000\n",
      "23/23 [==============================] - 2s 113ms/step - loss: -9.6394 - val_loss: -9.4331\n",
      "Epoch 4919/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.6200 - val_loss: -9.4403\n",
      "Epoch 4920/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.6372 - val_loss: -9.4319\n",
      "Epoch 4921/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.6353 - val_loss: -9.4368\n",
      "Epoch 4922/5000\n",
      "23/23 [==============================] - 3s 121ms/step - loss: -9.6169 - val_loss: -9.4389\n",
      "Epoch 4923/5000\n",
      "23/23 [==============================] - 2s 100ms/step - loss: -9.6309 - val_loss: -9.4339\n",
      "Epoch 4924/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.6147 - val_loss: -9.4335\n",
      "Epoch 4925/5000\n",
      "23/23 [==============================] - 3s 114ms/step - loss: -9.6346 - val_loss: -9.4357\n",
      "Epoch 4926/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -9.6375 - val_loss: -9.4336\n",
      "Epoch 4927/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6413 - val_loss: -9.4350\n",
      "Epoch 4928/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -9.6243 - val_loss: -9.4336\n",
      "Epoch 4929/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -9.6274 - val_loss: -9.4360\n",
      "Epoch 4930/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.6346 - val_loss: -9.4329\n",
      "Epoch 4931/5000\n",
      "23/23 [==============================] - 2s 109ms/step - loss: -9.6253 - val_loss: -9.4334\n",
      "Epoch 4932/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6100 - val_loss: -9.4346\n",
      "Epoch 4933/5000\n",
      "23/23 [==============================] - 2s 98ms/step - loss: -9.6131 - val_loss: -9.4366\n",
      "Epoch 4934/5000\n",
      "23/23 [==============================] - 2s 108ms/step - loss: -9.6149 - val_loss: -9.4351\n",
      "Epoch 4935/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6329 - val_loss: -9.4341\n",
      "Epoch 4936/5000\n",
      "23/23 [==============================] - 3s 131ms/step - loss: -9.6127 - val_loss: -9.4419\n",
      "Epoch 4937/5000\n",
      "23/23 [==============================] - 3s 113ms/step - loss: -9.6111 - val_loss: -9.4357\n",
      "Epoch 4938/5000\n",
      "23/23 [==============================] - 2s 110ms/step - loss: -9.6115 - val_loss: -9.4380\n",
      "Epoch 4939/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.6260 - val_loss: -9.4397\n",
      "Epoch 4940/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.6107 - val_loss: -9.4290\n",
      "Epoch 4941/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.6292 - val_loss: -9.4331\n",
      "Epoch 4942/5000\n",
      "23/23 [==============================] - 2s 110ms/step - loss: -9.6355 - val_loss: -9.4390\n",
      "Epoch 4943/5000\n",
      "23/23 [==============================] - 3s 125ms/step - loss: -9.6336 - val_loss: -9.4389\n",
      "Epoch 4944/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -9.6217 - val_loss: -9.4387\n",
      "Epoch 4945/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6162 - val_loss: -9.4309\n",
      "Epoch 4946/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -9.6187 - val_loss: -9.4357\n",
      "Epoch 4947/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.6154 - val_loss: -9.4386\n",
      "Epoch 4948/5000\n",
      "23/23 [==============================] - 2s 95ms/step - loss: -9.6238 - val_loss: -9.4363\n",
      "Epoch 4949/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -9.6289 - val_loss: -9.4361\n",
      "Epoch 4950/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.6287 - val_loss: -9.4357\n",
      "Epoch 4951/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.6234 - val_loss: -9.4368\n",
      "Epoch 4952/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -9.6190 - val_loss: -9.4343\n",
      "Epoch 4953/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.6289 - val_loss: -9.4393\n",
      "Epoch 4954/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6207 - val_loss: -9.4355\n",
      "Epoch 4955/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.6180 - val_loss: -9.4387\n",
      "Epoch 4956/5000\n",
      "23/23 [==============================] - 2s 105ms/step - loss: -9.5965 - val_loss: -9.4366\n",
      "Epoch 4957/5000\n",
      "23/23 [==============================] - 3s 114ms/step - loss: -9.6299 - val_loss: -9.4379\n",
      "Epoch 4958/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6132 - val_loss: -9.4346\n",
      "Epoch 4959/5000\n",
      "23/23 [==============================] - 3s 131ms/step - loss: -9.6069 - val_loss: -9.4427\n",
      "Epoch 4960/5000\n",
      "23/23 [==============================] - 2s 106ms/step - loss: -9.6267 - val_loss: -9.4376\n",
      "Epoch 4961/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -9.5910 - val_loss: -9.4335\n",
      "Epoch 4962/5000\n",
      "23/23 [==============================] - 3s 118ms/step - loss: -9.6356 - val_loss: -9.4362\n",
      "Epoch 4963/5000\n",
      "23/23 [==============================] - 3s 123ms/step - loss: -9.6241 - val_loss: -9.4345\n",
      "Epoch 4964/5000\n",
      "23/23 [==============================] - 3s 114ms/step - loss: -9.6259 - val_loss: -9.4398\n",
      "Epoch 4965/5000\n",
      "23/23 [==============================] - 3s 121ms/step - loss: -9.6180 - val_loss: -9.4357\n",
      "Epoch 4966/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -9.6144 - val_loss: -9.4348\n",
      "Epoch 4967/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.6052 - val_loss: -9.4397\n",
      "Epoch 4968/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6352 - val_loss: -9.4372\n",
      "Epoch 4969/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6302 - val_loss: -9.4384\n",
      "Epoch 4970/5000\n",
      "23/23 [==============================] - 3s 120ms/step - loss: -9.6369 - val_loss: -9.4346\n",
      "Epoch 4971/5000\n",
      "23/23 [==============================] - 3s 116ms/step - loss: -9.6114 - val_loss: -9.4392\n",
      "Epoch 4972/5000\n",
      "23/23 [==============================] - 2s 111ms/step - loss: -9.6348 - val_loss: -9.4397\n",
      "Epoch 4973/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -9.6230 - val_loss: -9.4324\n",
      "Epoch 4974/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6005 - val_loss: -9.4330\n",
      "Epoch 4975/5000\n",
      "23/23 [==============================] - 3s 127ms/step - loss: -9.6235 - val_loss: -9.4385\n",
      "Epoch 4976/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -9.6177 - val_loss: -9.4377\n",
      "Epoch 4977/5000\n",
      "23/23 [==============================] - 3s 119ms/step - loss: -9.6259 - val_loss: -9.4352\n",
      "Epoch 4978/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.6211 - val_loss: -9.4390\n",
      "Epoch 4979/5000\n",
      "23/23 [==============================] - 3s 122ms/step - loss: -9.6284 - val_loss: -9.4363\n",
      "Epoch 4980/5000\n",
      "23/23 [==============================] - 2s 103ms/step - loss: -9.6276 - val_loss: -9.4409\n",
      "Epoch 4981/5000\n",
      "23/23 [==============================] - 3s 114ms/step - loss: -9.6219 - val_loss: -9.4297\n",
      "Epoch 4982/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6322 - val_loss: -9.4369\n",
      "Epoch 4983/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6406 - val_loss: -9.4406\n",
      "Epoch 4984/5000\n",
      "23/23 [==============================] - 3s 131ms/step - loss: -9.6186 - val_loss: -9.4349\n",
      "Epoch 4985/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6212 - val_loss: -9.4413\n",
      "Epoch 4986/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6344 - val_loss: -9.4352\n",
      "Epoch 4987/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6230 - val_loss: -9.4425\n",
      "Epoch 4988/5000\n",
      "23/23 [==============================] - 3s 129ms/step - loss: -9.6122 - val_loss: -9.4322\n",
      "Epoch 4989/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -9.6056 - val_loss: -9.4418\n",
      "Epoch 4990/5000\n",
      "23/23 [==============================] - 3s 124ms/step - loss: -9.6245 - val_loss: -9.4348\n",
      "Epoch 4991/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -9.6155 - val_loss: -9.4399\n",
      "Epoch 4992/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6341 - val_loss: -9.4407\n",
      "Epoch 4993/5000\n",
      "23/23 [==============================] - 3s 131ms/step - loss: -9.6289 - val_loss: -9.4404\n",
      "Epoch 4994/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.6215 - val_loss: -9.4431\n",
      "Epoch 4995/5000\n",
      "23/23 [==============================] - 2s 107ms/step - loss: -9.6300 - val_loss: -9.4342\n",
      "Epoch 4996/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.5976 - val_loss: -9.4374\n",
      "Epoch 4997/5000\n",
      "23/23 [==============================] - 3s 130ms/step - loss: -9.6021 - val_loss: -9.4439\n",
      "Epoch 4998/5000\n",
      "23/23 [==============================] - 3s 126ms/step - loss: -9.6469 - val_loss: -9.4414\n",
      "Epoch 4999/5000\n",
      "23/23 [==============================] - 3s 128ms/step - loss: -9.6012 - val_loss: -9.4287\n",
      "Epoch 5000/5000\n",
      "23/23 [==============================] - 2s 102ms/step - loss: -9.5857 - val_loss: -9.4367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbdf0e5f220>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.fit([angle_train_dep,train_dataset],angle_train_dep,\n",
    "        validation_data=([angle_eval_dep,eval_dataset],angle_eval_dep),\n",
    "        batch_size=32,epochs=5000,\n",
    "       callbacks = [model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
